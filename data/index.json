{ "software": [{ "schema": "http://software.esciencecenter.nl/schema/software", "contributor": ["/person/s.verhoeven", { "linkedInUrl": "https://nl.linkedin.com/in/ross-mcguire-71457523", "affiliation": ["/organization/radboud.university.nijmegen"], "name": "Ross McGuire" }], "tagLine": "Virtual machine with all software and sample data to run 3D-e-Chem Knime workflows", "slug": "3d-e-chem-vm", "id": "/software/3d-e-chem-vm", "contactPerson": "/person/s.verhoeven", "codeRepository": "https://github.com/3D-e-Chem/3D-e-Chem-VM", "startDate": "2016-01-11", "competence": ["Optimized Data Handling"], "documentationUrl": "https://github.com/3D-e-Chem/3D-e-Chem-VM/wiki", "doi": "http://dx.doi.org/10.5281/zenodo.51474", "status": "active", "dependency": ["/software/chemical-analytics-platform"], "name": "3D-e-Chem Virtual machine", "title": "3d E Chem Vm", "owner": ["/organization/nlesc", "/organization/radboud.university.nijmegen", "/organization/vua"], "downloadUrl": "https://atlas.hashicorp.com/nlesc/boxes/3d-e-chem", "programmingLanguage": ["YAML"], "expertise": ["Reproducible Research"], "technologyTag": ["Knime", "Vagrant", "Packer"], "usedIn": ["/project/3d-e-chem"], "@id": "http://software.esciencecenter.nl/software/3d-e-chem-vm/", "description": "<p><img src=\"https://3d-e-chem.github.io/3D-e-Chem-VM/assets/images/3d-e-chem-vm-screenshot.png\" alt=\"Screenshot of Desktop\" title=\"Screenshot\" /></p>\n\n<p>3D-e-chem VM is freely available Virtual Machine (VM) encompassing tools, databases &amp; workflows, including new resources developed for ligand binding site comparisons and GPCR research.</p>\n\n<p>The VM contains a fully functional cheminformatics infrastructure consisting of a chemistry enabled relational database system (PostgreSQL + RDKit) with a data analytics workflow tool (KNIME) and additional cheminformatics capabilities.</p>\n\n<p>Tools, workflows and reference data sets are made available. The wide range of cheminformatics functionalities are provided in the downloadable 3D-e-chem VM allowing immediate use in research and education.</p>\n", "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/radboud.university.nijmegen", "/organization/vua"], "endorsedBy": ["/organization/nlesc"], "website": "https://3d-e-chem.github.io/3D-e-Chem-VM", "license": ["apache-2.0"], "discipline": ["eScience Methodology"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2014-04-01", "contributor": ["/person/m.vanmeersbergen", "/person/o.rubi", "/person/s.verhoeven"], "tagLine": "WebGL point cloud visualization of AHN2", "slug": "ahn2webviewer", "owner": ["/organization/nlesc"], "contactPerson": "/person/m.vanmeersbergen", "codeRepository": "https://github.com/NLeSC/ahn-pointcloud-viewer", "user": ["/organization/nlesc", "/person/o.rubi"], "title": "Ahn2webviewer", "competence": ["Big Data Analytics"], "status": "active", "dependency": ["/software/potree", "/software/potreeconverter", "/software/massivepotreeconverter"], "name": "AHN2 pointcloud viewer", "supportLevel": "specialized", "programmingLanguage": ["JavaScript"], "expertise": ["Scientific Visualization"], "technologyTag": ["Point clouds", "WebGL", "Website", "3D"], "usedIn": ["/project/massive-point-clouds-for-esciences"], "@id": "http://software.esciencecenter.nl/software/ahn2webviewer/", "description": "<p>WebGL point cloud visualization of the Actuele Hoogtekaart Nederland 2. \nThis renderer is based on http://potree.org</p>\n\n<p>In order to visualize such a massive data set, the AHN2 has to be reorganized in a multi-resolution octree. This processing can be done with the Massive-PotreeConverter (&lt;/software/massivepotreeconverter&gt;) which is a extension of the PotreeConverter (&lt;/software/potreeconverter&gt;) to distribute the processing into multiple machines/cores.</p>\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "id": "/software/ahn2webviewer", "website": "http://ahn2.pointclouds.nl/", "license": ["apache-2.0"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "contributor": ["/person/n.drost"], "tagLine": "The Astrophysical Multipurpose Simulation Environment", "slug": "amuse", "contactPerson": "/person/n.drost", "codeRepository": "https://github.com/amusecode/amuse", "license": ["gpl-2.0"], "user": ["/organization/nlesc"], "title": "Amuse", "competence": ["Efficient Computing"], "documentationUrl": "http://amusecode.org/doc/", "status": "active", "name": "AMUSE", "owner": ["/organization/leiden-university"], "programmingLanguage": ["Python", "Java", "C++", "C", "FORTRAN", "CUDA", "OpenCL"], "expertise": ["Distributed Computing", "Accelerated Computing", "High Performance Computing"], "technologyTag": ["Simulation", "MultiModel"], "usedIn": ["/project/amuse", "/project/abcmuse"], "@id": "http://software.esciencecenter.nl/software/amuse/", "description": "<p>AMUSE is the Astrophysical Multipurpose Software Environment.</p>\n\n<p>Our aim is to provide a software framework for astrophysical simulations, in which existing codes from different domains, such as stellar dynamics, stellar evolution, hydrodynamics and radiative transfer can be easily coupled.</p>\n\n<p>AMUSE is a community effort with the main development by the AMUSE team at Leiden Observatory under supervision of Simon Portegies Zwart.</p>\n", "discipline": ["Physics & Beyond"], "contributingOrganization": ["/organization/nlesc"], "id": "/software/amuse", "website": "http://amusecode.org/", "logo": "/images/software/amuse.png", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "title": "Archimate", "tagLine": "ArchiMate, an Open Group Standard, is an open and independent modelling language for enterprise architecture that is supported by different tool vendors and consulting firms.", "slug": "archimate", "downloadUrl": "http://www.opengroup.org/subjectareas/enterprise/archimate", "programmingLanguage": [""], "license": [], "documentationUrl": "http://www.opengroup.org/subjectareas/enterprise/archimate", "expertise": ["Information Integration"], "description": "<p>ArchiMate, an Open Group Standard, is an open and independent modelling language for enterprise architecture that is supported by different tool vendors and consulting firms. ArchiMate provides instruments to enable enterprise architects to describe, analyze and visualize the relationships among business domains in an unambiguous way. Farhad Arbab and Frank de Boer from CWIs Formal Methods group contributed to the design and implementation of the Archimate modelling language and developed techniques for formal analysis.</p>\n\n", "id": "/software/archimate", "@id": "http://software.esciencecenter.nl/software/archimate/", "discipline": ["eScience Methodology"], "logo": "https://www.cwi.nl/system/files/u207/Archimate-logo-website.jpg", "contributingOrganization": ["https://www.esciencecenter.nl/technology/organization/cwi"], "endorsedBy": [], "name": "ArchiMate", "website": "http://www.opengroup.org/subjectareas/enterprise/archimate", "nlescWebsite": "https://www.esciencecenter.nl/technology/software/archimate", "competence": ["Optimized Data Handling"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "title": "Autosubmit", "tagLine": "Versatile tool to manage Weather and Climate Experiments in diverse Supercomputing Environments", "slug": "autosubmit", "programmingLanguage": ["Python"], "status": "active", "expertise": ["Orchestrated Computing"], "owner": [{ "website": "https://www.bsc.es/", "name": "Barcelona Supercomputing Center (BSC)" }], "competence": ["Efficient Computing", "Optimized Data Handling"], "user": ["http://software.esciencecenter.nl/organization/nlesc"], "technologyTag": ["orchestrated computing", "workflow", "data assimilation"], "@id": "http://software.esciencecenter.nl/software/autosubmit/", "discipline": ["Environment & Sustainability"], "description": "<p>Autosubmit: a versatile tool to manage Weather and Climate Experiments in diverse Supercomputing Environments\nAutosubmit is a tool to create, manage and monitor experiments using\ncomputing clusters, HPC platforms and supercomputers remotely via ssh.</p>\n", "involvedOrganization": ["http://software.esciencecenter.nl/organization/nlesc"], "supportLevel": "advanced", "endorsedBy": ["/organization/knmi"], "name": "autosubmit", "license": ["gpl-3.0"], "id": "/software/autosubmit" }, { "schema": "http://software.esciencecenter.nl/schema/software", "tagLine": "A suite of c++ libraries for radio astronomy data processing.", "slug": "casacore", "codeRepository": "https://github.com/casacore/casacore", "user": ["/organization/astron", "/organization/nlesc", "/person/h.spreeuw", "/person/c.meijer"], "title": "Casacore", "competence": ["Optimized Data Handling"], "documentationUrl": "http://casacore.github.io/casacore", "status": "active", "dependency": ["/software/liblas"], "name": "Casacore", "owner": ["/organization/astron"], "programmingLanguage": ["C++"], "expertise": ["Handling Sensor Data"], "usedIn": ["/project/error-detection-and-error-localization"], "@id": "http://software.esciencecenter.nl/software/casacore/", "description": "<p>A suite of c++ libraries for radio astronomy data processing.</p>\n", "discipline": ["Physics & Beyond"], "contributingOrganization": ["/organization/astron"], "involvedOrganization": ["/organization/astron"], "website": "http://casacore.github.io/casacore", "license": ["gpl"], "id": "/software/casacore" }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2015-05-01", "contributor": ["/person/s.georgievska"], "tagLine": "A 3D web tool for interactive visualization of hierarchically clustered big data", "slug": "cclustera", "contactPerson": "/person/s.georgievska", "codeRepository": "http://github.com/NLeSC/CClusTera", "competence": ["Big Data Analytics"], "user": ["/organization/nlesc"], "title": "Cclustera", "discipline": ["eScience Methodology"], "status": "active", "supportLevel": "specialized", "name": "CClusTera", "owner": ["/organization/nlesc"], "programmingLanguage": ["JavaScript", "Python", "C++"], "expertise": ["Information Visualization", "Machine Learning"], "technologyTag": ["3D graphics", "Website"], "usedIn": ["/project/massive-biological-data-clustering-reporting-and-visualization-tools", "/project/3d-e-chem"], "@id": "http://software.esciencecenter.nl/software/cclustera/", "description": "<p>CClusTera enables interactive and web based 3D visualization of hierarchically clustered data. The application also enables colorizing points based on features other than their clusters.</p>\n\n<h1 id=\"why-cclustera\">Why CClusTera?</h1>\n\n<p>In many scientific domains data is hierarchically clustered based on similarity, primarily because of the large volume of data. A scientist would be then interested to view the clusters by expanding and collapsing the clusters, by loading data  up to a certain level in the hierarchy, or by colorizing the data based on features other than their clusters. This can provide new insights for domain research.</p>\n", "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "id": "/software/cclustera", "license": ["afl-3.0"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "title": "Cdo", "supportLevel": "advanced", "slug": "cdo", "programmingLanguage": ["FORTRAN"], "description": "<p>CDO is a collection of command line Operators to manipulate and analyse Climate and NWP model Data.\nSupported data formats are GRIB 1/2, netCDF 3/4, SERVICE, EXTRA and IEG. There are more than 600 operators available.</p>\n", "tagLine": "A collection of command line operators to manipulate and analyse climate and NWP model data.", "expertise": ["Information Retrieval"], "competence": ["Efficient Computing", "Optimized Data Handling"], "user": ["http://software.esciencecenter.nl/organization/knmi", "http://software.esciencecenter.nl/organization/nlesc"], "technologyTag": ["data analysis", "postprocessing"], "@id": "http://software.esciencecenter.nl/software/cdo/", "discipline": ["Environment & Sustainability"], "status": "active", "owner": [{ "website": "https://code.zmaw.de/", "name": "Max Planck Institute for Meteorology" }], "endorsedBy": ["http://software.esciencecenter.nl/organization/knmi"], "name": "cdo", "license": ["gpl-2.0"], "id": "/software/cdo" }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2014-10-08", "contributor": ["/person/n.drost", "/person/m.vanmeersbergen"], "tagLine": "3D Globe Visualization of NetCDF data.", "slug": "cesium-ncwms", "contactPerson": "/person/m.vanmeersbergen", "codeRepository": "https://github.com/NLeSC/Cesium-NcWMS", "user": ["/person/n.drost"], "title": "Cesium Ncwms", "competence": ["Big Data Analytics"], "status": "active", "dependency": ["/software/cesium"], "name": "Cesium-ncWMS", "owner": ["/organization/nlesc"], "programmingLanguage": ["JavaScript", "Java"], "expertise": ["Scientific Visualization"], "technologyTag": ["Visualization", "WebGL", "3D"], "usedIn": ["/project/ewatercycle"], "@id": "http://software.esciencecenter.nl/software/cesium-ncwms/", "description": "<p>Cesium (cesiumjs.org) based visualization using ncWMS to serve NetCDF data and D3 (d3js.org) to display graphs.\nA live running version of this software can be found at http://forecast.ewatercycle.org</p>\n\n<p><img src=\"https://github.com/NLeSC/Cesium-NcWMS/raw/master/DOC/images/ewa-saturation.png\" alt=\"logo\" title=\"Screenshot 1\" /></p>\n\n<p><img src=\"https://github.com/NLeSC/Cesium-NcWMS/raw/master/DOC/images/ewa-discharge.png\" alt=\"logo\" title=\"Screenshot 2\" /></p>\n", "discipline": ["Environment & Sustainability"], "contributingOrganization": ["/organization/nlesc"], "id": "/software/cesium-ncwms", "license": ["apache-2.0"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": null, "contributor": null, "tagLine": "3D Globe Visualization", "slug": "cesium", "contactPerson": null, "codeRepository": "https://github.com/AnalyticalGraphicsInc/cesium", "user": ["/person/m.vanmeersbergen"], "title": "Cesium", "dependencyOf": ["/software/cesium-ncwms", "/software/common-sense"], "competence": ["Optimized Data Handling", "Efficient Computing"], "status": "active", "name": "Cesium", "owner": null, "programmingLanguage": ["JavaScript"], "expertise": ["Scientific Visualization"], "technologyTag": ["Visualization", "WebGL", "3D"], "usedIn": ["/project/ewatercycle"], "@id": "http://software.esciencecenter.nl/software/cesium/", "description": "<p>Cesium is a JavaScript library for creating 3D globes and 2D maps in a web browser without a plugin. It uses WebGL for hardware-accelerated graphics, and is cross-platform, cross-browser, and tuned for dynamic-data visualization.</p>\n\n<p><img src=\"https://github.com/AnalyticalGraphicsInc/cesium/wiki/logos/Cesium_Logo_Color.jpg\" alt=\"logo\" title=\"Cesium Logo\" /></p>\n", "discipline": ["Environment & Sustainability"], "contributingOrganization": null, "id": "/software/cesium", "license": ["apache-2.0"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "contributor": ["/person/s.verhoeven", { "linkedInUrl": "https://nl.linkedin.com/in/ross-mcguire-71457523", "affiliation": ["/organization/radboud.university.nijmegen"], "name": "Ross McGuire" }], "tagLine": "Packer template to create Vagrant box with Knime inside", "slug": "chemical-analytics-platform", "id": "/software/chemical-analytics-platform", "contactPerson": "/person/s.verhoeven", "codeRepository": "https://github.com/NLeSC/Chemical-Analytics-Platform", "startDate": "2015-08-05", "dependencyOf": ["/software/3d-e-chem-vm"], "competence": ["Optimized Data Handling"], "documentationUrl": "https://github.com/NLeSC/Chemical-Analytics-Platform/wiki", "supportLevel": "specialized", "name": "Chemical Analytics Virtual Machine", "title": "Chemical Analytics Platform", "owner": ["/organization/nlesc", "/organization/radboud.university.nijmegen", "/organization/vua"], "downloadUrl": "https://atlas.hashicorp.com/nlesc/boxes/chemical-analytics-platform", "programmingLanguage": ["YAML"], "status": "active", "expertise": ["Reproducible Research"], "technologyTag": ["Knime", "Vagrant", "Packer"], "usedIn": ["/project/3d-e-chem"], "@id": "http://software.esciencecenter.nl/software/chemical-analytics-platform/", "description": "<p>Scripts to create a Vagrant box using packer and ansible.</p>\n\n<p>Vagrant box is a Virtual Machine in Virtualbox format.</p>\n\n<p>Start virtual machine with</p>\n\n<div class=\"highlighter-rouge\"><pre class=\"highlight\"><code>vagrant init nlesc/chemical-analytics-platform\nvagrant up\n</code></pre>\n</div>\n", "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/radboud.university.nijmegen", "/organization/vua"], "endorsedBy": ["/organization/nlesc"], "website": "https://github.com/NLeSC/Chemical-Analytics-Platform", "license": ["apache-2.0"], "discipline": ["eScience Methodology"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "title": "Collatex", "tagLine": "Software for Collating Textual Sources", "slug": "collatex", "programmingLanguage": ["JavaScript", "Python", "Java"], "codeRepository": "https://github.com/interedition/collatex/", "expertise": ["Text Mining"], "description": "<p>CollateX is software that</p>\n\n<ul>\n  <li>reads multiple (\u2265 2) versions of a text, splitting each version into parts (tokens) to be compared,</li>\n  <li>identifies similarities of and differences between the versions (including moved/transposed segments) by aligning tokens, and</li>\n  <li>outputs the alignment results in a variety of formats for further processing, for instance</li>\n  <li>to support the production of a critical apparatus or the stemmatical analysis of a text\u2019s genesis.</li>\n</ul>\n\n<p>It resembles software used to compute differences between files (e.g. diff) or tools for sequence alignment which are commonly used in Bioinformatics. While CollateX shares some of the techniques and algorithms with those tools, it mainly aims for a flexible and configurable approach to the problem of finding similarities and differences in texts, sometimes trading computational soundness or complexity for the user\u2019s ability to influence results.</p>\n\n<p>As such it is primarily designed for use cases in disciplines like Philology or \u2013 more specifically \u2013 the field of Textual Criticism where the assessment of findings is based on interpretation and therefore can be supported by computational means but is not necessarily computable.</p>\n", "@id": "http://software.esciencecenter.nl/software/collatex/", "competence": ["Big Data Analytics"], "discipline": ["Humanities & Social Sciences"], "status": "active", "involvedOrganization": ["/organization/huygens"], "id": "/software/collatex", "name": "CollateX", "license": ["gpl-3.0"], "endorsedBy": ["/organization/huygens"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2014-09-11", "contributor": ["/person/c.martinez", "/person/b.weel", "/person/j.borgdorff", { "githubUrl": "https://github.com/erikvullings", "affiliation": ["/organization/tno"], "name": "Erik Vullings" }], "tagLine": "User-friendly web application for showing (GIS) data on a map.", "slug": "common-sense", "id": "/software/common-sense", "contactPerson": "/person/c.martinez", "codeRepository": "https://github.com/TNOCS/csWeb/", "user": ["/organization/nlesc", "/organization/tno"], "title": "Common Sense", "dependencyOf": null, "competence": ["Big Data Analytics"], "documentationUrl": "https://github.com/TNOCS/csWeb/wiki/Getting-started", "supportLevel": "specialized", "dependency": ["/software/cesium"], "name": "Common Sense", "owner": ["/organization/tno"], "programmingLanguage": ["JavaScript", "TypeScript"], "status": "active", "expertise": ["Information Visualization"], "technologyTag": ["GIS"], "usedIn": ["/project/simcity"], "@id": "http://software.esciencecenter.nl/software/common-sense/", "description": "<p>csWeb, or the Common Sense Web application, is an intuitive open source web-based GIS application, providing casual users as well as business analysists and information manageners with a powerful tool to perform spatial analysis. It has a strong focus on usability and connectivity, be it connecting and sharing information with other users or connecting to services or calculation simulations and models</p>\n", "logo": "/images/software/common-sense.png", "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/tno"], "endorsedBy": ["/organization/nlesc"], "website": "https://tnocs.github.io/csWeb/", "license": ["mit"], "discipline": ["eScience Methodology"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "tagLine": "CompLearn is a suite of simple-to-use utilities to apply compression techniques on discovering and learning patterns.", "slug": "complearn", "codeRepository": "https://github.com/rudi-cilibrasi/libcomplearn", "badges": null, "title": "Complearn", "dependencyOf": null, "competence": ["Big Data Analytics"], "documentationUrl": "http://complearn.org/documentation.html", "dependency": null, "name": "CompLearn", "downloadUrl": "http://complearn.org/download.html", "programmingLanguage": ["C"], "expertise": ["Machine Learning", "Information Retrieval"], "technologyTag": ["PatternDiscovery"], "usedIn": null, "@id": "http://software.esciencecenter.nl/software/complearn/", "description": "<p>This powerful approach can mine patterns in completely different domains. It can classify musical styles of pieces of music and identify unknown composers. It can identify the language of a text. It can discover the relationships between species of life and even the origin of new unknown viruses such as SARS. In fact, this method requires no background knowledge about any particular classification.</p>\n\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/cwi"], "id": "/software/complearn", "website": "http://complearn.org", "license": null, "endorsedBy": [] }, { "schema": "http://software.esciencecenter.nl/schema/software", "tagLine": "Apache CouchDB\u2122 is a database that uses JSON for documents, JavaScript for MapReduce indexes, and regular HTTP for its API.", "slug": "couchdb", "contactPerson": "/person/j.borgdorff", "codeRepository": "https://github.com/apache/couchdb", "license": ["apache-2.0"], "user": ["/person/j.borgdorff", "/person/b.weel"], "startDate": "2008-03-28,", "dependencyOf": ["/software/docker-couch-admin", "/software/picas"], "competence": ["Optimized Data Handling"], "documentationUrl": "http://docs.couchdb.org/en/stable/", "status": "active", "dependency": ["/software/picas"], "name": "Apache CouchDB\u2122", "title": "Couchdb", "supportLevel": "basic", "downloadUrl": "http://couchdb.apache.org/#download", "programmingLanguage": ["JavaScript", "Python", "Ruby", "Erlang"], "expertise": ["Databases"], "technologyTag": ["NoSQL database", "DBMS"], "usedIn": ["/project/simcity"], "@id": "http://software.esciencecenter.nl/software/couchdb/", "description": "<p>CouchDB is a database that completely embraces the web. Store your data with\nJSON documents. Access your documents and query your indexes with your web\nbrowser, via HTTP. Index, combine, and transform your documents with\nJavaScript. CouchDB works well with modern web and mobile apps. You can even\nserve web apps directly out of CouchDB. And you can distribute your data, or\nyour apps, efficiently using CouchDB\u2019s incremental replication. CouchDB\nsupports master-master setups with automatic conflict detection.</p>\n", "discipline": ["eScience Methodology"], "website": "http://couchdb.apache.org", "logo": "/images/software/couchdb.png", "id": "/software/couchdb" }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2016-03-17", "contributor": ["/person/j.vanderzwaan", "/person/l.buitinck", "/person/p.bos"], "tagLine": "A Gibbs sampler that implements Cross-Perspective Topic Modeling", "slug": "cptm", "id": "/software/cptm", "contactPerson": "/person/j.vanderzwaan", "codeRepository": "https://github.com/NLeSC/cptm", "user": ["/organization/nlesc"], "title": "Cptm", "dependencyOf": null, "competence": ["Big Data Analytics"], "documentationUrl": null, "doi": "http://dx.doi.org/10.5281/zenodo.47756", "supportLevel": "specialized", "dependency": null, "name": "Cross-perspective Topic Modeling", "owner": ["/organization/nlesc", "/organization/uva"], "programmingLanguage": ["Python", "Cython"], "status": "inactive", "expertise": ["Text Mining"], "technologyTag": ["Topic Modeling", "Latent Dirichlet Allocation", "Gibbs Sampler"], "usedIn": ["/project/dilipad"], "@id": "http://software.esciencecenter.nl/software/cptm/", "description": "<p>A Gibbs sampler that implements Cross-Perspective Topic Modeling, as described in</p>\n\n<blockquote>\n  <p>Fang, Si, Somasundaram, &amp; Yu (2012). Mining Contrastive Opinions on Political Texts using Cross-Perspective Topic Model. In proceedings of the fifth ACM international conference on Web Search and Data Mining. http://dl.acm.org/citation.cfm?id=2124306</p>\n</blockquote>\n\n<p>The cross-perspective topic model is an extended form of Latent Dirichlet Allocation\n(LDA). Topics are learned by doing LDA on the topic words (nouns) in\nthe corpus. Opinions are learned from a separate LDA process using opinion words\n(adjectives, verbs, and adverbs). A topic is a probability distribution\nover topic words. An opinion is a probability distribution over opinion words.\nWhile the topics are shared among the entire corpus, opinions depend on the perspective\na document belongs to. A document can only belong to a single perspective, and the\ndivision of the corpus in perspectives is fixed and must be known in advance.</p>\n\n<p>The imaginary process for generating documents is: one first selects a topic,\nbased on the topic mixture of that document. Then a topic word is drawn from the\ntopic. This procedure is repeated until all topic words have been selected.\nNext, one selects an opinion based on the frequency of topic words associated\nwith the topics in the document. The more words associated with a certain topic,\nthe higher the chance that the corresponding opinion will be selected. The\ncontents of the opinion (i.e., probabilities of opinion words) depend on the\ngenerator\u2019s perspective. Next, an opinion word is drawn from the selected opinion.\nThis procedure is again repeated until all opinion words have been selected.</p>\n", "logo": null, "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/uva"], "nlescWebsite": null, "endorsedBy": ["/organization/nlesc"], "website": null, "license": ["apache-2.0"], "discipline": ["Humanities & Social Sciences"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "title": "Cr Tools", "contributor": [{ "affiliation": ["/organization/astron"], "name": "L. B\u00e4hren" }], "tagLine": "Reduction of Cosmic Ray data.", "slug": "cr-tools", "programmingLanguage": ["C++"], "contactPerson": null, "description": "<p>Reduction of Cosmic Ray data.</p>\n", "@id": "http://software.esciencecenter.nl/software/cr-tools/", "dependencyOf": ["/software/pycrtools"], "discipline": ["Physics & Beyond"], "contributingOrganization": ["/organization/astron"], "website": "http://www.lofar.org/wiki/doku.php?id=public:user_software:cr-tools", "name": "CR-Tools", "id": "/software/cr-tools" }, { "schema": "http://software.esciencecenter.nl/schema/software", "tagLine": "large-eddy simulation code designed for studies of the physics of the atmospheric boundary layer", "slug": "dales", "codeRepository": "https://github.com/dalesteam/dales", "user": ["http://software.esciencecenter.nl/organization/nlesc"], "title": "Dales", "competence": ["Efficient Computing"], "status": "active", "supportLevel": "advanced", "name": "dales", "owner": [{ "name": "TU Delft" }], "programmingLanguage": ["FORTRAN"], "expertise": ["High Performance Computing"], "technologyTag": ["Simulation"], "@id": "http://software.esciencecenter.nl/software/dales/", "description": "<p>DALES is a large-eddy simulation code designed for studies of the physics of the atmospheric boundary layer, including convective and stable boundary layers as well as cloudy boundary layers. In addition, DALES can be used for studies of more specific cases, such as flow over sloping or heterogeneous terrain, and dispersion of inert and chemically active\nspecies.</p>\n", "discipline": ["Environment & Sustainability"], "contributingOrganization": ["http://software.esciencecenter.nl/organization/knmi"], "involvedOrganization": ["http://software.esciencecenter.nl/organization/nlesc", "http://software.esciencecenter.nl/organization/knmi"], "endorsedBy": ["http://software.esciencecenter.nl/organization/knmi", "http://software.esciencecenter.nl/organization/tudelft"], "license": ["gpl-3.0"], "id": "/software/dales" }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2014-03-1", "contributor": ["/person/r.goncalves"], "tagLine": "Technology of Attachment to a DBMS of large file repositories.", "slug": "datavaults", "contactPerson": "/person/r.goncalves", "codeRepository": "https://github.com/MonetDB/data-vaults", "user": ["/person/r.goncalves"], "title": "Datavaults", "dependencyOf": ["/software/monetdb"], "competence": ["Optimized Data Handling"], "documentationUrl": "https://www.monetdb.org/Documentation/Extensions/DataVaults", "doi": null, "status": "active", "dependency": null, "logo": null, "name": "DataVaults", "supportLevel": "specialized", "downloadUrl": "https://www.monetdb.org/Downloads", "programmingLanguage": ["C"], "expertise": ["Databases"], "technologyTag": ["Scientific Databases", "In-situ data access"], "usedIn": ["/project/big-data-analytics-in-the-geo-spatial-domain", "/project/3d-geospatial-data-exploration-for-modern-risk-management-systems", "/project/massive-point-clouds-for-esciences"], "@id": "http://software.esciencecenter.nl/software/datavaults/", "description": "<p>A data vault provides a symbiosis between a DBMS and existing file-based repositories.\nIt keeps data in its original format while scalable processing functionality is offered\nthrough the DBMS. The concept was designed by the CWI Database group, currently the\nNetherlands eScience center works closely with CWI Database group to improve it and\nextend it.</p>\n\n<h1 id=\"why-datavaults\">Why DataVaults?</h1>\n\n<p>DataVaults provides transparent access to all data kept in the file repository\nthrough a tabular or array-based interface abstraction. The in-situ data access\nis possible due to the large amounts of metadata (data of data) existent on file\nformats such as NetCDF, LAS/LAZ, MSEEDS, HDF5, etc. Such metadata is used for\neffective data skipping, but also to collect data insights, e.g. summaries and\nsamples, without having to process the entire data set.</p>\n\n<p>Such an approach gives the user the opportunity to continue performing data\ncuration activities since the main data archive is the file-based repository,\ni.e., the raw data is kept outside of the DBMS.</p>\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/cwi", "/organization/monetdb", "/organization/jhu"], "nlescWebsite": null, "id": "/software/datavaults", "website": "https://www.monetdb.org/Documentation/Extensions/DataVaults", "license": ["mpl-2.0"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2015-01-01", "contributor": null, "tagLine": "3D modeling hydrodynamics suite", "slug": "delft3d", "contactPerson": null, "user": null, "title": "Delft3d", "discipline": ["Environment & Sustainability"], "status": "active", "supportLevel": "specialized", "name": "Delft3D", "endorsedBy": ["/organization/deltares"], "owner": [{ "name": "Deltares" }], "programmingLanguage": null, "expertise": ["Data Assimilation"], "technologyTag": null, "usedIn": null, "@id": "http://software.esciencecenter.nl/software/delft3d/", "description": "<p><img src=\"https://oss.deltares.nl/image/image_gallery?uuid=140ad2b9-d363-44ba-a97b-3580a2a7259c&amp;groupId=183920&amp;t=1448057841510\" alt=\"Screenshot of Delft3D\" title=\"Screenshot\" /> \nDelft3D is a world leading 3D modeling suite to investigate hydrodynamics, sediment transport and morphology and water quality for fluvial, estuarine and coastal environments. As per 1 January 2011, the Delft3D flow (FLOW), \nmorphology (MOR) and waves (WAVE) modules are available in open source.\nThe software is used and has proven his capabilities on many places around the world, like the Netherlands, USA, Hong Kong, Singapore, Australia, Venice, etc. The software is continuously improved and developed with innovating \nadvanced modelling techniques as consequence of the research work of our institute and to stay world leading.</p>\n", "contributingOrganization": ["/organization/deltares"], "involvedOrganization": ["/organization/deltares"], "id": "/software/delft3d", "license": ["custom"], "competence": ["Efficient Computing"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2015-01-01", "contributor": null, "tagLine": "integrated modeling environment", "slug": "deltashell", "contactPerson": null, "user": null, "title": "Deltashell", "discipline": ["Environment & Sustainability"], "status": "active", "supportLevel": "specialized", "name": "DeltaShell", "endorsedBy": ["/organization/deltares"], "owner": [{ "name": "Deltares" }], "programmingLanguage": ["C#"], "expertise": ["Data Assimilation"], "technologyTag": null, "usedIn": null, "@id": "http://software.esciencecenter.nl/software/deltashell/", "description": "<p><img src=\"http://oss.deltares.nl/image/image_gallery?img_id=345503&amp;t=1383298647214\" alt=\"Screenshot of Delta Shell\" title=\"Screenshot\" /> Delta Shell is a free integrated modeling environment with a focus to setup, configure, run and analyze results of the integrated environmental models used to simulate water, soil and the subsurface processes. The software \ncomponents available within Delta Shell are easy to reuse separately, or as a part of an integrated environment. The software can run in a graphical user interface or a command-line mode. Most of the components are developed using \nthe C# programming language.</p>\n\n", "contributingOrganization": ["/organization/deltares"], "involvedOrganization": ["/organization/deltares"], "id": "/software/deltashell", "license": ["freeware"], "competence": ["Efficient Computing"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2013-06-18", "contributor": ["/person/j.spaaks"], "tagLine": "Differential Evolution global optimization algorithm, with Metropolis for uncertainty estimation", "slug": "differential-evolution", "contactPerson": "/person/j.spaaks", "codeRepository": "https://github.com/NLeSC/DifferentialEvolution", "user": ["/organization/nlesc", "/person/j.spaaks"], "title": "Differential Evolution", "competence": ["Big Data Analytics"], "documentationUrl": null, "supportLevel": "specialized", "dependency": ["JFreeChart", "D3"], "name": "Differential Evolution", "description": "<p>Java implementation of the Differential Evolution algorithm by Storn &amp; Price.</p>\n\n<p>Additionally uses Metropolis algorithm to estimate the parameter uncertainty.</p>\n\n<p>The software includes some simple\nvisualizations using JFreeChart (Java) as well as some simple D3.js (JavaScript).</p>\n\n<p>Standard plotting routines include:</p>\n\n<ol>\n  <li>marginal parameter histograms;</li>\n  <li>matrix of 2-D parameter correlations (scatter);</li>\n  <li>matrix of 2-D parameter correlations (heatmap);</li>\n  <li>parameter evolution scatter;</li>\n  <li>objective score evolution scatter.</li>\n</ol>\n\n<p>Currently, the Differential Evolution algorithm can be used to optimize any one of 6 models:</p>\n\n<table>\n  <thead>\n    <tr>\n      <th>index</th>\n      <th>Java model class name</th>\n      <th>number of parameters</th>\n      <th>description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>CubicModel</td>\n      <td>4</td>\n      <td>polynomial</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>DoubleNormalModel</td>\n      <td>1</td>\n      <td>two Gaussians, benchmark check on the accuracy of the Metropolis part</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>LinearDynamicModel</td>\n      <td>1</td>\n      <td>draining linear tank</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>RastriginModel</td>\n      <td>2</td>\n      <td>benchmark model with response surface containing many local minima</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>RosenbrockModel</td>\n      <td>2</td>\n      <td>benchmark model with response surface containing many local minima, large insensitive areas, and curved ridges</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>SingleNormalModel</td>\n      <td>1</td>\n      <td>simpler version of the DoubleNormalModel</td>\n    </tr>\n  </tbody>\n</table>\n\n", "owner": ["/organization/nlesc", "/person/j.spaaks"], "programmingLanguage": ["Java", "JavaScript"], "expertise": ["Information Visualization", "Scientific Visualization", "Machine Learning"], "technologyTag": ["Visualization", "Global Optimization", "Uncertainty Estimation", "Parameter Estimation", "Calibration"], "usedIn": null, "@id": "http://software.esciencecenter.nl/software/differential-evolution/", "license": ["apache-2.0"], "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "id": "/software/differential-evolution", "website": "https://github.com/NLeSC/DifferentialEvolution", "status": "inactive", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "contributor": ["/person/j.borgdorff"], "tagLine": "Configures a web service using angular-schema-form and CouchDB", "slug": "docker-couch-admin", "id": "/software/docker-couch-admin", "contactPerson": "/person/j.borgdorff", "codeRepository": "https://github.com/NLeSC/docker-couch-admin", "license": ["apache-2.0"], "user": ["/organization/nlesc"], "title": "Docker Couch Admin", "dependencyOf": null, "competence": ["Efficient Computing"], "status": "inactive", "doi": "http://dx.doi.org/10.5281/zenodo.61301", "supportLevel": "specialized", "dependency": ["/software/couchdb"], "name": "Docker Couch Admin", "owner": ["/organization/nlesc"], "downloadUrl": "https://hub.docker.com/r/nlesc/couch-admin/", "programmingLanguage": ["JavaScript", "HTML", "Dockerfile"], "expertise": ["Information Integration"], "technologyTag": ["Docker", "CouchDB", "AngularJS", "JSON Schema"], "usedIn": ["/project/simcity"], "@id": "http://software.esciencecenter.nl/software/docker-couch-admin/", "description": "<p>A Docker image with a customisable CouchDB administration console, using\nangular-schema-form. All configuration is readable from the CouchDB database.</p>\n\n<p>This is specifically used to have dynamic but shared configuration in a set of\nDocker containers. The configuration is accessible from a web interface.</p>\n", "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "endorsedBy": ["/organization/nlesc"], "startDate": "2016-01-07", "discipline": ["eScience Methodology"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2013-04-12", "contributor": ["/person/r.vannieuwpoort"], "tagLine": "This tool can convert and visualize radio astronomy measurement sets, as well as most LOFAR intermediate data producs. It also does RFI mitigation.", "slug": "eastroviz", "contactPerson": "/person/r.vannieuwpoort", "codeRepository": "https://github.com/NLeSC/eAstroViz", "user": ["/person/r.vannieuwpoort"], "title": "Eastroviz", "dependencyOf": null, "competence": ["Optimized Data Handling"], "status": "active", "supportLevel": "specialized", "dependency": null, "name": "eAstroViz", "owner": ["/organization/nlesc"], "programmingLanguage": ["Java"], "expertise": ["Handling Sensor Data"], "technologyTag": ["Library"], "usedIn": ["/project/beyond-the-data-explosion"], "@id": "http://software.esciencecenter.nl/software/eastroviz/", "description": "<p>Visualization of the Netherlands eScience center eAstronomy project.</p>\n\n<p>This tool can convert and visualize radio astronomy measurement sets,\nas well as most LOFAR intermediate data producs, such as raw voltages,\nfiltered data and beam formed data. In addition, this tool can perform\nRFI mitigation.</p>\n", "discipline": ["Physics & Beyond", "eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/astron"], "id": "/software/eastroviz", "license": ["apache-2.0"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "title": "Ec Earth", "tagLine": "Atmosphere-ocean general circulation model", "slug": "ec-earth", "programmingLanguage": ["FORTRAN", "C++"], "status": "active", "expertise": ["Distributed Computing"], "owner": [{ "website": "http://www.ec-earth.org", "name": "The EC-Earth consortium" }], "competence": ["Efficient Computing", "Optimized Data Handling"], "user": ["http://software.esciencecenter.nl/organization/nlesc"], "technologyTag": ["Simulation", "Modeling"], "@id": "http://software.esciencecenter.nl/software/ec-earth/", "discipline": ["Environment & Sustainability"], "description": "<p>Earth System Models (ESMs), such as EC-Earth, are currently the only way of providing society with information on the future climate. EC-Earth generates reliable in-house predictions and projections of global climate change, which are a prerequisite to support the development of national adaptation and mitigation strategies.</p>\n\n<p>EC-Earth is developed as part of a Europe-wide consortium thus promoting international cooperation and access to wide knowledge and data base. It further enables fruitful interactions between academic institutions and the European climate impact community.</p>\n\n<p>EC-Earth made successful contributions to international climate change projections such as CMIP5. Ongoing development by the consortium will ensure that increasingly more reliable projections can be offered to decision and policy makers at regional, national and international levels.</p>\n\n<p>A new version of EC-Earth is under development and the consortium plans to participate in CMIP6.</p>\n\n<p>EC-Earth is a Europe-wide consortium and welcomes additional partners.</p>\n\n<p>The consortium is lead by a Steering Group planning and coordinating the development of the model and the consortium.</p>\n", "contributingOrganization": ["http://software.esciencecenter.nl/organization/knmi"], "supportLevel": "advanced", "involvedOrganization": ["http://software.esciencecenter.nl/organization/nlesc"], "endorsedBy": ["http://software.esciencecenter.nl/organization/knmi"], "name": "EC-Earth", "license": ["Unknown"], "id": "/software/ec-earth" }, { "schema": "http://software.esciencecenter.nl/schema/software", "contributor": ["/person/s.verhoeven"], "tagLine": "Visualize & annotate GPS measurements of bird movements", "slug": "eecology-annotation", "contactPerson": "/person/s.verhoeven", "doi": "http://dx.doi.org/10.5281/zenodo.45200", "license": ["apache-2.0"], "user": ["/organization/uva"], "title": "Eecology Annotation", "codeRepository": "https://github.com/NLeSC/eEcology-Annotation-WS", "competence": ["Optimized Data Handling"], "status": "active", "supportLevel": "specialized", "dependency": ["/software/extjs-datetime"], "name": "eEcology Annotation Tool", "owner": ["/organization/nlesc", "/organization/uva", "/person/s.verhoeven"], "downloadUrl": "https://github.com/NLeSC/eEcology-Annotation-WS/releases", "programmingLanguage": ["Python", "JavaScript"], "expertise": ["Handling Sensor Data", "Information Retrieval", "Scientific Visualization", "Databases"], "technologyTag": ["GIS", "Website"], "usedIn": ["/project/eecology"], "@id": "http://software.esciencecenter.nl/software/eecology-annotation/", "description": "<p>Rich web interface to virtualize &amp; annotate GPS measurements.\nThe visualization has been applied to <a href=\"http://www.uva-bits.nl/system\">uva-bits tracking devices</a> , but can be used for any spatial-temporal data.\nThe annotation tool is a <a href=\"http://uva-bits.nl/virtual-lab\">Virtual lab</a> of the uva-bits project.</p>\n\n<p><img src=\"https://github.com/NLeSC/eEcology-Annotation-UI/raw/master/resources/screenshot.png\" alt=\"Screenshot of annotation application\" title=\"Screenshot\" /></p>\n\n<p>The production web application is hosted at SurfSARA and requires membership of the UvA-BiTS community.\nA demo available <a href=\"http://nlesc.github.io/eEcology-Annotation-UI/demo/demo.html\">here</a> or without annotations <a href=\"http://nlesc.github.io/eEcology-Annotation-UI/demo/demo-na.html\">here</a>.</p>\n", "discipline": ["Environment & Sustainability"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/uva", "/organization/surfsara"], "id": "/software/eecology-annotation", "website": "https://services.e-ecology.sara.nl/aws/", "startDate": "2013-03-21", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2013-02-15", "contributor": ["/person/s.verhoeven"], "tagLine": "Calendar overview with daily statistics of GPS-tracker", "slug": "eecology-tracker-calendar", "contactPerson": "/person/s.verhoeven", "codeRepository": "https://github.com/NLeSC/eEcology-script-wrapper", "competence": ["Optimized Data Handling"], "user": ["/organization/uva"], "title": "Eecology Tracker Calendar", "discipline": ["Environment & Sustainability"], "status": "active", "supportLevel": "specialized", "name": "eEcology Tracker calendar", "owner": ["/organization/nlesc", "/organization/uva", "/person/s.verhoeven"], "programmingLanguage": ["Python"], "expertise": ["Handling Sensor Data", "Information Retrieval", "Scientific Visualization", "Databases"], "technologyTag": ["GIS", "Website"], "usedIn": ["/project/eecology"], "@id": "http://software.esciencecenter.nl/software/eecology-tracker-calendar/", "description": "<p>The tracker calendar shows daily statistics or metrics of tracker as a calendar heatmap. It can be used to find days when something interesting happened or to find repeating patterns.</p>\n\n<p><img src=\"/images/eecology-tracker-calendar.png\" alt=\"Screenshot of tracker calendar\" title=\"Screenshot\" /></p>\n\n<p>The following metrics of a tracker are calculated for each day:</p>\n\n<ul>\n  <li>Nr. of GPS measurements</li>\n  <li>Nr. of accelerometer measurements</li>\n  <li>2D distance travelled (km): Distance of line which consists of GPS measurements from midnight till midnight, altitude is ignored.</li>\n  <li>Maximum altitude (m): Highest absolute altitude</li>\n  <li>Average altitude (m): Average absolute altitude</li>\n  <li>Minimum altitude (m): Lowest absolute altitude</li>\n  <li>Maximum temperature (\u00b0C)</li>\n  <li>Average temperature (\u00b0C)</li>\n  <li>Minimum temperature (\u00b0C)</li>\n  <li>Minimum voltage battery (V): Lowest battery voltage</li>\n  <li>Maximum interval between GPS measurements (hh:mm:ss)</li>\n  <li>Minimum interval between GPS measurements (hh:mm:ss)</li>\n</ul>\n\n<p>The color range can be clipped to find outliers.</p>\n", "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/uva", "/organization/surfsara"], "id": "/software/eecology-tracker-calendar", "website": "https://public.e-ecology.sara.nl/sw/tool/calendar/", "license": ["apache-2.0"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2014-06-06", "contributor": ["/person/n.drost"], "tagLine": "Web-based visualization for the eWaterCycle project", "slug": "ewaterleaf", "contactPerson": "/person/n.drost", "codeRepository": "https://github.com/eWaterCycle/eWaterleaf", "title": "Ewaterleaf", "competence": ["Big Data Analytics"], "status": "inactive", "supportLevel": "basic", "name": "eWaterLeaf", "owner": ["/organization/nlesc"], "programmingLanguage": ["JavaScript"], "expertise": ["Scientific Visualization"], "technologyTag": ["Website"], "@id": "http://software.esciencecenter.nl/software/ewaterleaf/", "description": "<p>eWaterLeaf is a simple web-based visualization for the eWaterCycle project. It relies heavily on the Leaflet Javascript library, and ncWMS Web Map Service implementation.</p>\n\n<p>eWaterLeaf mostly serves as an exploration tool for the data generated by the PCRGLOB-WB model used in the eWaterCycle project, but it should work with any dataset compatible with ncWMS (NetCDF-CF files).</p>\n", "discipline": ["Environment & Sustainability"], "contributingOrganization": ["/organization/nlesc"], "id": "/software/ewaterleaf", "license": ["apache-2.0"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2013-08-23", "contributor": ["/person/s.verhoeven"], "tagLine": "DateTime form input field for ExtJS", "slug": "extjs-datetime", "contactPerson": "/person/s.verhoeven", "codeRepository": "https://github.com/NLeSC/ExtJS-DateTime", "user": ["/organization/uva"], "title": "Extjs Datetime", "dependencyOf": ["/software/eecology-annotation"], "competence": ["Optimized Data Handling"], "status": "active", "supportLevel": "specialized", "name": "ExtJS-DateTime", "owner": ["/organization/nlesc", "/organization/uva"], "programmingLanguage": ["JavaScript"], "expertise": ["Handling Sensor Data", "Information Retrieval", "Scientific Visualization", "Databases"], "technologyTag": ["Web UI component", "ExtJS"], "usedIn": ["/project/eecology"], "@id": "http://software.esciencecenter.nl/software/extjs-datetime/", "description": "<p>DateTime form input field for <a href=\"https://www.sencha.com/products/extjs/\">ExtJS</a> JavaScript framework.</p>\n\n<p>ExtJS had a date input field and a time input field, this field combines them into a single field.</p>\n", "discipline": ["Environment & Sustainability"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/uva", "/organization/surfsara"], "id": "/software/extjs-datetime", "website": "https://github.com/NLeSC/ExtJS-DateTime", "license": ["apache-2.0"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2015-06-01", "contributor": ["/person/a.kuzniar", { "githubUrl": "https://github.com/rajaram5", "affiliation": ["/organization/lumc"], "name": "Rajaram Kaliyaperuma" }, { "linkedInUrl": "http://www.linkedin.com/in/luizolavo", "affiliation": ["/organization/dtl"], "name": "Luiz Olavo Bonino da Silva Santos" }], "tagLine": "FAIR Data Point Metadata Service", "slug": "fairdatapoint", "id": "/software/fairdatapoint", "contactPerson": "/person/a.kuzniar", "codeRepository": "https://github.com/NLeSC/ODEX-FAIRDataPoint", "user": ["/person/a.kuzniar", "/organization/nlesc", "/organization/lumc", "/organization/wur"], "title": "Fairdatapoint", "dependencyOf": null, "competence": ["Optimized Data Handling"], "documentationUrl": null, "supportLevel": "specialized", "dependency": null, "name": "FAIR Data Point", "owner": ["/organization/nlesc"], "downloadUrl": "https://github.com/NLeSC/ODEX-FAIRDataPoint", "programmingLanguage": ["Python", "Java"], "status": "active", "expertise": ["Linked Data", "Information Integration"], "technologyTag": ["FAIR Data", "Linked Data", "Semantic Web", "RDF", "JSON-LD", "Turtle", "RDF/XML", "N-Triples", "DCAT", "Dublin Core metadata", "RESTful API"], "usedIn": ["/project/odex4all", "/project/candygene"], "@id": "http://software.esciencecenter.nl/software/fairdatapoint/", "description": "<p>FAIR Data Point (FDP) is one of the components of the FAIR Data e-infrastructure. FDP enables both i) the data owners to expose data sets in compliance with the <a href=\"http://www.force11.org/group/fairgroup/fairprinciples\">FAIR Data Guiding Principles</a> and ii) the data users to discover more information about available data sets. Specifically, the FDP addresses the first facet of the FAIRness, namely the findability or discoverability of data, by providing metadata at four complementary levels: about FDP itself, data catalog(s), data set(s) including available distribution(s). The FDP software has been developed as a stand-alone Web application in both Python and Java languages.</p>\n\n", "logo": null, "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/lumc", "/organization/dtl"], "nlescWebsite": "https://www.esciencecenter.nl/technology/software/fairdatapoint", "endorsedBy": ["/organization/nlesc"], "website": "http://fdp.biotools.nl:8080", "license": ["apache-2.0"], "discipline": ["Life Sciences & eHealth", "eScience Methodology"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "tagLine": "A Software Architecture and Framework for building HEP Data Processing Applications.", "slug": "gaudi", "@id": "http://software.esciencecenter.nl/software/gaudi/", "description": "<p>The Toolkit for Data Modeling with ROOT allows for modeling probability distributions in a compact and abstract way.</p>\n", "programmingLanguage": ["C++"], "user": ["/organization/nikhef"], "title": "Gaudi", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nikhef"], "involvedOrganization": ["/organization/nikhef"], "name": "Gaudi", "id": "/software/gaudi" }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2006-11-10", "contributor": [{ "githubUrl": "https://github.com/scottleedavis", "affiliation": ["/organization/uva"], "name": "Scott Lee Davis" }, "/person/j.spaaks"], "tagLine": "Export data from MATLAB to GoogleEarth's KML format.", "slug": "google-earth-toolbox-for-matlab", "contactPerson": "/person/j.spaaks", "codeRepository": "https://github.com/scottleedavis/googleearthtoolbox/", "user": ["/person/j.spaaks", { "name": "Scott Lee Davis" }], "title": "Google Earth Toolbox For Matlab", "competence": ["Big Data Analytics"], "documentationUrl": "https://github.com/scottleedavis/googleearthtoolbox/tree/master/matlab/html", "supportLevel": "specialized", "dependency": ["MATLAB"], "name": "GoogleEarth Toolbox for MATLAB", "description": "<p>The MATLAB functions within this toolbox let you visualize your spatially distributed data in GoogleEarth by automatically generating KML-formatted files.</p>\n", "owner": ["/person/j.spaaks", { "name": "Scott Lee Davis" }, "/organization/uva"], "programmingLanguage": ["MATLAB"], "expertise": ["Information Visualization", "Scientific Visualization"], "technologyTag": ["Visualization", "Maps", "GoogleEarth", "MATLAB"], "usedIn": null, "@id": "http://software.esciencecenter.nl/software/google-earth-toolbox-for-matlab/", "license": ["lgpl-3.0"], "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/uva"], "id": "/software/google-earth-toolbox-for-matlab", "website": "https://github.com/scottleedavis/googleearthtoolbox/", "status": "inactive", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "title": "Harmony", "tagLine": "Regional Atmospheric model", "slug": "harmony", "programmingLanguage": ["FORTRAN"], "status": "active", "expertise": ["Distributed Computing"], "owner": [{ "affiliation": ["/organization/knmi"], "website": "http://www.hirlam.org", "name": "knmi" }], "competence": ["Efficient Computing", "Optimized Data Handling"], "user": ["/organization/nlesc"], "technologyTag": ["Simulation", "Modeling"], "@id": "http://software.esciencecenter.nl/software/harmony/", "discipline": ["Environment & Sustainability"], "description": "<p>The international research programme HIRLAM (HIgh Resolution Limited Area Model) is a research cooperation of European meteorological institutes. The aim of the HIRLAM programme is to develop and maintain a numerical short-range weather forecasting system for operational use by the participating meteorological institutes.\nHIRLAM Management Group with Frits Brouwer Director General at KNMI 2012</p>\n\n<p>The programme was initiated in 1985 and has gone through numerous phases in the past two decades. Since 1 January 2011, the programme has entered a new phase, HIRLAM-B (see the Memorandum Of Understanding HIRLAM-B ). The model which is the focus of HIRLAM-B research activities is the non-hydrostatic convection permitting model HARMONIE. This is being developed in close cooperation with the ALADIN consortium and M\u00e9t\u00e9o-France, building on model components that have largely been developed previously in these two communities.</p>\n\n<p>The consortium is lead by a Steering Group planning and coordinating the development of the model and the consortium.</p>\n", "contributingOrganization": ["/organization/knmi"], "supportLevel": "advanced", "involvedOrganization": ["/organization/nlesc"], "endorsedBy": ["/organization/knmi"], "name": "Harmony", "license": ["Unknown"], "id": "/software/harmony" }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2016-03-17", "contributor": ["/person/j.vanderzwaan"], "tagLine": "279 17th and 18th century Dutch theater texts with HEEM labels", "slug": "heem-dataset", "contactPerson": "/person/j.vanderzwaan", "doi": "http://dx.doi.org/10.5281/zenodo.47751", "user": ["/organization/nlesc"], "title": "Heem Dataset", "competence": ["Big Data Analytics"], "status": "inactive", "supportLevel": "specialized", "name": "Historic Embodied Emotions Model (HEEM) dataset", "owner": ["/organization/nlesc", "/organization/vua"], "expertise": ["Text Mining"], "technologyTag": ["Dataset", "Emotion Mining"], "usedIn": ["/project/from-sentiment-mining-to-mining-embodied-emotions", "/project/visualizing-uncertainty-and-perspectives"], "@id": "http://software.esciencecenter.nl/software/heem-dataset/", "description": "<p>279 17th and 18th century Dutch theater texts in NAF format. 29 texts are manually annotated with\nHEEM labels. Machine learning was applied to predict HEEM labels for all texts.</p>\n\n<p>The dataset also contains metadata about the texts (title, authors, genre, period, etc.).</p>\n", "discipline": ["Humanities & Social Sciences"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/vua"], "id": "/software/heem-dataset", "license": ["cc-by"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2016-03-27", "contributor": ["/person/b.vanwerkhoven"], "tagLine": "A simple CUDA/OpenCL kernel tuner in Python.", "slug": "kernel_tuner", "contactPerson": "/person/b.vanwerkhoven", "codeRepository": "https://github.com/benvanwerkhoven/kernel_tuner", "user": ["/person/b.vanwerkhoven", "/person/h.spreeuw", "/organization/nlesc"], "title": "Kernel_tuner", "competence": ["Efficient Computing"], "documentationUrl": "http://benvanwerkhoven.github.io/kernel_tuner/index.html", "supportLevel": "specialized", "name": "Kernel Tuner", "description": "<p>The goal of this project is to provide a - as simple as possible - tool for tuning CUDA and OpenCL kernels.</p>\n\n<h1 id=\"kernel-tuning\">Kernel Tuning</h1>\n\n<p>A very common problem in GPU programming is that some combination of \nthread block dimensions and other kernel parameters, like tiling or \nunrolling factors, results in dramatically better performance than other \nkernel configurations. The goal of auto-tuning is to automate the \nprocess of finding the best performing configuration for a given device.</p>\n\n<p>This kernel tuner aims that you can directly use the tuned kernel \nwithout introducing any new dependencies. The tuned kernels can \nafterwards be used independently of the programming environment, whether \nthat is using C/C++/Java/Fortran or Python doesn\u2019t matter.</p>\n\n<p>The kernel_tuner module currently only contains one function which is \ncalled tune_kernel to which you pass at least the kernel name, a string \ncontaining the kernel code, the problem size, a list of kernel function \narguments, and a dictionary of tunable parameters. There are also a lot \nof optional parameters, for a full list see the full documentation.</p>\n", "owner": ["/person/b.vanwerkhoven", "/organization/nlesc"], "programmingLanguage": ["Python", "CUDA", "OpenCL"], "expertise": ["High Performance Computing", "Accelerated Computing"], "technologyTag": ["GPU Computing"], "usedIn": ["/project/a-jungle-computing-approach-to-large-scale-online-forensic-analysis", "/project/3d-geospatial-data-exploration-for-modern-risk-management-systems", "/project/neutrino", "/project/microscopy"], "@id": "http://software.esciencecenter.nl/software/kernel_tuner/", "license": ["apache-2.0"], "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "id": "/software/kernel_tuner", "website": "https://github.com/benvanwerkhoven/kernel_tuner", "status": "active", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2015-10-01", "contributor": ["/person/s.verhoeven"], "tagLine": "Generator for Knime workflow node skeleton repository with sample code.", "slug": "knime-archetype", "id": "/software/knime-archetype", "contactPerson": "/person/s.verhoeven", "codeRepository": "https://github.com/3D-e-Chem/tycho-knime-node-archetype", "title": "Knime Archetype", "competence": ["Optimized Data Handling"], "status": "active", "supportLevel": "specialized", "name": "Knime node archetype", "owner": ["/organization/nlesc", "/organization/radboud.university.nijmegen", "/organization/vua"], "downloadUrl": "https://bintray.com/nlesc/tycho-knime-node-archetype/tycho-knime-node-archetype/", "programmingLanguage": ["Java"], "expertise": ["Information Integration"], "technologyTag": ["Knime", "Maven", "Scaffold"], "usedIn": ["/project/3d-e-chem"], "@id": "http://software.esciencecenter.nl/software/knime-archetype/", "description": "<p><a href=\"https://travis-ci.org/3D-e-Chem/tycho-knime-node-archetype\"><img src=\"https://travis-ci.org/3D-e-Chem/tycho-knime-node-archetype.svg?branch=master\" alt=\"Build Status\" /></a>\n<a href=\"https://bintray.com/nlesc/tycho-knime-node-archetype/tycho-knime-node-archetype/_latestVersion\"> <img src=\"https://api.bintray.com/packages/nlesc/tycho-knime-node-archetype/tycho-knime-node-archetype/images/download.svg\" alt=\"Download\" /> </a></p>\n\n<p>Generates <a href=\"http://www.knime.org\">Knime</a> workflow node skeleton repository with sample code.</p>\n\n<p>The <a href=\"https://maven.apache.org/guides/introduction/introduction-to-archetypes.html\">Maven archetype</a> will generate a multi-module project.\nThe project can be build resulting in a Eclipse update site.\nNodes can be installed in Knime using the update site.</p>\n", "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/radboud.university.nijmegen", "/organization/vua"], "endorsedBy": ["/organization/nlesc"], "website": "https://github.com/3D-e-Chem/tycho-knime-node-archetype", "license": ["apache-2.0"], "discipline": ["Life Sciences & eHealth"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2015-10-01", "contributor": ["/person/s.verhoeven", { "linkedInUrl": "https://www.linkedin.com/in/ajkooistra/", "affiliation": ["/organization/vua"], "name": "Albert J. Kooistra" }], "tagLine": "KNIME nodes to interact with GPCRdb website", "slug": "knime-gpcrdb", "id": "/software/knime-gpcrdb", "contactPerson": "/person/s.verhoeven", "codeRepository": "https://github.com/3D-e-Chem/knime-gpcrdb", "title": "Knime Gpcrdb", "competence": ["Optimized Data Handling"], "status": "active", "supportLevel": "specialized", "name": "GPCRdb KNIME nodes", "owner": ["/organization/nlesc", "/organization/radboud.university.nijmegen", "/organization/vua"], "downloadUrl": "https://3d-e-chem.github.io/knime-node-collection", "programmingLanguage": ["Java"], "expertise": ["Information Integration"], "technologyTag": ["Knime", "Swagger", "workflow"], "usedIn": ["/project/3d-e-chem"], "@id": "http://software.esciencecenter.nl/software/knime-gpcrdb/", "description": "<p>KNIME nodes for retrieving data from http://gpcrdb.org, GPCRdb website contains data, web tools and diagrams for G protein-coupled receptors (GPCRs).</p>\n", "contributingOrganization": ["/organization/nlesc", "/organization/vua"], "involvedOrganization": ["/organization/nlesc", "/organization/radboud.university.nijmegen", "/organization/vua"], "endorsedBy": ["/organization/nlesc"], "website": "https://github.com/3D-e-Chem/knime-gpcrdb", "license": ["apache-2.0"], "discipline": ["Life Sciences & eHealth"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2016-06-11", "contributor": [{ "linkedInUrl": "https://www.linkedin.com/in/ajkooistra/", "affiliation": ["/organization/vua"], "name": "Albert J. Kooistra" }, "/person/s.verhoeven"], "tagLine": "KNIME nodes to interact with KLIFS website", "slug": "knime-klifs", "id": "/software/knime-klifs", "contactPerson": "/person/s.verhoeven", "codeRepository": "https://github.com/3D-e-Chem/knime-klifs", "title": "Knime Klifs", "competence": ["Optimized Data Handling"], "status": "active", "supportLevel": "specialized", "name": "KLIFS KNIME nodes", "owner": ["/organization/vua", "/organization/nlesc", "/organization/radboud.university.nijmegen"], "downloadUrl": "https://3d-e-chem.github.io/knime-node-collection", "programmingLanguage": ["Java"], "expertise": ["Information Integration"], "technologyTag": ["Knime", "Swagger", "workflow"], "usedIn": ["/project/3d-e-chem"], "@id": "http://software.esciencecenter.nl/software/knime-klifs/", "description": "<p>KNIME nodes for retrieving data from KLIFS (http://klifs.vu-compmedchem.nl). KLIFS is a structural kinase-ligand interaction database. For more information regarding KLIFS see <a href=\"http://klifs.vu-compmedchem.nl\">the website</a> and the references at the bottom.</p>\n", "contributingOrganization": ["/organization/vua", "/organization/nlesc"], "involvedOrganization": ["/organization/vua", "/organization/nlesc", "/organization/radboud.university.nijmegen"], "endorsedBy": ["/organization/nlesc"], "website": "https://github.com/3D-e-Chem/knime-klifs", "license": ["apache-2.0"], "discipline": ["Life Sciences & eHealth"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2015-10-01", "contributor": ["/person/s.verhoeven", { "linkedInUrl": "https://www.linkedin.com/in/ajkooistra/", "affiliation": ["/organization/vua"], "name": "Albert J. Kooistra" }], "tagLine": "KNIME nodes to view molecules in 3D", "slug": "knime-molviewer", "id": "/software/knime-molviewer", "contactPerson": "/person/s.verhoeven", "codeRepository": "https://github.com/3D-e-Chem/knime-molviewer", "title": "Knime Molviewer", "competence": ["Optimized Data Handling"], "status": "active", "supportLevel": "specialized", "name": "KNIME molviewer", "owner": ["/organization/nlesc", "/organization/radboud.university.nijmegen", "/organization/vua"], "downloadUrl": "https://3d-e-chem.github.io/knime-node-collection", "programmingLanguage": ["Java"], "expertise": ["Information Integration"], "technologyTag": ["Knime", "Swagger", "workflow"], "usedIn": ["/project/3d-e-chem"], "@id": "http://software.esciencecenter.nl/software/knime-molviewer/", "description": "<p>KNIME node which launches a web browser with a 3D molecule viewer powered by (NGL)[https://github.com/arose/ngl].</p>\n", "contributingOrganization": ["/organization/nlesc", "/organization/vua"], "involvedOrganization": ["/organization/nlesc", "/organization/radboud.university.nijmegen", "/organization/vua"], "endorsedBy": ["/organization/nlesc"], "website": "https://github.com/3D-e-Chem/knime-molviewer", "license": ["apache-2.0"], "discipline": ["Life Sciences & eHealth"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "title": "Langident", "tagLine": "This is a language guesser for 17th century German, English, French, Latin and Dutch.", "slug": "langident", "programmingLanguage": ["Java"], "codeRepository": "https://github.com/HuygensING/langident", "expertise": ["Text Mining"], "description": "<p>This is a language guesser for historical text. It distinguishes between German, English, French, Latin and Dutch (that is, the seventeenth-century variants of all those).</p>\n", "@id": "http://software.esciencecenter.nl/software/langident/", "competence": ["Big Data Analytics"], "discipline": ["Humanities & Social Sciences"], "status": "active", "involvedOrganization": ["/organization/huygens"], "id": "/software/langident", "name": "Langident", "license": ["gpl-3.0"], "endorsedBy": ["/organization/huygens"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2007-01-01", "contributor": ["/person/o.rubi", "/person/r.goncalves"], "tagLine": "C/C++ library for reading and writing the very common LAS Lidar format.", "slug": "liblas", "contactPerson": "/person/o.rubi", "codeRepository": "http://www.liblas.org/", "user": ["/organization/nlesc", "/person/o.rubi", "/person/r.goncalves"], "title": "Liblas", "dependencyOf": ["/software/casacore"], "competence": ["Big Data Analytics"], "status": "active", "name": "libLAS", "supportLevel": "specialized", "programmingLanguage": ["C++", "C"], "expertise": null, "technologyTag": ["Point clouds", "Library"], "usedIn": ["/project/massive-point-clouds-for-esciences", "/project/big-data-analytics-in-the-geo-spatial-domain", "/project/3d-geospatial-data-exploration-for-modern-risk-management-systems"], "@id": "http://software.esciencecenter.nl/software/liblas/", "description": "<p>libLAS is a C/C++ library for reading and writing the very common LAS Lidar format and its compressed version (LAZ). The NLeSC contribution to the repository has been (so far) two binary converters from LAS/LAZ to PostgreSQL and MonetDB binary dumpt formats.</p>\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "license": ["bsd-2-clause"], "id": "/software/liblas" }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2011-05-10", "contributor": ["/person/l.ridder", "/person/s.verhoeven", "/person/m.sanders"], "tagLine": "MAGMa is an online application for the automatic chemical annotation of accurate multistage MSn spectral data.", "slug": "magma", "contactPerson": "/person/l.ridder", "codeRepository": "https://github.com/NLeSC/Osmium", "user": ["/person/l.ridder", "/person/m.sanders"], "title": "Magma", "competence": ["Big Data Analytics", "Efficient Computing"], "status": "active", "supportLevel": "specialized", "dependency": ["/software/osmium", "/software/rdkit"], "name": "MAGMa", "owner": ["/organization/nlesc", "/organization/wur"], "programmingLanguage": ["Python", "JavaScript"], "expertise": ["High Performance Computing", "Scientific Visualization"], "technologyTag": ["Distributed", "Webservice"], "usedIn": ["/project/emetabolomics"], "@id": "http://software.esciencecenter.nl/software/magma/", "description": "<p>MAGMa is an online application for the automatic chemical annotation of accurate multistage MSn spectral data.</p>\n\n<ul>\n  <li>MSn data can be uploaded as a hierarchical tree of fragment peaks, either based on m/z values or elemental formulas, or as an mzXML file of the raw data.</li>\n  <li>Candidate molecules are automatically retrieved from PubChem, from a subset of PubChem compounds present in Kegg, or from the Human Metabolome Database.</li>\n  <li>Candidate molecules can be predicted based on in silico reaction rules describing microbiotic and human biotransformations</li>\n  <li>For each candidate molecule, substructures are generated and matched with the observed fragment peaks.</li>\n  <li>The web browser enables efficient mining of the automatically annotated data.</li>\n  <li>Open Source, source code available at <a href=\"https://github.com/NLeSC/MAGMa\">https://github.com/NLeSC/MAGMa</a></li>\n</ul>\n\n<p><img src=\"https://github.com/NLeSC/MAGMa/raw/master/web/magmaweb/static/img/metabolites.png\" alt=\"screenshot\" title=\"Screenshot of web application\" />.</p>\n", "discipline": ["Life Sciences & eHealth"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/wur"], "endorsedBy": ["/organization/nlesc"], "website": "http://www.emetabolomics.org/magma", "license": ["apache-2.0"], "id": "/software/magma" }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2012-05-1", "contributor": ["/person/j.maassen"], "tagLine": "An MPI wrapper library that allows traditional MPI applications to be run on a combination of multiple supercomputers or clusters, without changing a single line of code in the application.", "slug": "magnesium", "contactPerson": "/person/j.maassen", "codeRepository": "https://github.com/NLeSC/eSalsa-MPI", "user": ["/organization/nlesc", "/person/j.maassen"], "title": "Magnesium", "dependencyOf": ["/project/esalsa"], "competence": ["Efficient Computing"], "status": "active", "supportLevel": "specialized", "name": "Magnesium", "owner": ["/organization/nlesc", "/person/j.maassen"], "programmingLanguage": ["C", "Java"], "expertise": ["Distributed Computing"], "technologyTag": ["Distributed", "Library"], "usedIn": ["/project/esalsa"], "@id": "http://software.esciencecenter.nl/software/magnesium/", "description": "<p>Magnesium is an MPI wrapper library that allows traditional MPI \napplications to be run on a combination of multiple supercomputers \nor clusters, without changing a single line of code in the application.</p>\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "id": "/software/magnesium", "license": ["apache-2.0"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2011-01-01", "contributor": ["/person/o.rubi", "/person/m.vanmeersbergen", "/person/s.verhoeven"], "tagLine": "Distributed generation of massive multi-resolution octrees (required by Potree-based renderers)", "slug": "massivepotreeconverter", "owner": ["/organization/nlesc"], "contactPerson": "/person/o.rubi", "codeRepository": "https://github.com/NLeSC/Massive-PotreeConverter", "user": ["/organization/nlesc", "/person/o.rubi"], "title": "Massivepotreeconverter", "dependencyOf": ["/software/ahn2webviewer"], "competence": ["Optimized Data Handling"], "status": "active", "dependency": ["/software/potreeconverter", "/software/potree"], "name": "Massive-PotreeConverter", "supportLevel": "specialized", "programmingLanguage": ["Python"], "expertise": ["Databases", "Distributed Computing"], "technologyTag": ["Point clouds"], "usedIn": ["/project/massive-point-clouds-for-esciences"], "@id": "http://software.esciencecenter.nl/software/massivepotreeconverter/", "description": "<p>This repository extends the PotreeConverter (&lt;/software/potreeconverter&gt;) through a collection of Python scripts to make it able to convert massive point clouds to the potree format (octree).</p>\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/potree"], "id": "/software/massivepotreeconverter", "license": ["bsd-2-clause"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "tagLine": "Matifus is a Matlab \u00ae toolbox for 2D image fusion.", "slug": "matifus", "badges": null, "title": "Matifus", "dependencyOf": ["http://nl.mathworks.com/products/matlab/"], "competence": ["Big Data Analytics"], "documentationUrl": "http://oai.cwi.nl/oai/asset/11009/11009D.pdf", "dependency": null, "name": "Matifus", "downloadUrl": "http://matifus.project.cwi.nl/Register/prov_person_data.php", "programmingLanguage": ["MATLAB"], "expertise": ["Computer Vision", "Handling Sensor Data"], "technologyTag": ["ImageProcessing"], "usedIn": null, "@id": "http://software.esciencecenter.nl/software/matifus/", "description": "<p>Image fusion methods aim to combine images in such a way that all the salient information is put together into (usually) one image suitable for hum an perception or further processing. An important example is that one and the same scene is recorded by cameras o perating for differ ent bands of light (e.g. infrared and visible light). Many applications exist in the areas of defense, surveillance, medical imaging, remote sensing etc. Multiresolution decomposition has become an im portant means wi thin the devel opment of image fusion methods.  Wavelet methods for instance are eligible because of the spatial localization and hierarchy in scaling. MATIFUS is a MATLAB r \u00a9 toolbox f or image fusion, based on various multiresolution decomposi- tions and fusi on schemes.</p>\n\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/cwi"], "id": "/software/matifus", "website": "http://homepages.cwi.nl/%7Epauldz/Bulk/Codes/MATIFUS/", "license": null, "endorsedBy": [] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2016-03-16", "contributor": ["/person/j.spaaks"], "tagLine": "Visualization of multi-dimensional data using a matrix of linked scatter plots.", "slug": "matrix-of-scatter", "contactPerson": "/person/j.spaaks", "codeRepository": "https://github.com/jspaaks/matrix-of-scatter", "user": ["/person/j.spaaks"], "title": "Matrix Of Scatter", "competence": ["Big Data Analytics"], "documentationUrl": "http://jspaaks.github.io/matrix-of-scatter/docs/", "supportLevel": "specialized", "dependency": ["https://plot.ly/python/", "https://www.python.org/"], "name": "Matrix of scatter", "description": "<p>Visualization of multi-dimensional data using a matrix of linked scatter plots</p>\n", "owner": ["/person/j.spaaks"], "programmingLanguage": ["Python3"], "expertise": ["Information Visualization", "Scientific Visualization"], "technologyTag": ["Visualization", "Python", "matrix of scatter", "trellis", "n-dimensional", "multi-dimensional", "Plotly"], "usedIn": ["/project/sherlock"], "@id": "http://software.esciencecenter.nl/software/matrix-of-scatter/", "license": ["apache-2.0"], "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "id": "/software/matrix-of-scatter", "website": "https://github.com/jspaaks/matrix-of-scatter", "status": "wip", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "title": "Mcatnlo", "tagLine": "MC@NLO implements the eponymous scheme for combining a Monte Carlo event generator with Next-to-Leading-Order calculations of rates for QCD processes.", "slug": "mcatnlo", "programmingLanguage": ["FORTRAN"], "description": "<p>MC@NLO is a Fortran package to implement the eponymous scheme for combining a Monte Carlo event generator with Next-to-Leading-Order calculations of rates for QCD processes.</p>\n", "expertise": ["Reproducible Research"], "user": ["/organization/nikhef"], "@id": "http://software.esciencecenter.nl/software/mcatnlo/", "discipline": ["Physics & Beyond"], "contributingOrganization": ["/organization/nikhef"], "involvedOrganization": ["/organization/nikhef"], "name": "MCatNLO", "id": "/software/mcatnlo" }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2016-05-20", "contributor": ["/person/c.meijer", "/person/d.vankuppevelt", "/person/v.hees"], "tagLine": "A deep learning tool for time series classification", "slug": "mcfly", "id": "/software/mcfly", "contactPerson": "/person/c.meijer", "codeRepository": "https://github.com/NLeSC/mcfly", "license": ["apache-2.0"], "user": ["/organization/nlesc", "/person/c.meijer", "/person/d.vankuppevelt", "/person/v.hees"], "title": "Mcfly", "competence": ["Big Data Analytics"], "documentationUrl": "https://github.com/NLeSC/mcfly/wiki", "doi": "https://zenodo.org/badge/latestdoi/59207352", "supportLevel": "specialized", "name": "mcfly", "description": "<p>This tool enables researchers to try deep learning technology for time series classification with minimum effort. The advantages of deep learning algorithms is that it can handle raw data directly with no need to compute signal features, it does not require a expert domain knowledge about the data, and it has been shown to be competitive with conventional machine learning techniques.</p>\n", "owner": ["/organization/nlesc"], "downloadUrl": "https://github.com/NLeSC/mcfly/releases", "programmingLanguage": ["Python"], "expertise": ["Machine Learning"], "technologyTag": ["Deep learning", "Library"], "usedIn": null, "@id": "http://software.esciencecenter.nl/software/mcfly/", "logo": "/images/software/mcfly.png", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "endorsedBy": ["/organization/nlesc"], "website": "https://github.com/NLeSC/mcfly/wiki", "status": "active", "nlescWebsite": "https://www.esciencecenter.nl/technology/software/mcfly" }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2015-11-17", "contributor": ["/person/j.spaaks", "/person/f.diblen", "/person/j.hidding", "/person/m.kuzak", "/person/l.veen"], "tagLine": "Graph visualization using metrolines.", "slug": "metrochartjs", "contactPerson": "/person/j.spaaks", "codeRepository": "https://github.com/nlesc-sherlock/metrochartjs", "user": ["/organization/nlesc", "/organization/nfi", "/person/j.spaaks"], "title": "Metrochartjs", "competence": ["Big Data Analytics"], "documentationUrl": "http://nlesc-sherlock.github.io/metrochartjs/sites/tsdoc/", "supportLevel": "specialized", "name": "metrochartjs", "description": "<p>TypeScript library to visualize graphs in the style of metroline maps.</p>\n", "owner": ["/organization/nlesc"], "programmingLanguage": ["TypeScript"], "expertise": ["Information Visualization", "Scientific Visualization"], "technologyTag": ["Visualization", "Website", "Graph", "Timeline"], "usedIn": ["/project/sherlock"], "@id": "http://software.esciencecenter.nl/software/metrochartjs/", "license": ["apache-2.0"], "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "id": "/software/metrochartjs", "website": "https://github.com/nlesc-sherlock/metrochartjs", "status": "active", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2013-10-01", "contributor": ["/person/o.rubi"], "tagLine": "Open Source photogrammetry toolset (from images to point clouds)", "slug": "micmac", "owner": ["/organization/ign"], "contactPerson": "/person/o.rubi", "codeRepository": "https://geoportail.forge.ign.fr/hg/culture3d", "user": ["/organization/nlesc", "/person/o.rubi"], "title": "Micmac", "competence": ["Optimized Data Handling"], "status": "active", "name": "MicMac", "supportLevel": "specialized", "programmingLanguage": ["C++"], "expertise": ["Handling Sensor Data", "High Performance Computing"], "technologyTag": ["Point clouds", "Photogrammetry"], "usedIn": ["/project/improving-photogrammetry"], "@id": "http://software.esciencecenter.nl/software/micmac/", "description": "<p>MicMac is an open source set of tools that executes the various steps of the photogrammetric workflow (from images to a point cloud).</p>\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/ign", "/organization/utwente"], "id": "/software/micmac", "license": ["CeCILL-B"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2012-12-18", "contributor": ["/person/j.spaaks", { "affiliation": ["/organization/uva"], "name": "Willem Bouten" }, { "affiliation": ["/organization/uva"], "name": "Jasper A. Vrugt" }, { "affiliation": ["/organization/surfsara"], "name": "Jeroen Engelberts" }], "tagLine": "MATLAB toolbox for global optimization and state estimation of dynamic models using distributed computing", "slug": "mmsoda-toolbox-for-matlab", "contactPerson": "/person/j.spaaks", "codeRepository": "https://github.com/NLeSC/esibayes", "license": ["apache-2.0"], "user": ["/person/j.spaaks", "/organization/nlesc"], "title": "Mmsoda Toolbox For Matlab", "dependencyOf": null, "competence": ["Big Data Analytics", "Efficient Computing"], "documentationUrl": "https://github.com/NLeSC/esibayes/blob/master/manual/out/2013-mmsoda-manual.pdf", "supportLevel": "specialized", "name": "MMSODA Toolbox for MATLAB", "description": "<p>An eScience infrastructure for Bayesian inverse modeling</p>\n\n<p>We have developed a parallel MATLAB version of SODA (Vrugt et al., 2005) that makes use of MPI. The software package is called \u2018The MMSODA Toolbox for MATLAB\u2019, or MMSODA for short (MMSODA stands for MATLAB-MPI-SODA).</p>\n\n<p>MMSODA offers the functionality of a number of previously separate softwares, namely SCEM-UA (Vrugt <em>et al</em>., 2003b), SODA (Vrugt <em>et al.</em>, 2005a,b; Clark and Vrugt, 2006), MOSCEM-UA (Vrugt <em>et al.</em>, 2003a), multi-objective SODA (Vrugt <em>et al.</em>, 2008), the MPITB-parallel version of SCEM-UA implemented in Octave (Vrugt <em>et al.</em>, 2006b), and the MPITB-parallel version of SODA implemented in Octave (Vrugt <em>et al.</em>, 2006a). Additionally, MMSODA offers a parallel version of multi-objective SCEM-UA, and a parallel version of multi-objective SODA, both of which did not exist previously. Moreover, MMSODA does not use Octave when running in parallel, because Octave does not evaluate code as quickly as does MATLAB. MMSODA circumvents (in a legal fashion) the license requirements that are often an impediment to parallel computation by compiling the MATLAB code into a binary which can be run without any license. Compiling the binary, however, does require a license, both for the MATLAB program itself, as well as for the MATLAB Compiler Runtime Toolbox. Fortunately, the required licenses are available on most cluster environments targeting a scientific and engineering audience.</p>\n\n<p>In short, the acronyms mentioned above mean that: MMSODA can do parameter tuning with or without intermediate state updating by an ensemble Kalman Filter; that MMSODA supports both single-objective and multi-objective optimization; and that the optimization can be run either sequentially on a local machine, or in parallel on a cluster computer.</p>\n\n<p>The serial/parallel capability is particularly attractive, since it allows the users to set up their optimizations locally on their own machines, thus ensuring a familiar development environment without the need to make the code compatible with Octave syntax. When the user finishes setting up the optimization, running it on a cluster computer is simply a matter of copying the relevant directory to the cluster storage using standard tools (e.g. WinSCP) and compiling the software by executing a script that comes with the software. Furthermore, MMSODA is fully documented with HTML documentation which can be accessed in the same way as MATLAB\u2019s built-in commands, namely through the <code class=\"highlighter-rouge\">doc</code> command.</p>\n\n<p><em>References</em></p>\n\n<ul>\n  <li>J. A. Vrugt, H. V. Gupta, L. A. Bastidas, W. Bouten, and S. Sorooshian. Effective and efficient algorithm for multi-objective optimization of hydrologic models. Water Resources Research, 39(8):1214, 2003a. doi: 10.1029/2002WR001746.</li>\n  <li>J. A. Vrugt, H. V. Gupta, W. Bouten, and S. Sorooshian. A Shuffled Complex Evolution Metropolis algorithm for optimization and uncertainty assessment of hydrologic model parameters. Water Resources Research, 39(8):1201, 2003b. doi: 10.1029/2002WR001642.</li>\n  <li>Jasper A. Vrugt, Cees G. H. Diks, Hoshin V. Gupta, Willem Bouten, and Jacobus M. Verstraten. Improved treatment of uncertainty in hydrologic modeling: Combining the strengths of global optimization and data assimilation. Water Resources Research, 41:W01017, 2005a. doi: 10.1029/2004WR003059.</li>\n  <li>Jasper A. Vrugt, Bruce A. Robinson, and Velimir V. Vesselinov. Improved inverse modeling for flow and transport in subsurface media: Combined parameter and state estimation. Geophysical Research Letters, 32:L18408, 2005b. doi: 10.1029/2005GL023940.</li>\n  <li>Jasper A. Vrugt, Hoshin V. Gupta, Breand\u00e1nn \u00d3 Nuall\u00e1in, and Willem Bouten. Real-time data assimilation for operational ensemble streamflow forecasting. Journal of Hydrometeorology, 7(3):548\u2013575, 2006a. doi: 10.1175/JHM504.1.</li>\n  <li>Jasper A. Vrugt, Breand\u00e1nn \u00d3 Nuall\u00e1in, Bruce A. Robinson, Willem Bouten, Stefan C. Dekker, and Peter M. A. Sloot. Application of parallel computing to stochastic parameter estimation in environmental models. Computers &amp; Geosciences, 32:1139\u20131155, 2006b. doi:10.1016/j.cageo.2005.10.015.</li>\n  <li>Jasper A. Vrugt, Philip H. Stauffer, Th. W\u00f6hling, Bruce A. Robinson, and Velimir V. Vesselinov. Inverse modeling of subsurface flow and transport properties: A review with new developments. Vadose Zone Journal, 7(2):843\u2013864, 2008. doi: 10.2136/vzj2007.0078.</li>\n</ul>\n\n", "owner": ["/organization/nlesc", "/person/j.spaaks", "/organization/uva"], "downloadUrl": "https://github.com/NLeSC/esibayes/archive/master.zip", "programmingLanguage": ["MATLAB", "C"], "expertise": ["Data Assimilation", "Distributed Computing", "High Performance Computing"], "technologyTag": ["Cluster Computing", "Global Optimization", "Inverse Modeling", "SCEM-UA", "SODA", "Single-objective", "Multi-objective", "Dynamic Modeling", "Uncertainty Estimation"], "usedIn": ["/project/esibayes"], "@id": "http://software.esciencecenter.nl/software/mmsoda-toolbox-for-matlab/", "logo": null, "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/uva"], "nlescWebsite": "https://www.esciencecenter.nl/project/esibayes", "id": "/software/mmsoda-toolbox-for-matlab", "website": "https://github.com/NLeSC/esibayes", "status": "inactive", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "contributor": ["/person/r.goncalves", "/person/v.hees"], "tagLine": "A relational column-oriented Database Management System.", "slug": "monetdb", "contactPerson": "/person/r.goncalves", "codeRepository": "https://www.monetdb.org/Downloads", "license": ["mpl-2.0"], "user": ["/person/r.goncalves", "/person/o.rubi", "/person/v.hees"], "title": "Monetdb", "competence": ["Optimized Data Handling"], "documentationUrl": "https://www.monetdb.org/Documentation", "status": "active", "dependency": ["/software/datavaults"], "name": "MonetDB", "supportLevel": "specialized", "downloadUrl": "https://www.monetdb.org/Downloads", "programmingLanguage": ["C"], "expertise": ["Databases"], "technologyTag": ["Column-stores", "Relational Databases", "DBMS", "Scientific Databases"], "usedIn": ["/project/big-data-analytics-in-the-geo-spatial-domain", "/project/3d-geospatial-data-exploration-for-modern-risk-management-systems", "/project/massive-point-clouds-for-esciences", "/project/compressing-the-sky-into-a-large-collection-of-statistical-models"], "@id": "http://software.esciencecenter.nl/software/monetdb/", "discipline": ["eScience Methodology"], "description": "<p>MonetDB is an open source column-oriented database management system developed\nat the Centrum Wiskunde &amp; Informatica (CWI) in the Netherlands. It was designed\nto provide high performance on complex queries against large databases, such as\ncombining tables with hundreds of columns and multi-million rows. MonetDB has\nbeen applied in high-performance applications for online analytical processing\n(OLAP), data mining, GIS, text retrieval, sequence alignment processing and in\nearth observation applications.</p>\n\n<h1 id=\"why-monetdb\">Why MonetDB?</h1>\n\n<p>MonetDB is DBMS which provides storage model based on vertical fragmentation,\na modern CPU-tuned query execution architecture, automatic and self-tuning indexes,\nrun-time query optimization, and a modular software architecture. It has been\nused by the Netherlands eScience Center for efficient spatio-temporal analysis.</p>\n\n<p>With in-house expertise on MonetDB architecture, the Netherlands eScience center\ncontributes to the design, research and implementation of new functionality to\nsupport geo-spatial applications. Architectural improvements and new Geo-spatial\nfunctionality, following OGS standards, were added to provide efficiency and\nscalability to applications running on top of PostGIS or other commercial Spatial\nDBMSs.</p>\n", "logo": "/images/software/monetdb.png", "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/cwi", "/organization/monetdb"], "id": "/software/monetdb", "website": "https://en.wikipedia.org/wiki/MonetDB", "startDate": "2014-03-01", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "contributor": ["/person/r.vanharen"], "tagLine": "A fortran application to convert NetCDF files to the Little-R format.", "slug": "netcdf2littler", "id": "/software/netcdf2littler", "contactPerson": "/person/r.vanharen", "codeRepository": "https://github.com/rvanharen/netcdf2littler", "license": ["apache-2.0", "bsd-3-clause (custom extension)"], "user": ["/person/r.vanharen", "/organization/wur"], "title": "Netcdf2littler", "dependencyOf": null, "competence": ["Big Data Analytics"], "status": "wip", "supportLevel": "specialized", "dependency": ["NetCDF", "udunits2"], "name": "NetCDF2LittleR", "owner": ["/person/r.vanharen"], "downloadUrl": "https://github.com/rvanharen/netcdf2littler/releases", "programmingLanguage": ["FORTRAN"], "expertise": ["Data Assimilation"], "technologyTag": ["FileConversion"], "usedIn": ["/project/era-urban"], "@id": "http://software.esciencecenter.nl/software/netcdf2littler/", "description": "<p>A FORTRAN application to convert NetCDF files to the Little-R format. The Little-R format is the accepted input format for the WRF data assimilation system (WRFDA) preprocessor (obsproc).</p>\n", "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "endorsedBy": ["/organization/nlesc"], "startDate": "2015-6-17", "discipline": ["Environment & Sustainability", "eScience Methodology"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2015-10-11", "contributor": ["/person/j.hidding", "/person/b.weel", { "githubUrl": "https://github.com/felipeZ", "affiliation": ["/organization/vua"], "name": "Felipe Zapata" }], "tagLine": "Programmable workflow engine for Python.", "slug": "noodles", "id": "/software/noodles", "contactPerson": "/person/j.hidding", "codeRepository": "https://github.com/NLeSC/noodles", "user": ["/organization/nlesc", "/organization/vua", "/person/j.hidding", "/person/o.rubi", "/person/l.ridder"], "title": "Noodles", "dependencyOf": ["/pymicmac", "/software/pymicmac"], "competence": ["Efficient Computing"], "documentationUrl": "http://nlesc.github.io/noodles/sphinxdoc/html/index.html", "supportLevel": "specialized", "dependency": ["/software/xenon", "/software/pyxenon"], "name": "Noodles", "owner": ["/organization/nlesc"], "programmingLanguage": ["Python"], "status": "active", "expertise": ["Orchestrated Computing"], "technologyTag": ["workflow"], "usedIn": ["/project/computational-chemistry-made-easy", "/project/improving-photogrammetry"], "@id": "http://software.esciencecenter.nl/software/noodles/", "description": "<p>Noodles is a programmable workflow engine for Python. It can be used to parallelize your code with minimal effort.</p>\n\n<h1 id=\"why-noodles\">Why Noodles?</h1>\n\n<p>The primary goal of Noodles is to make it easy to run jobs on cluster supercomputers, in parallel, straight from a Python shell. The user enters a Python script that looks and feels like a serial program. The Noodles engine then converts this script into a call graph. This graph can be executed on a variety of machines using the different back-end runners that Noodles provides. This is not so much a design driven by technology but by social considerations. The end user may expect an elegant, easy to understand, interface to a computational library. This user experience we refer to as eating of noodles.</p>\n\n<p>The computational library that is exposed to the user by means of Noodles needs to adhere to some design principles that are more strict than plain Python gives us. The library should follow a functional style of programming and is limited by the fact that function arguments need to pass through a layer where data is converted to and from a JSON format. The design of such a library is the cooking of noodles. As it is with ramen noodles, ofttimes the cook is also an avid consumer of noodles.</p>\n\n<p>The complexity of running a workflow in parallel on a wide variety of architectures is taken care of by the Noodles engine. This is the production of noodles which is left as an exercise for the Noodles dev-team at the Netherlands eScience Center.</p>\n", "discipline": ["Life Sciences & eHealth", "eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/vua"], "endorsedBy": ["/organization/nlesc"], "website": "http://nlesc.github.io/noodles/", "license": ["lgpl-3.0"], "nlescWebsite": "https://www.esciencecenter.nl/technology/software/noodles" }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2010-01-01", "contributor": ["/person/n.drost"], "tagLine": "Data Assimilation Toolbox", "slug": "openda", "contactPerson": "/person/n.drost", "user": ["/person/n.drost"], "title": "Openda", "discipline": ["Environment & Sustainability", "eScience Methodology"], "status": "active", "supportLevel": "basic", "name": "OpenDA", "endorsedBy": ["/organization/nlesc", "/organization/deltares"], "owner": [{ "name": "OpenDA Association" }], "programmingLanguage": ["Java"], "expertise": ["Data Assimilation"], "technologyTag": ["Calibration"], "usedIn": ["/project/ewatercycle", "/project/large-scale-data-assimilation"], "@id": "http://software.esciencecenter.nl/software/openda/", "description": "<p>OpenDA is an open interface standard for (and free implementation of) a set of tools to quickly implement data-assimilation and calibration for arbitrary numerical models. OpenDA wants to stimulate the use of data-assimilation and calibration by lowering the implementation costs and enhancing the exchange of software among researchers and end-users.\nA model that conforms to the OpenDA standard can use all the tools that are available in OpenDA. This allows experimentation with data-assimilation/calibration methods without the need for extensive programming. Reversely, developers of data-assimilation/calibration software that make their implementations compatible with the OpenDA interface will make their new methods usable for all OpenDA users (either for free or on a commercial basis).\nOpenDA has been designed for high performance. Hence, even large-scale models can use it. Also, OpenDA allows users to optimize the interaction between their model and the data-assimilation/calibration methods. Hence, data-assimilation with OpenDA can be as efficient as with custom-made implementations of data-assimilation methods.\nOpenDA is an Open Source project. Contributions are welcome from anyone wishing to participate in the further development of the OpenDA toolset.</p>\n", "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/tu-delft", "/organization/deltares"], "id": "/software/openda", "license": ["lgpl-3"], "competence": ["Optimized Data Handling"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2015-01-01", "contributor": null, "tagLine": "Open Knowledge Platform Delta Technology", "slug": "openearth", "contactPerson": null, "user": null, "title": "Openearth", "discipline": ["Environment & Sustainability"], "status": "active", "supportLevel": "specialized", "name": "OpenEarth", "endorsedBy": ["/organization/deltares"], "owner": [{ "name": "Deltares" }], "programmingLanguage": null, "expertise": ["Data Assimilation"], "technologyTag": null, "usedIn": null, "@id": "http://software.esciencecenter.nl/software/openearth/", "description": "<p><img src=\"https://publicwiki.deltares.nl/display/OET/KML+Screenshots\" alt=\"Screenshot of Open Earth\" title=\"Screenshot\" /> OpenEarth is a free and open source initiative to deal with Data, Models and Tools in earth science &amp; engineering projects, currently mainly marine &amp; coastal. In current practice, research, consultancy and construction projects \ncommonly spend a significant part of their budget to setup some basic infrastructure for data and knowledge management. Most of these efforts disappear again once the project is finished. As an alternative to these ad-hoc \napproaches, OpenEarth aims for a more continuous approach to data &amp; knowledge management. It provides a platform to archive, host and disseminate high quality data, state-of-the-art model systems and well-tested tools for \npractical analysis. Through this project-superseding approach, marine &amp; coastal engineers and scientists can learn from experiences in previous projects and each other. This may lead to considerable efficiency gains, both in terms \nof budget and time. The following papers describe the OpenEarth approach in more detail: Terra et Aqua, 2013, NCK 2012 &amp; WODCON 2010.</p>\n", "contributingOrganization": ["/organization/deltares"], "involvedOrganization": ["/organization/deltares"], "id": "/software/openearth", "license": ["custom"], "competence": ["Efficient Computing"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "title": "Openifs", "supportLevel": "advanced", "slug": "openifs", "programmingLanguage": ["FORTRAN"], "status": "active", "expertise": ["High Performance Computing"], "owner": [{ "name": "European Centre for Medium-Range Weather Forecasts (ECMWF)" }], "competence": ["Efficient Computing"], "user": ["/organization/knmi", "/organization/nlesc"], "technologyTag": ["Simulation"], "@id": "http://software.esciencecenter.nl/software/openifs/", "discipline": ["Environment & Sustainability"], "description": "<p>The OpenIFS programme at ECMWF provides academic and research institutions with an easy-to-use version of the ECMWF IFS (Integrated Forecasting System) (OpenIFS model), the single column model (SCM) and the offline-surface model (OSM). The OpenIFS model provides the full forecast capability of IFS, supporting software and documentation but without the data assimilation system. OpenIFS has a support team at ECMWF for technical assistance but limited resources for detailed scientific assistance.</p>\n", "contributingOrganization": ["/organization/ecmwf"], "tagLine": "Easy-to-use version of the ECMWF Integrated Forecasting System", "involvedOrganization": ["/organization/knmi", "/organization/nlesc"], "endorsedBy": ["/organization/knmi", "/organization/ecmwf"], "name": "OpenIFS", "license": ["Unknown"], "id": "/software/openifs" }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2013-04-12", "contributor": ["/person/s.verhoeven", "/person/j.borgdorff"], "tagLine": "Web service to submit jobs via a Xenon supported scheduler.", "slug": "osmium", "id": "/software/osmium", "contactPerson": "/person/s.verhoeven", "codeRepository": "https://github.com/NLeSC/osmium", "license": ["apache-2.0"], "user": ["/person/s.verhoeven", "/person/l.ridder"], "title": "Osmium", "dependencyOf": ["/software/magma"], "competence": ["Optimized Data Handling"], "status": "active", "supportLevel": "specialized", "dependency": ["/software/xenon"], "name": "Osmium", "owner": ["/organization/nlesc", "/organization/wur", "/person/s.verhoeven"], "downloadUrl": "https://github.com/NLeSC/osmium/releases", "programmingLanguage": ["Java"], "expertise": ["Distributed Computing"], "technologyTag": ["Distributed", "Webservice"], "usedIn": ["/project/emetabolomics"], "@id": "http://software.esciencecenter.nl/software/osmium/", "description": "<p>At the center we developed Xenon library which can be used to submit calculations to schedulers or batch queue systems on high performance computing infrastructure like clusters. Xenon requires Java programming knowledge. To make the Xenon schedulers available in other languages than Java a web service was made called Osmium. With Osmium calculations can be submitted using any programming language to any of the Xenon supported schedulers.</p>\n", "discipline": ["Physics & Beyond", "eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/wur"], "endorsedBy": ["/organization/nlesc"], "website": "https://github.com/NLeSC/osmium", "logo": "/images/software/osmium.png", "nlescWebsite": "https://www.esciencecenter.nl/technology/software/osmium" }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2016-01-25", "contributor": ["/person/e.ranguelova"], "tagLine": "image dataset for transformation-independant interest region detection", "slug": "oxfrei-dataset", "contactPerson": "/person/e.ranguelova", "doi": "http://dx.doi.org/10.5281/zenodo.45155", "user": ["/organization/nlesc"], "title": "Oxfrei Dataset", "competence": ["Big Data Analytics"], "status": "inactive", "supportLevel": "specialized", "name": "OxFrei dataset dataset", "owner": ["/organization/nlesc"], "expertise": ["Computer Vision"], "technologyTag": ["Dataset", "Computer Vision"], "usedIn": ["/software/salient-region-detectors"], "@id": "http://software.esciencecenter.nl/software/oxfrei-dataset/", "description": "<p>OxFrei is an imaging datset which combines the strong features of the well-known  Oxford and\nFreiburg datasets. It contains 54 images in 9 structured scenes\neach under realistic blur, lighting, scaling and viewpoint\ntransformations. This is achieved by transforming the Freiburg base images with all homographies of the Oxford dataset.</p>\n\n<p>The dataset allows a transformation-independent robustness\nstudy by comparing performance on all data subject to\nthe same realistic transformation.</p>\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "id": "/software/oxfrei-dataset", "license": ["cc-by"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2013-10-01", "contributor": ["/person/j.attema", "/person/l.buitinck", "/person/j.borgdorff", "/person/c.martinez"], "tagLine": "Reusable point cloud analytics software (segmentation, registration, file format conversion)", "slug": "pattyanalytics", "owner": ["/organization/nlesc"], "contactPerson": "/person/j.attema", "codeRepository": "https://github.com/NLeSC/PattyAnalytics", "user": ["/organization/nlesc", "/person/o.rubi"], "title": "Pattyanalytics", "competence": ["Big Data Analytics"], "status": "active", "dependency": ["/software/python-pcl"], "name": "PattyAnalytics", "supportLevel": "specialized", "programmingLanguage": ["Python"], "expertise": ["Databases", "Handling Sensor Data"], "technologyTag": ["Point clouds", "GIS", "PCL"], "usedIn": ["/project/viaappia-patty"], "@id": "http://software.esciencecenter.nl/software/pattyanalytics/", "description": "<p>Reusable point cloud analytics software. Includes segmentation, registration, file format conversion. This makes use of the python bindings of the Point Cloud Library (PCL; <a href=\"https://github.com/NLeSC/python-pcl\">https://github.com/NLeSC/python-pcl</a>).</p>\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "id": "/software/pattyanalytics", "license": ["apache-2.0"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2013-10-01", "contributor": ["/person/o.rubi", "/person/e.ranguelova", "/person/r.goncalves", "/person/r.vanharen"], "tagLine": "Data Management scripts for the Via Appia 3D GIS", "slug": "pattydata", "owner": ["/organization/nlesc"], "contactPerson": "/person/o.rubi", "codeRepository": "https://github.com/NLeSC/PattyData", "user": ["/organization/nlesc", "/person/o.rubi"], "title": "Pattydata", "competence": ["Optimized Data Handling"], "status": "active", "name": "PattyData", "supportLevel": "specialized", "programmingLanguage": ["Python"], "expertise": ["Databases", "Handling Sensor Data"], "technologyTag": ["Point clouds", "GIS", "Dataset"], "usedIn": ["/project/viaappia-patty"], "@id": "http://software.esciencecenter.nl/software/pattydata/", "description": "<p>This repository is related to the data management for the Via Appia 3d GIS.</p>\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "id": "/software/pattydata", "license": ["apache-2.0"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2013-01-01", "contributor": ["/person/p.bos", "/person/o.rubi", "/person/m.vanmeersbergen", "/person/s.verhoeven", "/person/m.kuzak", "/person/j.vanderzwaan", "/person/b.vanwerkhoven", "/person/l.kulik"], "tagLine": "WebGL point cloud visualization of the Via Appia based on potree", "slug": "pattyvis", "owner": ["/organization/nlesc"], "contactPerson": "/person/m.vanmeersbergen", "codeRepository": "https://github.com/NLeSC/pattyvis", "user": ["/organization/nlesc", "/person/o.rubi"], "title": "Pattyvis", "competence": ["Big Data Analytics"], "status": "active", "dependency": ["/software/potree", "/software/potreeconverter"], "name": "PattyVis", "supportLevel": "specialized", "programmingLanguage": ["JavaScript"], "expertise": ["Scientific Visualization"], "technologyTag": ["Point clouds", "WebGL", "GIS"], "usedIn": ["/project/viaappia-patty"], "@id": "http://software.esciencecenter.nl/software/pattyvis/", "description": "<p><a href=\"https://travis-ci.org/NLeSC/PattyVis\"><img src=\"https://travis-ci.org/NLeSC/PattyVis.svg?branch=master\" alt=\"Build Status\" /></a>\n<a href=\"https://codeclimate.com/github/NLeSC/PattyVis\"><img src=\"https://codeclimate.com/github/NLeSC/PattyVis/badges/gpa.svg\" alt=\"Code Climate\" /></a>\n<a href=\"https://codeclimate.com/github/NLeSC/PattyVis\"><img src=\"https://codeclimate.com/github/NLeSC/PattyVis/badges/coverage.svg\" alt=\"Test Coverage\" /></a>\n<a href=\"https://saucelabs.com/u/patty-vis\"><img src=\"https://saucelabs.com/buildstatus/patty-vis\" alt=\"Sauce Test Status\" /></a>\n<a href=\"https://david-dm.org/NLeSC/PattyVis#info=devDependencies\"><img src=\"https://david-dm.org/NLeSC/PattyVis/dev-status.svg\" alt=\"devDependency Status\" /></a>\n<a href=\"https://www.codacy.com/public/sverhoeven/PattyVis\"><img src=\"https://www.codacy.com/project/badge/a2ebd9977fe04aa1af6e5c47dc8d6927\" alt=\"Codacy Badge\" /></a>\n<a href=\"http://dx.doi.org/10.5281/zenodo.45923\"><img src=\"https://zenodo.org/badge/doi/10.5281/zenodo.45923.svg\" alt=\"DOI\" /></a></p>\n\n<h2 id=\"webgl-point-cloud-visualization-of-the-via-appia-based-on-httppotreeorg\">Webgl point cloud visualization of the Via Appia based on http://potree.org</h2>\n<p><img src=\"https://github.com/NLeSC/PattyVis/raw/master/DOCS/pattyvis_fp_ss4.png\" alt=\"logo\" title=\"A beautiful vista\" />\nA big step towards a 3D GIS Application.<br />\n<img src=\"https://github.com/NLeSC/PattyVis/raw/master/DOCS/pattyvis_fp_ss2.png\" alt=\"logo\" title=\"A big step towards a 3D GIS Application\" />\nWith 3D footprints of grave monuments based on GPS coordinates.<br />\n<img src=\"https://github.com/NLeSC/PattyVis/raw/master/DOCS/pattyvis_fp_ss1.png\" alt=\"logo\" title=\"With 3D footprints based on GPS coordinates\" />\nA \u2018background\u2019 or reference frame was made with Fugro\u2019s drive-map technology http://www.drive-map.eu/<br />\n<img src=\"https://github.com/NLeSC/PattyVis/raw/master/DOCS/pattyvis_fp_ss9.png\" alt=\"logo\" title=\"The drive map visualized\" />\nSeveral monuments have been photographed extensively and made into seperate point clouds. This is an ongoing process.<br />\n<img src=\"https://github.com/NLeSC/PattyVis/raw/master/DOCS/pattyvis_fp_ss5.png\" alt=\"logo\" title=\"Here you can see the drive-map and the site-specific photography based point cloud next to eachother\" />\n<img src=\"https://github.com/NLeSC/PattyVis/raw/master/DOCS/pattyvis_fp_ss3.png\" alt=\"logo\" title=\"A particularly well-captured monument.\" />\nMeasurements can be made in the 3D environment.<br />\n<img src=\"https://github.com/NLeSC/PattyVis/raw/master/DOCS/pattyvis_fp_ss8.png\" alt=\"logo\" title=\"Measurements can be made in the 3D environment.\" />\nHistorical maps can give extra information on the site\u2019s history.<br />\n<img src=\"https://github.com/NLeSC/PattyVis/raw/master/DOCS/pattyvis_fp_ss6.png\" alt=\"logo\" title=\"Historical maps can give extra information on the site's history.\" />\nSearching options like the material used in the site can give extra insight.<br />\n<img src=\"https://github.com/NLeSC/PattyVis/raw/master/DOCS/pattyvis_fp_ss7.png\" alt=\"logo\" title=\"Historical maps can give extra information on the site's history.\" /></p>\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/vua"], "id": "/software/pattyvis", "license": ["apache-2.0"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "title": "Paxer", "tagLine": "Processor for Analyzing XENON (PAX) is used for doing digital signal processing and other data processing on the XENON100/XENON1T raw data.", "slug": "paxer", "programmingLanguage": ["Python"], "description": "<p>Processor for Analyzing XENON (PAX) is used for doing digital signal processing and other data processing on the XENON100/XENON1T raw data.</p>\n", "expertise": ["Handling Sensor Data"], "user": ["/organization/nikhef"], "@id": "http://software.esciencecenter.nl/software/paxer/", "discipline": ["Physics & Beyond"], "contributingOrganization": ["/organization/nikhef"], "involvedOrganization": ["/organization/nikhef"], "name": "PAX", "id": "/software/paxer" }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2011-01-01", "contributor": ["/person/o.rubi"], "tagLine": "C++ Library for translating and manipulating point cloud data.", "slug": "pdal", "contactPerson": "/person/o.rubi", "codeRepository": "http://www.pdal.io/", "user": ["/organization/nlesc", "/person/o.rubi"], "title": "Pdal", "competence": ["Big Data Analytics"], "status": "active", "name": "PDAL", "supportLevel": "specialized", "programmingLanguage": ["C++"], "expertise": null, "technologyTag": ["Point clouds", "Library"], "usedIn": ["/project/massive-point-clouds-for-esciences"], "@id": "http://software.esciencecenter.nl/software/pdal/", "description": "<p>PDAL is a C++ BSD library for translating and manipulating point cloud data. It is very much like the GDAL library which handles raster and vector data.</p>\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "id": "/software/pdal", "license": ["bsd-2-clause"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2012-06-12", "contributor": ["/person/j.borgdorff", { "affiliation": ["/organization/surfsara"], "name": "Jan Bot" }, { "affiliation": ["/organization/surfsara"], "name": "Maarten Kooyman" }, { "affiliation": ["/organization/surfsara"], "name": "Anatoli Danezi" }], "tagLine": "Simple distributed task execution framework using a CouchDB database", "slug": "picas", "contactPerson": "/person/j.borgdorff", "codeRepository": "https://github.com/sara-nl/picasclient", "user": ["/person/j.borgdorff"], "title": "Picas", "dependencyOf": ["/software/couchdb"], "competence": ["Efficient Computing"], "status": "active", "supportLevel": "specialized", "dependency": ["/software/couchdb"], "name": "picas", "owner": ["/organization/surfsara"], "programmingLanguage": ["Python"], "expertise": ["Distributed Computing"], "technologyTag": ["Distributed", "Library", "CouchDB"], "usedIn": ["/project/simcity"], "@id": "http://software.esciencecenter.nl/software/picas/", "description": "<p>PiCaS is a simple task execution framework using a CouchDB database. All tasks\nare stored in a single database, before, during, and after processing, thereby\nkeeping a log of all actions.</p>\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/surfsara"], "license": ["mit"], "id": "/software/picas" }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2014-08-01", "contributor": ["/person/p.bos", "/person/l.buitinck"], "tagLine": "A collection of scripts used in the PIDIMEHS project", "slug": "pidilib", "id": "/software/pidilib", "contactPerson": "/person/p.bos", "codeRepository": "https://bitbucket.org/egpbos/pidilib", "user": ["/organization/university.of.groningen"], "title": "Pidilib", "dependencyOf": null, "competence": ["Big Data Analytics"], "documentationUrl": null, "supportLevel": "advanced", "dependency": null, "name": "PIDIlib", "owner": ["/organization/nlesc"], "programmingLanguage": ["Python"], "status": "inactive", "expertise": ["Text Mining", "Information Retrieval", "Information Visualization", "Data Assimilation"], "technologyTag": ["Elasticsearch"], "usedIn": ["/project/pidimehs"], "@id": "http://software.esciencecenter.nl/software/pidilib/", "description": "<p>PIDIlib is a collection of scripts used in the PIDIMEHS project. It is mainly provided to showcase the possibilities of combining Elasticsearch, Pandas and Matplotlib in Python in the study of history of politics and media. PIDIlib\u2019s main contents are:</p>\n\n<ul>\n  <li>Ways of querying the PIDIMEHS KB newspaper Elasticsearch instance</li>\n  <li>Using Pandas to analyze the queried aggregations</li>\n  <li>Visualization using Matplotlib</li>\n  <li>Data used for \u2018indicators of pillarization\u2019 in the PIDIMEHS project</li>\n  <li>Jupyter notebooks that were used to produce the results presented in the PIDIMEHS technical paper.</li>\n</ul>\n\n<p>The KB newspaper data can be freely obtained from <a href=\"www.delpher.nl\">Delpher</a>. It is not allowed to redistribute this data, so we cannot give access to our own instance. To use PIDIlib, one will have to set up their own Elasticsearch instance. Alternatively, one may contact the KB or SURFsara to request access to the SURFsara instance (which we used as well).</p>\n", "logo": null, "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/university.of.groningen", "/organization/uva", "/organization/surfsara"], "nlescWebsite": null, "endorsedBy": ["/organization/nlesc"], "website": null, "license": ["apache-2.0"], "discipline": ["Humanities & Social Sciences"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2011-01-01", "contributor": ["/person/m.vanmeersbergen", "/person/o.rubi", "/person/s.verhoeven"], "tagLine": "WebGL point cloud viewer", "slug": "potree", "contactPerson": "/person/m.vanmeersbergen", "codeRepository": "https://github.com/potree/potree", "user": ["/organization/nlesc", "/person/o.rubi"], "title": "Potree", "dependencyOf": ["/software/ahn2webviewer", "/software/massivepotreeconverter", "/software/pattyvis"], "competence": ["Big Data Analytics"], "status": "active", "supportLevel": "specialized", "name": "Potree", "owner": ["/organization/potree"], "programmingLanguage": ["JavaScript"], "expertise": ["Scientific Visualization"], "technologyTag": ["Point clouds", "WebGL", "Website"], "usedIn": ["/project/massive-point-clouds-for-esciences", "/project/viaappia-patty"], "@id": "http://software.esciencecenter.nl/software/potree/", "description": "<p>WebGL point cloud viewer for large datasets (<a href=\"http://potree.org\">http://potree.org</a>)</p>\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/potree"], "id": "/software/potree", "license": ["bsd-2-clause"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2011-01-01", "contributor": ["/person/o.rubi"], "tagLine": "Generation of multi-resolution octrees (required by Potree-based renderers)", "slug": "potreeconverter", "owner": ["/organization/potree"], "contactPerson": "/person/o.rubi", "codeRepository": "https://github.com/potree/PotreeConverter", "user": ["/organization/nlesc", "/person/o.rubi"], "title": "Potreeconverter", "dependencyOf": ["/software/ahn2webviewer", "/software/massivepotreeconverter", "/software/pattyvis"], "competence": ["Optimized Data Handling"], "status": "active", "name": "PotreeConverter", "supportLevel": "specialized", "programmingLanguage": ["C++"], "expertise": ["Scientific Visualization"], "technologyTag": ["Point clouds", "Library"], "usedIn": ["/project/massive-point-clouds-for-esciences", "/project/viaappia-patty"], "@id": "http://software.esciencecenter.nl/software/potreeconverter/", "description": "<p>Builds a potree octree from las, laz, binary ply, xyz or ptx files. This is required by any Potree-based renderer. For massive point clouds use the Massive-PotreeConverter (&lt;/software/massivepotreeconverter&gt;)</p>\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/potree"], "id": "/software/potreeconverter", "license": ["bsd-2-clause"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2015-11-17", "contributor": ["/person/j.spaaks", "/person/f.diblen", "/person/j.hidding", "/person/m.kuzak", "/person/l.veen"], "tagLine": "Timeline visualisation using punchcards.", "slug": "punchcardjs", "contactPerson": "/person/j.spaaks", "codeRepository": "https://github.com/nlesc-sherlock/punchcardjs", "user": ["/organization/nlesc", "/organization/nfi", "/person/j.spaaks"], "title": "Punchcardjs", "competence": ["Big Data Analytics"], "documentationUrl": "http://nlesc-sherlock.github.io/punchcardjs/sites/tsdoc/", "supportLevel": "specialized", "name": "punchcardjs", "description": "<p>TypeScript library to visualize timeline data using punchcard maps.</p>\n", "owner": ["/organization/nlesc"], "programmingLanguage": ["TypeScript"], "expertise": ["Information Visualization", "Scientific Visualization"], "technologyTag": ["Visualization", "Website", "Timeline"], "usedIn": ["/project/sherlock"], "@id": "http://software.esciencecenter.nl/software/punchcardjs/", "license": ["apache-2.0"], "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "id": "/software/punchcardjs", "website": "https://github.com/nlesc-sherlock/punchcardjs", "status": "active", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "contributor": ["/person/o.rubi"], "tagLine": "pycoeman (Python Commands Execution Manager) is a Python toolkit for executing command-line commands.", "slug": "pycoeman", "contactPerson": "/person/o.rubi", "codeRepository": "https://github.com/NLeSC/pycoeman", "license": ["apache-2.0"], "user": ["/person/o.rubi"], "title": "Pycoeman", "dependencyOf": ["/software/pymicmac"], "competence": ["Efficient Computing"], "status": "active", "supportLevel": "specialized", "dependency": null, "name": "pycoeman", "owner": ["/organization/nlesc"], "downloadUrl": "https://github.com/NLeSC/pycoeman", "programmingLanguage": ["Python"], "expertise": ["Distributed Computing"], "technologyTag": ["Distributed", "workflow", "Library"], "usedIn": ["/project/improving-photogrammetry"], "@id": "http://software.esciencecenter.nl/software/pycoeman/", "description": "<p>Python Commands Execution Manager</p>\n\n<p>pycoeman is a Python toolkit for executing command-line commands. It allows the execution of:</p>\n\n<ul>\n  <li>\n    <p>Sequential commands: this is a chain of command-line commands which will be executed one after the other. In other words, this is a set of commands that you would traditionally execute in a Bash script. Normally there are IO dependencies between commands (one command requires the output from one or previous ones).</p>\n  </li>\n  <li>\n    <p>Parallel commands: this is a set of command-line commands which are executed in parallel. In other words, this is a set of commands that you would traditionally execute in a Bash script with all the commands as background jobs (with the &amp; at the end). There cannot be IO dependencies between commands. This is can be useful for pleasingly parallel solutions, i.e. tools which are single-core at programming level but can be parallelized at data level and usually require some final merging process.</p>\n  </li>\n</ul>\n\n<p>pycoeman adds CPU/MEM/disk monitoring during the execution of the commands and it allows to create clean execution environments for easier management of your executions (the commands will be executed in different folders separated from where the input data is). pycoeman has tools to run both sequential and parallel commands locally (in the local computer), and also to run parallel commands in a set of remote hosts accessible via SSH as well as in SGE clusters (computer clusters with Sun Grid Engine batch-queuing system). pycoeman is configured using XML files.</p>\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "startDate": "2016-07-25", "id": "/software/pycoeman" }, { "schema": "http://software.esciencecenter.nl/schema/software", "title": "Pycrtools", "contributor": [{ "affiliation": ["/organization/astron"], "name": "M. Vandenakker" }], "tagLine": "Python wrapper around CR-Tools", "slug": "pycrtools", "programmingLanguage": ["Python"], "description": "<p>Python wrapper around CR-Tools.</p>\n", "@id": "http://software.esciencecenter.nl/software/pycrtools/", "discipline": ["Physics & Beyond"], "contributingOrganization": ["/organization/astron", "/organization/radboud.university.nijmegen"], "dependency": ["/software/cr-tools"], "website": "http://www.astro.ru.nl/software/pycrtools", "name": "PyCRTools", "id": "/software/pycrtools" }, { "schema": "http://software.esciencecenter.nl/schema/software", "contributor": ["/person/o.rubi"], "tagLine": "pymicmac provides a python interface for MicMac workflows execution and distributed computing tools for MicMac.", "slug": "pymicmac", "contactPerson": "/person/o.rubi", "codeRepository": "https://github.com/ImproPhoto/pymicmac", "license": ["apache-2.0"], "user": ["/person/o.rubi"], "title": "Pymicmac", "dependencyOf": null, "competence": ["Optimized Data Handling"], "status": "active", "supportLevel": "specialized", "dependency": ["/software/pycoeman", "/software/noodles"], "name": "pymicmac", "owner": ["/organization/nlesc"], "downloadUrl": "https://github.com/ImproPhoto/pymicmac", "programmingLanguage": ["Python"], "expertise": ["Distributed Computing"], "technologyTag": ["Distributed", "workflow", "Library", "Point clouds"], "usedIn": ["/project/improving-photogrammetry"], "@id": "http://software.esciencecenter.nl/software/pymicmac/", "description": "<p>pymicmac provides a python interface for MicMac workflows execution and distributed computing tools for MicMac. pymicmac uses pycoeman (Python Commands Execution Manager) (https://github.com/NLeSC/pycoeman) which also provides CPU/MEM/disk monitoring.</p>\n\n<p>MicMac is a photogrammetric suite which contains many different tools to execute photogrammetric workflows. In short, a photogrammetric workflow contains at least:</p>\n\n<p>(1) tie-point detection: extraction of key features in images and cross-match between different images to detect tie-points (points in the images that represent the same physical locations).</p>\n\n<p>(2) Estimation of camera positions and orientations and of calibration parameters: mainly the bundle adjustment but may include some preparation and/or refinement steps.</p>\n\n<p>(3) Dense-matching point cloud generation. 3D projection of image pixels to produce the dense point cloud.</p>\n\n<p>pymicmac provides the tool micmac-run-workflow to run photogrammetric workflows with a sequence of MicMac commands. The tool uses the sequential commands execution tool of pycoeman which is configured with a XML configuration file that defines a chain of MicMac commands to be executed sequentially.</p>\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "startDate": "2016-05-03", "id": "/software/pymicmac" }, { "schema": "http://software.esciencecenter.nl/schema/software", "title": "Pyroot", "tagLine": "A Python extension module that allows the user to interact with any ROOT class from the Python interpreter.", "slug": "pyroot", "programmingLanguage": ["C++, Python"], "description": "<p>PyROOT is a Python extension module that allows the user to interact with any ROOT class from the Python interpreter.</p>\n", "expertise": ["Data Assimilation"], "user": ["/organization/nikhef"], "usedIn": ["/project/pandas-root"], "@id": "http://software.esciencecenter.nl/software/pyroot/", "discipline": ["Physics & Beyond"], "contributingOrganization": ["/organization/nikhef"], "supportLevel": "specialized", "involvedOrganization": ["/organization/nikhef"], "id": "/software/pyroot", "dependency": ["ROOT"], "name": "PyROOT", "competence": ["Big Data Analytics"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2014-10-01", "contributor": ["/person/j.attema", "/person/l.buitinck", "/person/j.borgdorff", "/person/c.martinez"], "tagLine": "Python bindings to Point Cloud Library (PCL)", "slug": "python-pcl", "owner": ["/organization/nlesc"], "contactPerson": "/person/j.attema", "codeRepository": "https://github.com/NLeSC/python-pcl", "user": ["/organization/nlesc", "/person/o.rubi"], "title": "Python Pcl", "dependencyOf": ["/software/pattyanalytics"], "competence": ["Big Data Analytics"], "status": "active", "name": "python-pcl", "supportLevel": "specialized", "programmingLanguage": ["Python"], "expertise": ["Handling Sensor Data"], "technologyTag": ["Point clouds"], "usedIn": ["/project/viaappia-patty"], "@id": "http://software.esciencecenter.nl/software/python-pcl/", "description": "<p>This is a small python binding to the pointcloud library. Currently, the following parts of the API are wrapped (all methods operate on PointXYZRGB) point types</p>\n\n<ul>\n  <li>I/O and integration; saving and loading PCD files</li>\n  <li>segmentation</li>\n  <li>SAC</li>\n  <li>smoothing</li>\n  <li>filtering</li>\n</ul>\n\n<p>The code tries to follow the Point Cloud API, and also provides helper function for interacting with NumPy.</p>\n\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "id": "/software/python-pcl", "license": ["apache-2.0"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "contributor": ["/person/j.borgdorff", "/person/j.hidding", "/person/s.verhoeven"], "tagLine": "Python wrapper for the Xenon programming interface to various compute and storage resources.", "slug": "pyxenon", "contactPerson": "/person/j.borgdorff", "doi": "http://dx.doi.org/10.5281/zenodo.60929", "license": ["apache-2.0"], "user": ["/person/j.borgdorff", "/person/j.hidding", "/person/r.vanharen"], "title": "Pyxenon", "dependencyOf": ["/software/noodles", "/software/wrfpy"], "competence": ["Efficient Computing"], "status": "active", "supportLevel": "specialized", "dependency": ["/software/xenon"], "name": "pyxenon", "codeRepository": "https://github.com/NLeSC/pyxenon", "owner": ["/organization/nlesc"], "downloadUrl": "https://pypi.python.org/pypi/pyxenon", "programmingLanguage": ["Python"], "expertise": ["Distributed Computing"], "technologyTag": ["Distributed", "Library"], "usedIn": ["/project/simcity", "/project/era-urban"], "@id": "http://software.esciencecenter.nl/software/pyxenon/", "description": "<p>Xenon is a middleware abstraction library. It provides a simple\nprogramming interface to various pieces of software that can be used to\naccess distributed compute and storage resources. pyxenon is the Python\nwrapper to Xenon.</p>\n\n<h1 id=\"why-xenon\">Why Xenon?</h1>\n\n<p>Xenon is developed by the Netherlands eScience Center as a support\nlibrary for our projects. Several projects develop end-user applications\nthat require access to distributed compute and storage resources. Xenon\nprovides a simple API to access those resources, allowing those\napplications to be developed more rapidly. The experience gained during\nthe development of these end-user applications is used to improve the\nXenon API and implementation.</p>\n", "discipline": ["Physics & Beyond", "eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "id": "/software/pyxenon", "startDate": "2015-11-29", "endorsedBy": ["/organization/nlesc"] }, { "@id": "http://software.esciencecenter.nl/software/rascal/", "schema": "http://software.esciencecenter.nl/schema/software", "documentationUrl": "http://www.rascal-mpl.org/help/", "tagLine": "Rascal is a domain specific language for source code analysis and manipulation, also known as meta-programming.", "slug": "rascal", "downloadUrl": "http://www.rascal-mpl.org/start/", "programmingLanguage": ["Java"], "license": [], "codeRepository": "https://github.com/usethesource/rascal", "expertise": ["Information Integration", "Reproducible Research"], "description": "<p>Rascal is a domain specific language for source code analysis and manipulation, also known as meta-programming. CWI researchers have started the design in 2010. It is currently being developed and tested at CWI. Rascal is a programming language; such that meta programs can be created by, understood by, and debugged by programmers.  Rascal primitives include immutable data, context-free grammars and algebraic data-types, relations, relational calculus operators, advanced patterns matching, generic type-safe traversal, comprehensions, concrete syntax for objects, lexically scoped backtracking, and string templates for code generation. It has libraries for integrating language front-ends, for reusing analysis algorithms, for getting typed meta-data out of version management systems, for interactive visualization, etc.</p>\n\n", "id": "/software/rascal", "title": "Rascal", "discipline": ["eScience Methodology"], "logo": "https://www.cwi.nl/system/files/u207/rascal-logo-3.jpg", "contributingOrganization": ["https://www.esciencecenter.nl/technology/organization/cwi"], "endorsedBy": [], "name": "Rascal Metaprogramming Language", "website": "http://www.rascal-mpl.org/", "nlescWebsite": "https://www.esciencecenter.nl/technology/software/rascal", "competence": ["Optimized Data Handling", "Efficient Computing"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "tagLine": "RDKit is a collection of cheminformatics and machine-learning software written in C++ and Python.", "slug": "rdkit", "codeRepository": "https://github.com/rdkit/rdkit", "license": ["bsd-3-clause"], "title": "Rdkit", "dependencyOf": ["/software/magma"], "competence": ["Optimized Data Handling"], "documentationUrl": "http://rdkit.org/docs/index.html", "status": "active", "name": "RDKit", "downloadUrl": "http://sourceforge.net/projects/rdkit/files", "programmingLanguage": ["Python", "C++"], "expertise": ["Data Assimilation"], "technologyTag": ["Library", "Chemistry"], "usedIn": ["/project/emetabolomics", "/project/3d-e-chem"], "@id": "http://software.esciencecenter.nl/software/rdkit/", "description": "<p>RDKit is a collection of cheminformatics and machine-learning software written in C++ and Python.</p>\n\n<p>It is used in eMetabolomics project to perform reactions.</p>\n\n<p>It is used in 3D-e-Chem project to visualize molecules in KNIME and to store molecules in SQLite.</p>\n", "discipline": ["Life Sciences & eHealth"], "endorsedBy": ["/organization/nlesc"], "website": "http://rdkit.org/", "logo": "http://rdkit.org/Images/logo.png", "id": "/software/rdkit" }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2015-03-27", "contributor": [{ "affiliation": ["/organization/university.of.southampton"], "website": "http://www.rtwilson.com", "name": "Robin Wilson" }, "/person/j.vanderzwaan"], "tagLine": "Effortless provenance in Python", "slug": "recipy", "contactPerson": "/person/j.vanderzwaan", "codeRepository": "https://github.com/recipy/recipy", "competence": ["Big Data Analytics"], "user": ["/organization/nlesc"], "title": "Recipy", "discipline": ["eScience Methodology"], "status": "active", "supportLevel": "advanced", "name": "ReciPy", "owner": [{ "affiliation": ["/organization/university.of.southampton"], "website": "http://www.rtwilson.com", "name": "Robin Wilson" }, "/organization/nlesc"], "programmingLanguage": ["Python"], "expertise": ["Reproducible Research"], "technologyTag": ["Provenance"], "@id": "http://software.esciencecenter.nl/software/recipy/", "description": "<p>Imagine the situation: You\u2019ve written some wonderful Python code which produces a beautiful graph as an output. You save that graph, naturally enough, as \u201cgraph.png\u201d. You run the code a couple of times, each time making minor modifications. You come back to it the next week/month/year. Do you know how you created that graph? What input data? What version of your code? If you\u2019re anything like me then the answer will often, frustratingly, be \u201cno\u201d. Of course, you then waste lots of time trying to work out how you created it, or even give up and never use it in that journal paper that will win you a Nobel Prize\u2026</p>\n\n<p>ReciPy (from <em>recipe</em> and <em>python</em>) is a Python module that will save you from this situation! (Although it can\u2019t guarantee that your resulting paper will win a Nobel Prize!) With the addition of a single line of code to the top of your Python files, ReciPy will log each run of your code to a database, keeping track of the input files, output files and the version of your code, and then let you query this database to find out how you actually did create \u201cgraph.png\u201d.</p>\n\n<p>When you import recipy it adds a number of classes to \u201csys.meta_path\u201d. These are then used by Python as part of the importing procedure for modules. The classes that we add are classes derived from \u201cPatchImporter\u201d, often using the easier interface provided by \u201cPatchSimple\u201d, which allow us to wrap functions that do input/output in a function that calls recipy first to log the information.</p>\n\n<p>Currently, ReciPy provides patches for:</p>\n\n<ul>\n  <li>numpy</li>\n  <li>pandas</li>\n  <li>matplotlib.pyplot</li>\n  <li>gdal</li>\n  <li>sklearn</li>\n  <li>nibabel</li>\n</ul>\n", "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "id": "/software/recipy", "license": ["apache-2.0"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "contributor": ["/person/j.vanderzwaan", "/person/w.vanhage", "/person/o.rubi", "/person/l.buitinck"], "tagLine": "Big data cleaning toolkit", "slug": "rig", "contactPerson": "/person/j.vanderzwaan", "codeRepository": "https://github.com/nlesc-sherlock/Rig", "license": ["apache-2.0"], "user": ["/organization/nlesc"], "title": "Rig", "competence": ["Big Data Analytics"], "status": "active", "supportLevel": "specialized", "name": "Rig", "owner": ["/organization/nlesc"], "programmingLanguage": ["Python", "JavaScript"], "expertise": ["Text Mining", "Information Visualization", "Databases", "Distributed Computing"], "technologyTag": ["Spark"], "usedIn": ["/project/sherlock"], "@id": "http://software.esciencecenter.nl/software/rig/", "discipline": ["eScience Methodology"], "description": "<p>Every data analysis project starts with exploring and cleaning data. For tabular data, there are some tools available that facilitate data pre-processing, such as OpenRefine and Trifacta Wrangler. However, these tools one big disadvantage; they don\u2019t scale to really big data sets. Also, Trifacta Wrangler is not open source. For full text data, no tools for data cleanup exist.</p>\n\n<p>The goal of the data cleaning toolkit subproject is to create a data cleaning toolkit that is open source, supports both tabular data and full text pre-processing, and scales to big data sets. The frontend is a web interface that supports loading the data and creating workflows. Based on user input, it generates scripts that are send to the backend for execution. The backend relies on spark to ensure scalability.</p>\n\n<p>Because building a complete toolkit is is rather ambitious, we focus on the use case of vocabulary cleanup for full text data. When working with full text data, pre-processing often consists of tokenizing texts (i.e., splitting them into words), lematizing or stemming the tokens, and performing some kind of filtering to remove typo\u2019s and other unwanted tokens. The data cleaning toolkit should support customizing these tasks, and provide visualizations that facilitate vocabulary cleanup.</p>\n", "logo": "/images/software/rig.png", "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "endorsedBy": ["/organization/nlesc"], "startDate": "2016-02-16", "id": "/software/rig" }, { "schema": "http://software.esciencecenter.nl/schema/software", "title": "Roofit", "contributor": ["/person/p.bos"], "tagLine": "The Toolkit for Data Modeling with ROOT allows for modeling probability distributions in a compact and abstract way.", "slug": "roofit", "programmingLanguage": ["C++"], "contactPerson": "/person/p.bos", "codeRepository": "https://github.com/nlesc/root-roofit-dev", "expertise": ["High Performance Computing", "Data Assimilation"], "user": ["/organization/nikhef"], "usedIn": ["/project/automated-parallel-calculation-of-collaborative-statistical-models"], "@id": "http://software.esciencecenter.nl/software/roofit/", "competence": ["Big Data Analytics"], "description": "<p>RooFit is a module in the ROOT package that allows for the interactive and flexible modeling of complex physical processes and the subsequent fitting of physical parameters to collision data from particle physics experiments. A prime current example is the Higgs boson experiment carried out by the ATLAS and CMS detectors at CERN.</p>\n", "contributingOrganization": ["/organization/nikhef", "/organization/nlesc"], "involvedOrganization": ["/organization/nikhef"], "id": "/software/roofit", "dependency": ["ROOT"], "name": "RooFit", "discipline": ["Physics & Beyond"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "contributor": ["/person/d.remenska", "/person/s.verhoeven"], "tagLine": "Conda recipes for building CERN ROOT binaries and its dependencies, with Python 3 support. It provides a \"pythonic\" interface (pandas DataFrames) to the ROOT I/O format.", "slug": "root-conda-recipes", "id": "/software/root-conda-recipes", "contactPerson": "/person/d.remenska", "codeRepository": "http://github.com/NLeSC/root-conda-recipes", "badges": ["[![Build Status](https://api.travis-ci.org/NLeSC/root-conda-recipes.svg)](https://travis-ci.org/NLeSC/root-conda-recipes/)", "[![DOI](https://zenodo.org/badge/20885/NLeSC/root-conda-recipes.svg)](https://zenodo.org/badge/latestdoi/20885/NLeSC/root-conda-recipes)", "[![Join the chat at https://gitter.im/NLeSC/root-conda-recipes](https://badges.gitter.im/NLeSC/root-conda-recipes.svg)](https://gitter.im/NLeSC/root-conda-recipes?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)"], "user": ["/organization/nikhef"], "title": "Root Conda Recipes", "dependencyOf": null, "competence": ["Efficient Computing"], "documentationUrl": "http://www.gitbook.com/book/nlesc/cern-root-conda-recipes/details", "doi": "http://dx.doi.org/10.5281/zenodo.47512", "supportLevel": "specialized", "dependency": ["ROOT", "root-numpy", "rootpy"], "name": "ROOT-conda-recipes", "owner": ["/person/d.remenska"], "downloadUrl": "http://github.com/NLeSC/root-conda-recipes/archive/master.zip", "programmingLanguage": ["Python"], "status": "active", "expertise": ["Distributed Computing"], "technologyTag": ["Anaconda", "pandas DataFrame", "Computing model"], "usedIn": ["/project/pandas-root"], "@id": "http://software.esciencecenter.nl/software/root-conda-recipes/", "description": "<p>This repository contains Conda recipes for building CERN <a href=\"https://root.cern.ch/\">ROOT</a> binaries and its dependencies. For the needs of the <a href=\"http://www.xenon1t.org/\">XENON Dark Matter project</a>, the goal is to provide a \u201cpythonic\u201d interface to the ROOT I/O format, primarily for loading and saving Pandas dataframes in the ROOT format. For this purpose, there are also recipes for building conda binaries of <a href=\"https://github.com/rootpy/root_numpy\">root-numpy</a> and <a href=\"https://github.com/rootpy/rootpy\">rootpy</a>, the community-driven initiative to provide a more pythonic interface with ROOT on top of the existing PyROOT bindings.</p>\n\n<p>The most most important thing for making things work out of the box is the ABI (binary) compatibility between different gcc(libstdc++)/glibc library versions, on various linux distributions. Typically ROOT would even complain when the GCC headers are not of the same version as the one used for building it, so <em>shipping the full GCC and glibc as a run dependency</em> of ROOT, seemed like the best solution.</p>\n\n<p>Combine this with the fact that ROOT 6 requires GCC&gt;=4.8, while we want things to work on older platforms with no \u201csudo\u201d required, <strong>we decided to fix our GCC distribution to (a relatively recent one) 4.8.2, built against a rather old glibc version 2.12</strong>, making it as cross platform as possible.</p>\n\n<p>Working ROOT has been tested on: Ubuntu 11.10, 12.04, 14.04, 15.04, SLC-6.7, SLC-7. Please try it out and let us know if you experience problems.</p>\n\n", "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nikhef"], "nlescWebsite": "http://www.esciencecenter.nl/technology/software/root-conda-recipes", "endorsedBy": ["/organization/nlesc"], "website": "http://www.gitbook.com/book/nlesc/cern-root-conda-recipes/details", "license": ["apache-2.0"], "discipline": ["Physics & Beyond"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "title": "Root", "tagLine": "An object-oriented software framework with the functionalities needed to deal with big data processing, statistical analysis, visualisation and storage.", "slug": "root", "programmingLanguage": ["C++"], "description": "<p>A modular scientific software framework. It provides all the functionalities needed to deal with big data processing, statistical analysis, visualisation and storage. It is mainly written in C++ but integrated with other languages such as Python and R.</p>\n\n", "expertise": ["Data Assimilation"], "user": ["/organization/nikhef"], "usedIn": ["/project/pandas-root", "/project/automated-parallel-calculation-of-collaborative-statistical-models"], "@id": "http://software.esciencecenter.nl/software/root/", "discipline": ["Physics & Beyond"], "contributingOrganization": ["/organization/nikhef"], "involvedOrganization": ["/organization/nikhef"], "id": "/software/root", "name": "ROOT", "competence": ["Big Data Analytics"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2015-04-01", "contributor": ["/person/e.ranguelova", "/person/d.vankuppevelt"], "tagLine": "Software package for detecting salient regions in images.", "slug": "salient-region-detectors", "id": "/software/salient-region-detectors", "contactPerson": "/person/e.ranguelova", "codeRepository": "https://github.com/NLeSC/SalientDetector-python", "user": ["/organization/nlesc"], "title": "Salient Region Detectors", "dependencyOf": null, "competence": ["Big Data Analytics"], "documentationUrl": "http://nlesc.github.io/SalientDetector-python", "supportLevel": "specialized", "dependency": null, "name": "Salient Region Detectors", "owner": ["/organization/nlesc"], "programmingLanguage": ["Python", "MATLAB"], "status": "wip", "expertise": ["Computer Vision"], "technologyTag": ["OpenCV"], "usedIn": null, "@id": "http://software.esciencecenter.nl/software/salient-region-detectors/", "description": "<p>This package provide functionality to detect salient regions in images. Salient regions, or features, are regions in the image that are \u2018interesting\u2019, such as corners, lines and blobs. The detectors in this package specifically find blob-like regions. The detected regions could be used, for example, to match photos of the same object, taken under different conditions. These salient regions are invariant under transformations such as blurring, light change and rotation.</p>\n\n<p>The software is implemented both in MATLAB and Python.</p>\n", "logo": null, "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "endorsedBy": ["/organization/nlesc"], "website": null, "license": ["apache-2.0"], "discipline": ["eScience Methodology"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2013-10-01", "contributor": ["/person/n.drost", "/person/j.spaaks", "/person/j.maassen"], "tagLine": "Structure from Motion pipeline (from images to point clouds)", "slug": "sfm", "owner": ["/organization/nlesc"], "contactPerson": "/person/n.drost", "codeRepository": "https://github.com/NLeSC/structure-from-motion", "user": ["/organization/nlesc", "/person/o.rubi"], "title": "Sfm", "competence": ["Efficient Computing"], "status": "active", "name": "Structure-From-Motion", "supportLevel": "specialized", "programmingLanguage": ["Python", "C++"], "expertise": ["Handling Sensor Data", "High Performance Computing"], "technologyTag": ["Point clouds", "Photogrammetry"], "usedIn": ["/project/viaappia-patty"], "@id": "http://software.esciencecenter.nl/software/sfm/", "description": "<p>This repo contains a complete Structure from Motion pipeline. Structure from Motion is a technique to construct a 3d point cloud from a set of images (or a video) of an object. The software in this repository relies heavily on a number of third party libaries, notably Bundler, CMVS, PMVS, and SIFT.</p>\n", "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "id": "/software/sfm", "license": ["apache-2.0"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2015-11-17", "contributor": ["/person/j.spaaks", "/person/f.diblen", "/person/j.hidding", "/person/m.kuzak", "/person/l.veen"], "tagLine": "Time line data visualization using spiral charts.", "slug": "spiraljs", "contactPerson": "/person/j.spaaks", "codeRepository": "https://github.com/nlesc-sherlock/spiraljs", "user": ["/organization/nlesc", "/organization/nfi", "/person/j.spaaks"], "title": "Spiraljs", "competence": ["Big Data Analytics"], "documentationUrl": "http://nlesc-sherlock.github.io/spiraljs/sites/tsdoc", "supportLevel": "specialized", "name": "spiraljs", "description": "<p>TypeScript library to visualize seasonal time line data on a spiral chart.</p>\n", "owner": ["/organization/nlesc"], "programmingLanguage": ["TypeScript"], "expertise": ["Information Visualization", "Scientific Visualization"], "technologyTag": ["Visualization", "Website", "Timeline"], "usedIn": ["/project/sherlock"], "@id": "http://software.esciencecenter.nl/software/spiraljs/", "license": ["apache-2.0"], "discipline": ["eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "id": "/software/spiraljs", "website": "https://github.com/nlesc-sherlock/spiraljs", "status": "active", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2014-12-18", "contributor": ["/person/m.vanmeersbergen", "/person/j.vanderzwaan"], "tagLine": "Visualizing complex humanities data", "slug": "storyteller", "id": "/software/storyteller", "contactPerson": "/person/m.vanmeersbergen", "codeRepository": "https://github.com/NLeSC/UncertaintyVisualization", "user": ["/organization/nlesc"], "title": "Storyteller", "dependencyOf": null, "competence": ["Big Data Analytics"], "documentationUrl": null, "supportLevel": "specialized", "dependency": null, "name": "StoryTeller", "owner": ["/organization/nlesc"], "programmingLanguage": ["Python", "JavaScript"], "status": "active", "expertise": ["Information Visualization", "Text Mining"], "technologyTag": ["Data-Driven Documents (D3.js)", "Crossfilter", "dc.js"], "usedIn": ["/project/visualizing-uncertainty-and-perspectives"], "@id": "http://software.esciencecenter.nl/software/storyteller/", "description": "<p>Storyteller, a visualization tool that helps to analyze complex, multilayered data. This is accomplished by allowing the user to interactively explore the data by adjusting the queries.\nIn addition, Storyteller takes provenance into account by allowing the user to view the data in the original context of their source.</p>\n", "logo": null, "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "nlescWebsite": null, "endorsedBy": ["/organization/nlesc"], "website": "http://nlesc.github.io/UncertaintyVisualization/", "license": ["apache-2.0"], "discipline": ["Humanities & Social Sciences"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2013-12-04", "contributor": ["/person/j.vanderzwaan", { "affiliation": ["/organization/uu"], "website": "http://www.uu.nl/staff/MHvanderKlis/", "name": "Martijn van der Klis" }], "tagLine": "Texcavator is a text mining application used for historical research", "slug": "texcavator", "id": "/software/texcavator", "contactPerson": "/person/j.vanderzwaan", "codeRepository": "https://github.com/UUDigitalHumanitieslab/texcavator", "user": ["/organization/uu"], "title": "Texcavator", "dependencyOf": null, "competence": ["Big Data Analytics"], "documentationUrl": null, "supportLevel": "advanced", "dependency": null, "name": "Texcavator", "owner": ["/organization/nlesc", "/organization/uva", "/organization/uu"], "programmingLanguage": ["Python", "JavaScript"], "status": "inactive", "expertise": ["Information Retrieval", "Text Mining", "Distributed Computing", "Information Visualization"], "technologyTag": ["Elasticsearch", "Django", "Dojo Toolkit"], "usedIn": ["/project/texcavator", "/project/shico"], "@id": "http://software.esciencecenter.nl/software/texcavator/", "description": "<p>Texcavator is a text mining application used for historical research using newspaper data (the KB newspaper archive).\nThe newspaper articles are stored in an Elasticsearch index.\nDjango is used for user management and other functionality that requires storing information in a relational database (as opposed to storing documents in Elasticsearch). Because the KB data is not public, every user has their own login. Also, users can save queries (currently, a saved query is required to be able to generate word clouds and time lines). User data is stored in a (MySQL) database; Django provides a convenient interface to the database and provides standard functionality for manipulating database records. A disadvantage of Django is that the front end (user interface) and back end are somewhat intertwined. On top of that, the user interface (implemented in Dojo version 1.8.6) directly retrieved and updated information in the database in some cases.</p>\n", "logo": null, "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/uva", "/organization/uu"], "nlescWebsite": null, "endorsedBy": ["/organization/nlesc"], "website": "http://texcavator.surfsaralabs.nl/", "license": ["apache-2.0"], "discipline": ["Humanities & Social Sciences"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "title": "Timbuctoo", "tagLine": "Data management for historical interpretative research.", "slug": "timbuctoo", "programmingLanguage": ["JavaScript", "Java"], "codeRepository": "https://github.com/HuygensING/timbuctoo", "expertise": ["Information Integration"], "description": "<p>Timbuctoo is aimed at historians doing interpretative research. Such a researcher collects facts from various documents, interprets and structures them, and creates tables of these facts. The researcher then uses this new dataset either as an object to do analysis on, or as an index that allows them to look at their sources from a distance quickly stepping back to the original source for the real interpretative work.</p>\n\n<p>As such an historian you often need to categorize your findings. For example: you keep track of birthplaces. You then need to decide how to write down the birthplace</p>\n\n<ul>\n  <li>Do you use the name of the city, or the burrough?</li>\n  <li>Do you use the current name or the name when the person was born?</li>\n  <li>If your dataset spans a long time you might have two different cities on the same geographical location. Are they one name or more?</li>\n</ul>\n\n<p>These judgements are sometimes the core of your research and sometimes incidental to it. Timbuctoo aims to make it easier to publish your research dataset and then to re-use other people\u2019s published datasets. To continue the example: another researcher might create a dataset containing locations, their co\u00f6rdinates and names and how that changed over time. You can then re-use that dataset and link to the entries instead of typing a string of characters that a humand might correctly interpret or not.</p>\n", "@id": "http://software.esciencecenter.nl/software/timbuctoo/", "competence": ["Optimized Data Handling"], "discipline": ["Humanities & Social Sciences"], "status": "active", "involvedOrganization": ["/organization/huygens"], "id": "/software/timbuctoo", "name": "Timbuctoo", "license": ["gpl-3.0"], "endorsedBy": ["/organization/huygens"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2016-02-22", "contributor": ["/person/j.vanderzwaan"], "tagLine": "Dutch language resource for calculating topic coherence with Palmetto", "slug": "topic-coherence-for-dutch", "id": "/software/topic-coherence-for-dutch", "contactPerson": "/person/j.vanderzwaan", "codeRepository": null, "user": ["/organization/nlesc"], "title": "Topic Coherence For Dutch", "dependencyOf": null, "competence": ["Big Data Analytics"], "documentationUrl": null, "doi": "http://dx.doi.org/10.5281/zenodo.46377", "supportLevel": "specialized", "dependency": null, "name": "Palmetto position storing Lucene index of Dutch Wikipedia", "owner": ["/organization/nlesc", "/organization/uva"], "programmingLanguage": null, "status": "inactive", "expertise": ["Text Mining"], "technologyTag": ["Dataset", "Topic Modeling", "Topic Coherence", "Palmetto"], "usedIn": ["/project/dilipad"], "@id": "http://software.esciencecenter.nl/software/topic-coherence-for-dutch/", "description": "<p>Dutch language resource for calculating topic coherence with <a href=\"http://aksw.org/Projects/Palmetto.html\">Palmetto</a> [1]. The dataset is a position storing Lucene index of the <a href=\"https://dumps.wikimedia.org/nlwiki/20151102/\">Dutch Wikipedia</a>. It was created in the context of the <a href=\"https://www.esciencecenter.nl/project/dilipad\">Netherlands eScience Center Dilipad project</a>. The pdf file contains the results of a case study that shows best topic coherence measure for topics consisting of Dutch nouns is NPMI.</p>\n\n<p>More details can be found in the README.</p>\n\n<p>[1] M. Roeder, A. Both, and A. Hinneburg. Exploring the space of topic coherence measures. In Proceedings of the Eighth ACM International Conference on Web Search and Data Mining, pages 399\u2013408, 2015.</p>\n", "logo": null, "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/uva"], "nlescWebsite": null, "endorsedBy": ["/organization/nlesc"], "website": null, "license": ["cc-by-sa"], "discipline": ["Humanities & Social Sciences"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "contributor": ["/person/e.tjongkimsang"], "tagLine": "Searchable Dutch tweets", "slug": "twiqs.nl", "contactPerson": "/person/e.tjongkimsang", "startDate": "2013-02-22", "competence": ["Big Data Analytics"], "status": "inactive", "supportLevel": "basic", "name": "twiqs.nl", "title": "Twiqs.nl", "owner": ["/organization/nlesc", "/organization/radboud.university.nijmegen", "/organization/surfsara", "/person/e.tjongkimsang"], "programmingLanguage": ["Perl", "Java"], "expertise": ["Text Mining", "Information Retrieval"], "technologyTag": ["Hadoop", "Twitter", "Website"], "usedIn": ["/project/twinl"], "@id": "http://software.esciencecenter.nl/software/twiqs.nl/", "description": "<p>twiqs.nl provides researchers and students the opportunity to search through Dutch tweets. You can look up words and find out where, when and how often they are used, by whom and with what other words they frequently occur together.</p>\n\n<p>The service is based on an existing system set up at the ISLA (UvA) and the RUG with infrastructure from SURFsara - mapping these tweets is a very compute intensive activity. The Twitter API, providing free access to approximately 1% of all tweets worldwide, is constantly harvested and the resulting data stored. Interfaces to this data provide users with a number of analysis tools that can be run on all content and metadata.</p>\n", "discipline": ["Humanities & Social Sciences"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/radboud.university.nijmegen", "/organization/surfsara"], "id": "/software/twiqs.nl", "website": "http://twiqs.nl/", "license": ["apache-2.0"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "contributor": ["/person/r.vanharen"], "tagLine": "Python workflow application to set up/run WRF simulations (optionally including data assimilation).", "slug": "wrfpy", "id": "/software/wrfpy", "contactPerson": "/person/r.vanharen", "codeRepository": "https://github.com/rvanharen/wrfpy", "license": ["apache-2.0"], "user": ["/person/r.vanharen", "/organization/wur"], "title": "Wrfpy", "dependencyOf": null, "competence": ["Big Data Analytics", "Efficient Computing"], "status": "wip", "supportLevel": "specialized", "dependency": ["/software/pyxenon", "f90nml", "WRF", "WRFDA", "UPP", "WPS"], "name": "WRFpy", "owner": ["/person/r.vanharen"], "downloadUrl": "https://github.com/rvanharen/wrfpy/releases", "programmingLanguage": ["Python"], "expertise": ["Data Assimilation", "Distributed Computing", "High Performance Computing", "Databases"], "technologyTag": ["Simulation", "workflow"], "usedIn": ["/project/era-urban"], "@id": "http://software.esciencecenter.nl/software/wrfpy/", "description": "<p>WRFpy is a python application that provides an easy way to set up, run,\nand monitor (long) Weather Research and Forecasting (WRF) simulations. It\nprovides a simple user-editable JSON configuration file and an integration\nwith pyxenon to access distributes computing and storage resources.\nOptionally, WRFpy allows for data assimilation using WRF data assimilation\nsystem (WRFDA) and postprocessing of wrfinput files using the NCEP Unified\nPost Processing System (UPP).</p>\n", "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "endorsedBy": ["/organization/nlesc"], "startDate": "2015-10-15", "discipline": ["Environment & Sustainability", "eScience Methodology"] }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2013-04-12", "contributor": ["/person/j.maassen", "/person/s.verhoeven", "/person/n.drost", "/person/r.vannieuwpoort", "/person/j.borgdorff", "/person/c.meijer", "/person/b.vanwerkhoven"], "tagLine": "A middleware abstraction library that provides a simple programming interface to various compute and storage resources.", "slug": "xenon", "id": "/software/xenon", "contactPerson": "/person/j.maassen", "codeRepository": "https://github.com/NLeSC/Xenon", "license": ["apache-2.0"], "user": ["/organization/nlesc", "/person/j.maassen", "/person/n.drost", "/person/s.verhoeven", "/person/j.borgdorff", "/person/b.vanwerkhoven", "/person/r.vannieuwpoort"], "title": "Xenon", "dependencyOf": ["/software/noodles", "/software/pyxenon", "/software/osmium"], "competence": ["Efficient Computing"], "documentationUrl": "http://nlesc.github.io/Xenon/versions/1.1.0/javadoc", "doi": "http://dx.doi.org/10.5281/zenodo.35415", "supportLevel": "specialized", "name": "Xenon", "description": "<p>Xenon is a middleware abstraction library. It provides a simple\nprogramming interface to various pieces of software that can be used to\naccess distributed compute and storage resources.</p>\n\n<h1 id=\"why-xenon\">Why Xenon?</h1>\n\n<p>Xenon is developed by the Netherlands eScience Center as a support\nlibrary for our projects. Several projects develop end-user applications\nthat require access to distributed compute and storage resources. Xenon\nprovides a simple API to access those resources, allowing those\napplications to be developed more rapidly. The experience gained during\nthe development of these end-user applications is used to improve the\nXenon API and implementation.</p>\n", "owner": ["/organization/nlesc", "/person/j.maassen"], "downloadUrl": "https://bintray.com/nlesc/xenon/xenon/view", "programmingLanguage": ["Java"], "expertise": ["Distributed Computing"], "technologyTag": ["Distributed", "Library"], "usedIn": ["/project/emetabolomics", "/project/simcity", "/project/viaappia-patty", "/project/esalsa", "/project/amuse", "/project/abcmuse", "/project/biomarker", "/project/computational-chemistry-made-easy", "/project/large-scale-data-assimilation"], "@id": "http://software.esciencecenter.nl/software/xenon/", "logo": "/images/software/xenon.png", "discipline": ["Physics & Beyond", "eScience Methodology"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc"], "endorsedBy": ["/organization/nlesc"], "website": "http://nlesc.github.io/Xenon/", "status": "active", "nlescWebsite": "https://www.esciencecenter.nl/technology/software/xenon" }, { "schema": "http://software.esciencecenter.nl/schema/software", "startDate": "2013-01-01", "contributor": ["/person/l.veen"], "tagLine": "the eXtensible Text Analysis Suite", "slug": "xtas", "contactPerson": "/person/j.attema", "codeRepository": "https://github.com/NLeSC/xtas", "user": ["/organization/nlesc", "/organization/uva", "/person/p.bos"], "title": "Xtas", "competence": ["Efficient Computing", "Big Data Analytics"], "documentationUrl": "http://nlesc.github.io/xtas/setup.html", "supportLevel": "basic", "name": "xtas", "description": "<p>xtas is a collection of natural language processing and text mining tools, brought together in a single software package with built-in distributed computing and support for the Elasticsearch document store.</p>\n\n<p>xtas functionality consists partly of wrappers for existing packages, with automatic installation of software and data; and partly of custom-built modules coming out of research. Currently offered are various parsers for Dutch and English (Alpino, CoreNLP, Frog, Semafor), named entity recognizers (Frog, Stanford and custom-built ones), a temporal expression tagger (Heideltime) and a sentiment tagger based on SentiWords.</p>\n\n<p>A basic installation of xtas works like a Python module. Built-in package management and a simple, uniform interface take away the hassle of installing, configuring and using many existing NLP tools.</p>\n\n<p>xtas\u2019s open architecture makes it possible to include custom code, run this in a distributed fashion and have it communicate with Elasticsearch to provide document storage and retrieval.</p>\n", "owner": ["/organization/nlesc", "/organization/uva"], "programmingLanguage": ["Java", "Python"], "expertise": ["Text Mining", "Distributed Computing", "Information Retrieval"], "technologyTag": ["NER", "NLP", "Parsing", "Sentiment analysis"], "usedIn": ["/project/candygene", "/project/texcavator"], "@id": "http://software.esciencecenter.nl/software/xtas/", "license": ["apache-2.0"], "discipline": ["Humanities & Social Sciences"], "contributingOrganization": ["/organization/nlesc"], "involvedOrganization": ["/organization/nlesc", "/organization/uva"], "nlescWebsite": "https://www.esciencecenter.nl/technology/software/xtas", "id": "/software/xtas", "website": "http://xtas.net/", "status": "active", "endorsedBy": ["/organization/nlesc"] }], "project": [{ "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2018-10-01", "tagLine": "Integration of ligand and protein data for structure-based prediction of protein-ligand selectivity and polypharmacology", "slug": "3d-e-chem", "coordinator": "/person/l.ridder", "contactPerson": "/person/s.verhoeven", "engineer": ["/person/s.verhoeven"], "startDate": "2015-10-01", "dataMagnitude": "GB", "nlescWebsite": "https://www.esciencecenter.nl/project/3d-e-chem", "name": "3D-e-Chem", "dataFormat": ["HDF5", "CSV", "sqlite3", "JSON"], "infrastructure": "Virtual Machine", "competence": ["Optimized Data Handling"], "uses": ["/software/3d-e-chem-vm", "/software/cclustera", "/software/knime-archetype", "/software/knime-gpcrdb", "/software/knime-klifs", "/software/knime-molviewer", "/software/chemical-analytics-platform", "/software/rdkit"], "expertise": ["Information Integration", "Reproducible Research"], "principalInvestigator": [{ "affiliation": ["/organization/vua"], "website": "http://www.few.vu.nl/~cdgraaf/", "name": "Dr. Chris de Graaf" }], "@id": "http://software.esciencecenter.nl/project/3d-e-chem/", "description": "<p>The 3D-e-Chem project will develop technologies to improve the integration of ligand and protein data for structure-based prediction of protein-ligand selectivity and polypharmacology.</p>\n\n<p>The project will use <a href=\"http://www.knime.org\">Knime Analytics Platform</a> to integrate the different technologies and datasets.</p>\n", "discipline": ["Life Sciences & eHealth"], "involvedOrganization": ["/organization/nlesc", "/organization/radboud.university.nijmegen", "/organization/vua"], "title": "3d E Chem", "endorsedBy": ["/organization/nlesc"], "website": "https://3d-e-chem.github.io/", "logo": "/images/project/3d-e-chem.jpg", "id": "/project/3d-e-chem" }, { "schema": "http://software.esciencecenter.nl/schema/project", "title": "3d Geospatial Data Exploration For Modern Risk Management Systems", "tagLine": "COMMIT valorization project: 3D geospatial data exploration for modern risk management systems", "slug": "3d-geospatial-data-exploration-for-modern-risk-management-systems", "uses": ["/software/monetdb", "/software/datavaults", "/software/kernel_tuner", "/software/liblas"], "dataFormat": ["LAS", "LAZ", "GML", "NetCDF", "GeoJSON", "Shapefiles"], "contactPerson": "/person/r.goncalves", "description": "<p>55% of The Netherlands is below sea level. This area contains 60% of the population and generates 65% of the Gross National Product. Obviously, The Netherlands requires efficient risk and water management.</p>\n\n<p>Efficient risk assessment requires large-scale flood simulations with high precision in case a dike or dam breaks. Continuous monitoring of man-made infrastructures in search of small deviations or breaches. And impact assessment of urban area re-organization.</p>\n\n<p>For precise and effective risk assessment, we must increase precision in high-resolution flood simulations, improve accuracy of semantic trajectory determination of water channel networks, and provide the means to align and compare data sets at different resolutions to study the spatial evolution over time of an area or structure.</p>\n\n<p>Unfortunately, current solutions, consisting of PostGIS combined with stand-alone applications and libraries, lack the necessary flexibility and scalability and require extensive preprocessing of the data. The goal of this project is to modernize generation and manipulation of these datasets by using a Geospatial Database Management System (DBMS). The unique advantage of this approach is that, unlike previous solutions, it stores the raw data sets, and transforms, combines and processes them only when needed. This will vastly improve flexibility and performance.</p>\n\n<p>To achieve this goal the project team will extend a Geospatial Database Management System (G-DBMS) with a flexible storage schema for 2D/3D geospatial datasets (point cloud, raster, vector, etc.). This is used to store semantically rich objects needed for the personalization of 3D digital city models (i.e., data re-generation with user defined parameters). These 3D digital city models form the basis for flow simulations, urban planning and under- and over- ground formation analysis. Additionally they are very important for automated anomaly detection on manmade structures.</p>\n\n<p>In this G-DBMS, topological and geometric functionality for 3D raster manipulation will become first-class citizens. For near real-time 3D model generation and manipulation some of these operators will be complemented with a GPU version. Application specific functionality, such as constrained Delaunay triangulation and the marching cubes algorithm for surface re-construction, will also be added as they are important tools in the work done by our commercial partners.</p>\n\n<p>Within this project, spatial analysis tailored to different use case scenarios is done on demand and fast enough to be used by modern risk management systems to, for example, determine trajectory escape routes. In addition, it will provide the means to identify and quantify deviations on flow patterns, such as wind and water, while modeling under- and over- ground surfaces. In other words, it addresses the challenges identified by three major companies in the sector: Fugro, Geodan, and Deltares.</p>\n\n<p>Furthermore, this project stands on the shoulders of a successful COMMIT/ project, \u201cspatiotemporal data warehouses for trajectory exploitation\u201d (P19), and the strategic partnership between CWI Database group, Netherlands eScience Center (NLeSC), TU Delft 3D Geo-information group, VU Geographic Information Systems (GIS) group and Geodan to develop core technology for \u201cBig Data Analytics in the Geo-Spatial Domain\u201d.</p>\n", "expertise": ["Information Visualization", "Information Integration", "Databases"], "id": "/project/3d-geospatial-data-exploration-for-modern-risk-management-systems", "engineer": ["/person/r.goncalves"], "@id": "http://software.esciencecenter.nl/project/3d-geospatial-data-exploration-for-modern-risk-management-systems/", "dataMagnitude": "TB", "discipline": ["eScience Methodology"], "involvedOrganization": ["/organization/commit", "/organization/monetdb", "/organization/deltares", "/organization/cwi", "/organization/geodan", "/organization/fugro"], "endorsedBy": ["/organization/nlesc"], "name": "3D Geospatial Data Exploration for Modern Risk Management Systems", "logo": "/images/project/3d-geospatial-data-exploration-for-modern-risk-management-systems.jpg", "competence": ["Optimized Data Handling", "Big Data Analytics"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "competence": ["Optimized Data Handling", "Big Data Analytics", "Efficient Computing"], "tagLine": "Programming tools that simplify application development and deployment", "slug": "a-jungle-computing-approach-to-large-scale-online-forensic-analysis", "uses": ["/software/kernel_tuner"], "contactPerson": "/person/j.maassen", "description": "<p>Computing devices (including mobile phones) feature in many of the day-to-day crimes. Computer forensics has emerged as a discipline to assist law enforcement agencies in addressing the increasing use of digital storage devices in criminal acts. Forensic examination of for example mobile phones and personal computers can reveal a wealth of evidence.</p>\n\n<p>Increasingly, high profile criminal cases are benefitting from digital evidence gathered via a computer forensic examination. However, analyzing these large volume data sets of evidence can prove to be a very time consuming process due to the variety of the data and the quantity of potential evidence in a digital environment. For this reason, the Netherlands Forensic Institute (NFI) designed the HANSKEN platform - an important aid in modern police investigation, capable of micro level analysis of digital traces contained in digital devices such as hard disks and mobile phones, and generating macro level forensic views.</p>\n\n<h1 id=\"a-new-computing-paradigm\">A new computing paradigm</h1>\n\n<p>The HANSKEN platform requires a wide variety of computing hardware \u2013 all at once. The concurrent use of such variety of hardware has been applied in scientific and industrial applications, spawning a new computing paradigm: Jungle Computing. This variety of computing hardware used in Jungle Computing can take many forms \u2013 ranging from a single centralized machine consisting of heterogeneous hardware components (e.g., multicore CPUs, GPUs, and FPGAs) to large-scale distributed systems consisting of combinations of multiple clusters, grids, and cloud systems (each potentially being self-heterogeneous as well).</p>\n\n<p>The complexity of Jungle Computing Systems has generated a need for programming tools that simplify application development and deployment. Above all, such tools must hide as much as possible the idiosyncrasies of the underlying hardware. Moreover, such tools must allow programmers to efficiently integrate multiple compute kernels each potentially implemented using different languages or models (e.g. C, MPI, Python, CUDA), to easily combine and integrate different types of data (potentially from different locations), and to easily deal with dynamic computing needs (software malleability and scalability) and ad-hoc hardware availability (hardware malleability and fault-tolerance). This project focuses on the development of a high quality set of technologies that adhere to all these requirements.</p>\n\n<h1 id=\"a-jungle-computing-version-of-the-hansken-platform\">A Jungle Computing version of the HANSKEN platform</h1>\n\n<p>The project aims to apply Jungle Computing to the above described extremely demanding domain of forensic analysis, in particular by extending and adapting the HANSKEN platform. Important requirements underlying the HANSKEN platform include: high-performance, full coverage of all available (possibly distributed) traces, ability to support a wide variety of trace analysis compute kernels, and direct access for various types of police investigators. Although the HANSKEN approach is proven successful (showing 80 times speed improvement over NFI\u2019s current XIRAF system), the expected growth in data volumes, the need for multi-tenancy, and the need for deep analysis of multimedia traces in particular, put further demands on the HANSKEN platform. This proposal aims to realize a Jungle Computing enabled version of HANSKEN that adheres to all these requirements.</p>\n\n<h1 id=\"providing-faster-insights-in-forensic-casework\">Providing faster insights in forensic casework</h1>\n\n<p>Driven by the demands of the forensic analysis domain, expected outcomes of the proposed project include:</p>\n<ul>\n  <li>High quality releases of core Jungle Computing technologies, based on the Ibis system of VU University.</li>\n  <li>Optimized GPU implementations for a set of performance-critical multimedia analysis kernels.</li>\n  <li>A generic and flexible interface to analysis tools, toolsets and/or libraries for specific forensic analysis domains.</li>\n</ul>\n\n<p>Based on the collaboration between VU University, NFI and the Netherlands eScience Center, it is expected that forensic digital analysis will provide faster insights in forensic casework as well as new links between cases that would otherwise not have been found (for example cross-trace camera identification).</p>\n", "expertise": ["Distributed Computing", "Accelerated Computing", "High Performance Computing"], "engineer": ["/person/j.maassen", "/person/b.vanwerkhoven"], "@id": "http://software.esciencecenter.nl/project/a-jungle-computing-approach-to-large-scale-online-forensic-analysis/", "discipline": ["eScience Methodology"], "logo": "/images/project/a-jungle-computing-approach-to-large-scale-online-forensic-analysis.jpg", "involvedOrganization": ["/organization/nfi", "/organization/nlesc", "/organization/vua"], "title": "A Jungle Computing Approach To Large Scale Online Forensic Analysis", "id": "/project/a-jungle-computing-approach-to-large-scale-online-forensic-analysis", "name": "A Jungle Computing approach to large scale online Forensic Analysis", "nlescWebsite": "https://www.esciencecenter.nl/project/a-jungle-computing-approach-to-large-scale-online-forensic-analysis", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "tagLine": "A mystery of modern astrophysics", "slug": "aa-alert", "coordinator": "/person/j.attema", "contactPerson": "/person/j.attema", "engineer": ["/person/j.attema", "/person/o.rubi"], "dataMagnitude": "PB", "startDate": "2016-07-01", "infrastructure": "Apertif, A 75-GPU cluster and 10 PB storage", "nlescWebsite": "https://www.esciencecenter.nl/project/aa-alert", "name": "Access and Acceleration of the Apertif Legacy Exploration of the Radio Transient Sky", "title": "Aa Alert", "competence": ["Big Data Analytics", "Efficient Computing"], "expertise": ["Accelerated Computing", "Handling Sensor Data", "High Performance Computing"], "principalInvestigator": [{ "affiliation": ["/organization/astron"], "website": "http://www.astron.nl/astronomy-group/people/joeri-van-leeuwen/joeri-van-leeuwen", "name": "Dr. Joeri van Leeuwen" }], "@id": "http://software.esciencecenter.nl/project/aa-alert/", "description": "<p>In our largely unchanging Universe, highly dynamic components were\nrecently discovered: flashes of bright radio emission that last only\nmilliseconds. Some of these radio bursts can be traced to nearby\nneutron stars, providing insight in physics environments far more\nextreme than any Earth laboratory. Other bursts however, apparently\noriginate far outside our Galaxy, and must be exceedingly energetic.</p>\n\n<p>These bursts are buried far below the instrument noise. Through\nprocessing algorithms that for example recognize tenuous intergalactic\nmatter, and through subsequent classification in a many-parameter\nspace, the project leader\u2019s team already made a series of\nground-breaking detections, resulting in 6 Science and Nature\npapers. Still the origin of the extragalactic bursts remains a mystery\nat the forefront of modern astrophysics.</p>\n\n<p>The goal of this project is to understand both kinds of luminous\nbursts. The project leader\u2019s team started a highly innovative survey,\nALERT, with the rejuvenated, upgraded Westerbork Telescope - the most\nsensitive such experiment in the world by over an order of\nmagnitude. ALERT includes a 75-GPU cluster and 10 PB storage.</p>\n\n<p>How to match this jump in observational and compute capabilities with\na similar leap in real-time data analysis? A team of eScience Research\nEngineers and Astronomers will investigate how to first Accelerate to\nreal time; and how to then most insightfully Access the resulting\ndata, and trigger global telescope follow up. Through that unique\ncombination, AA-ALERT could help shed light on the nature of these\nenigmatic radio bursts for the first time - evaporating primordial\nblack holes; explosions in host galaxies; or, the unknown?</p>\n", "discipline": ["Physics & Beyond"], "involvedOrganization": ["/organization/astron", "/organization/nlesc"], "id": "/project/aa-alert", "logo": "/images/project/aa-alert.jpg", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "title": "Abcmuse", "competence": ["Efficient Computing"], "slug": "abcmuse", "uses": ["/software/xenon", "/software/amuse"], "coordinator": "/person/j.maassen", "contactPerson": "/person/j.maassen", "description": "<p>Robust high-resolution multi-physics simulations.</p>\n", "expertise": ["Distributed Computing"], "nlescWebsite": "https://www.esciencecenter.nl/project/abc-muse", "@id": "http://software.esciencecenter.nl/project/abcmuse/", "discipline": ["Physics & Beyond"], "involvedOrganization": ["/organization/uu", "/organization/leiden-university"], "id": "/project/abcmuse", "name": "ABCmuse", "logo": "/images/project/abcmuse.jpg", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "tagLine": "Simulating complex astrophysical phenomena using Distributed Computing.", "slug": "amuse", "coordinator": "/person/j.maassen", "contactPerson": "/person/n.drost", "engineer": ["/person/n.drost"], "title": "Amuse", "infrastructure": "Supercomputer", "nlescWebsite": "https://www.esciencecenter.nl/project/amuse", "involvedOrganization": ["/organization/nlesc", "/organization/leiden-university"], "name": "Distributed AMUSE", "dataFormat": ["HDF5"], "competence": ["Efficient Computing"], "uses": ["/software/xenon", "/software/amuse"], "expertise": ["High Performance Computing"], "principalInvestigator": [{ "affiliation": ["/organization/leiden-university"], "website": "http://home.strw.leidenuniv.nl/~spz/", "name": "Simon Portegies Zwart" }], "@id": "http://software.esciencecenter.nl/project/amuse/", "description": "<p>##The evolution of embedded star clusters</p>\n\n<p>The early evolution of star clusters is one aspect of the formation of our Universe which is not yet completely understood. When stars are born they develop from large clouds of molecular gas, clusters composed of hundreds of solar masses of material. Early in the formation of our Galaxy large clusters formed from giant molecular clouds. Each cluster contains over 10,000 members. These clusters, appearing very compact, contain the oldest stars in the Universe. Understanding the changes in their lifetime helps us understand the formation of our Universe.</p>\n\n<p>##Simulating the exact circumstances in the early Universe</p>\n\n<p>In the past decade, our picture of star and cluster formation has changed hugely and we now believe that many - if not most - stars form in clusters, and the process of star and cluster formation is extremely rapid and dynamic. Using the Astrophysical Multipurpose Software Environment (AMUSE), a simulation can be made that mimics the exact circumstances of such a cluster.</p>\n\n<p>AMUSE provides a homogeneous interface to a wide variety of packages enabling the study of astrophysical phenomena where complex interactions occur between different physical domains, such as stellar evolution and dynamics, (magneto-)hydrodynamics, radiative transfer, and astrochemistry. Applications are numerous. For example, AMSUSE enables studying the co-evolution of planetary systems within cluster environments, the formation and evolution of black holes in galaxies, or the interplay of gas, radiation, and chemistry in star formation process. These simulations lead to new understandings of the processes involved, and their effects on the current state of our Universe.</p>\n\n<p>The above is only one example of the possibilities of AMUSE. Based on the work done in the Ibis project at the VU University Amsterdam, we are building a robust, stable system for running these large scale simulations on a possibly distributed set of resources, including supercomputers. This will allow astrophysicists from around the world to scale up their simulations, increasing our understanding of the Universe.</p>\n", "discipline": ["Physics & Beyond"], "dataMagnitude": "TB", "endorsedBy": ["/organization/nlesc"], "logo": "/images/project/amuse.jpg", "id": "/project/amuse" }, { "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2017-09-01", "tagLine": "Detecting anomalous behaviour in stadium crowds using Wi-Fi positioning", "slug": "arena", "coordinator": "/person/e.ranguelova", "contactPerson": "/person/s.georgievska", "description": "\n", "dataFormat": ["JSON"], "engineer": ["/person/s.georgievska"], "principalInvestigator": [{ "affiliation": ["/organization/uva"], "website": "https://nl.linkedin.com/in/sanderklous", "name": "Dr. Sander Klous" }], "nlescWebsite": "https://www.esciencecenter.nl/project/detecting-anomalous-behavior-in-stadium-crowds", "@id": "http://software.esciencecenter.nl/project/arena/", "dataMagnitude": "GB", "competence": ["Big Data Analytics"], "involvedOrganization": ["/organization/nlesc", "/organization/uva"], "infrastructure": "Computers Cluster", "title": "Arena", "id": "/project/arena", "name": "ArenA", "startDate": "2015-09-01", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2019-12-31", "tagLine": "Looking for unconfirmed or unknown fundamental physics", "slug": "automated-parallel-calculation-of-collaborative-statistical-models", "coordinator": "/person/j.attema", "contactPerson": "/person/p.bos", "engineer": ["/person/p.bos"], "startDate": "2016-05-15", "dataMagnitude": "MB", "competence": ["Optimized Data Handling", "Efficient Computing"], "involvedOrganization": ["/organization/nlesc", "/organization/nikhef"], "name": "Automated Parallel Calculation of Collaborative Statistical Models", "dataFormat": ["ROOT binary format"], "title": "Automated Parallel Calculation Of Collaborative Statistical Models", "id": "/project/automated-parallel-calculation-of-collaborative-statistical-models", "uses": ["/software/roofit", "/software/root"], "expertise": ["Accelerated Computing", "High Performance Computing"], "principalInvestigator": [{ "affiliation": ["/organization/nikhef"], "website": "https://www.nikhef.nl/medewerker/dr-wouter-verkerke/", "name": "Prof. dr. Wouter Verkerke" }], "@id": "http://software.esciencecenter.nl/project/automated-parallel-calculation-of-collaborative-statistical-models/", "description": "<p>Large scale statistical data analysis in particle physics</p>\n", "discipline": ["Physics & Beyond"], "infrastructure": "DAS5 and NIKHEF computer cluster for testing and benchmarking", "endorsedBy": ["/organization/nlesc"], "logo": "/images/project/automated-parallel-calculation-of-collaborative-statistical-models.jpg", "nlescWebsite": "https://www.esciencecenter.nl/project/automated-parallel-calculation-of-collaborative-statistical-models" }, { "schema": "http://software.esciencecenter.nl/schema/project", "title": "Beyond The Book", "tagLine": "How international is a work of fiction?", "slug": "beyond-the-book", "coordinator": "/person/j.attema", "contactPerson": "/person/c.martinez", "description": "<h1 id=\"visualizing-the-level-of-international-readability-of-works-of-fiction\">Visualizing the level of international readability of works of fiction</h1>\n\n<p>The impact of globalization on culture and literature is quite significant. However, works of fiction still face stumbling blocks when translated to for readers from another culture. In many cases, when reading a book from another culture, the reader is required to have at least some knowledge of persons, places, or events from that other culture. Some names will be universally known, such as New York or Angela Merkel, but others will be mostly unknown and perhaps even mysterious, such as Monnikendam or Meneer Beerta. We could therefore ask the question of how \u201cinternational\u201d a work of fiction actually is.\nMeasuring how \u201cinternational\u201d a work of fiction is</p>\n\n<p>If we want to know how \u201cinternational\u201d a work of fiction is, we first need to understand which textual features play a role in how readable a work of fiction for readers from a different culture. Which of these features can be identified and measured in a digital text (and which not)? And how can the identifiable and measurable features be turned into a usable indicator of readability for readers from other cultures?</p>\n", "expertise": ["Text Mining", "Information Retrieval", "Linked Data", "Information Integration"], "id": "/project/beyond-the-book", "engineer": ["/person/c.martinez"], "principalInvestigator": [{ "affiliation": ["/organization/huygens"], "photo": "https://www.esciencecenter.nl/img/team/karina-van-dalen-oskam-cropped-bw.jpg", "website": "http://www.huygens.knaw.nl/vandalen/?lang=en", "name": "Karina van Dalen-Oskam" }], "nlescWebsite": "https://www.esciencecenter.nl/project/beyond-the-book", "@id": "http://software.esciencecenter.nl/project/beyond-the-book/", "competence": ["Optimized Data Handling"], "involvedOrganization": ["/organization/huygens", "/organization/nlesc"], "endorsedBy": ["/organization/nlesc"], "name": "Beyond the Book", "publication": ["http://dx.doi.org/10.1109/eScience.2015.12"], "logo": "/images/project/beyond-the-book.jpg", "discipline": ["Humanities & Social Sciences"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "startDate": "2012-06-12", "tagLine": "Big Data for the Big Bang", "slug": "beyond-the-data-explosion", "coordinator": "/person/r.vannieuwpoort", "contactPerson": "/person/r.vannieuwpoort", "engineer": ["/person/r.vannieuwpoort"], "dataMagnitude": "PB", "title": "Beyond The Data Explosion", "infrastructure": "LOFAR", "nlescWebsite": "https://www.esciencecenter.nl/project/beyond-the-data-explosion", "name": "An eScience infrastructure for huge interferometric datasets", "competence": ["Optimized Data Handling", "Big Data Analytics", "Efficient Computing"], "uses": ["/software/eastroviz"], "expertise": ["Handling Sensor Data", "High Performance Computing", "Accelerated Computing", "Low Power Computing"], "principalInvestigator": [{ "affiliation": ["/organization/astron"], "website": "https://www.linkedin.com/in/devoscm", "name": "Dr. Marco de Vos" }], "@id": "http://software.esciencecenter.nl/project/beyond-the-data-explosion/", "description": "<p>People are used to the stunning visual images taken by telescopes like\nthe Hubble or the great telescopes in Hawaii and Chile, but maybe only\nhave heard of radio astronomy through movies like \u201cContact\u201d. But radio\ntelescopes can \u201csee\u201d regions beyond the optical view of a galaxy. They\ncan uncover the mysteries as to how the early galaxies, in the\nmillions of years following the Big Bang, began to evolve: Where did\nthey get their material? What drives their rotation? What has shaped\nthem?</p>\n\n<p>Since the 1930s astronomers have used radio telescopes to explore the\nUniverse by detecting radio waves emitted by a wide range of\nobjects. Our Sun, the nearest star to Earth is a powerful radio\nemission source, mainly due to its proximity to our planet, but some\nradio sources, which are millions of even billions of light years\naway, are truly colossal in terms of their radio output.</p>\n\n<p>Radio telescopes provide alternative views to optical telescopes. They\ncan detect invisible gas, and can reveal areas of space that may be\nobscured with cosmic dust. And unlike optical telescopes, which can be\nhampered by cloud or poor weather conditions on Earth, radio\ntelescopes, working with signals at a longer wavelength, can be used\neven in cloudy skies.Radio telescopes can, for example, indirectly\nmeasure the effects of gravity on objects in the Universe. Objects\nlike Pulsars, the fast spinning remnants of supernova explosions, and\ntheir more exotic cousins, the Black Holes, which are the densest\nobjects in the Universe, exert huge gravitational effects on nearby\nobjects.</p>\n\n<p>However, to discover these pulsars you need a high resolution radio\ntelescope; it would be kilometers across. For a single dish this is\nclearly not possible or practical. To get around this limitation in\nsize radio astronomers use astronomical interferometers; an array of\nradio telescopes linked together. In the Netherlands, the LOFAR radio\ninterferometric array is distributed over an area of about one hundred\nkilometers in diameter.</p>\n\n<p>The brute-force search for pulsars takes place over many parameter\ncombinations, because we do not know the position, distance and period\nof the pulsars. Searching for pulsars is a Big Data problem: typical\nobservations produce hundreds of terabytes, and petabytes of\nresults. Moreover, the pulsar signal is faint and can be completely\ncovered by Radio Frequency Interference (RFI), which has to be\nanalyzed and removed from the signal. In this project we aim to\ngreatly speed up the search for new pulsars by using Graphics\nProcessing Units (GPUs) for the complex computations. We are\ndeveloping a complete real-time pulsar searching pipeline using a GPU\ncluster, and are testing it with two Dutch radio telescopes: LOFAR and\nApertif. LOFAR currently is the largest radio telescope in the world.</p>\n\n<p>Astronomical processing software requires expertise from a variety of\ndisciplines The results of this work will be extremely important in\ndeveloping the hardware and software for what will be the most\npowerful radio telescope ever built, the Square Kilometer Array\n(SKA). The SKA will be three to four orders of magnitude larger than\nLOFAR; requiring exascale computing and networking, and the tools\ndeveloped in this project, to run efficiently.</p>\n\n<p>This project explores a new development model for astronomical\nprocessing software where expertise from a variety of disciplines is\ncombined. This includes for example mathematics for the foundations of\nnew algorithms, and computer science to optimize for high-performance\nplatforms. Optimized software and demonstrators will be developed that\ncan be re-used in a variety of contexts, not just for\nradio/mm-astronomy, but also in other areas where large data-streams\nare combined.</p>\n", "discipline": ["Physics & Beyond"], "involvedOrganization": ["/organization/astron", "/organization/nlesc"], "id": "/project/beyond-the-data-explosion", "logo": "/images/project/beyond-the-data-explosion.jpg", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "title": "Big Data Analytics In The Geo Spatial Domain", "tagLine": "Strategic partnership: Big Data Analytics in the Geo-Spatial Domain", "slug": "big-data-analytics-in-the-geo-spatial-domain", "uses": ["/software/monetdb", "/software/datavaults", "/software/liblas"], "dataFormat": ["LAS/LAZ", "GML"], "contactPerson": "/person/r.goncalves", "description": "<p>Digital 3D city models play a crucial role in research of urban phenomena; they form the basis of flow simulations (wind streams, water runoff and heat island effects), urban planning and analysis of underground formations. Urban scenes consist of large collections of complex objects which have rich semantic properties, such as materials and colors. Modeling and storing these properties indicating the relationships between them is best handled in a relational database.</p>\n\n<p>Database management systems (DBMSs) are a well-established solution when it comes to archiving, filtering, analysis, and correlation of large data collections. Ability to perform analysis near data is one of the key requirements identified by the 4th Paradigm to handle the data deluge. A single spatial DBMS offers functionality for geo-spatial modeling and management of semantic properties in one place, thus avoiding the need for multiple software tools associated with high volume data transfer and format transformations.</p>\n\n<p>The provision of spatial and geo-spatial features in database systems needs to be extended and brought to maturity to fulfill the requirements of real-world scientific applications. A class of DBMSs, called column-stores, has proven efficiency for analytical applications on extremely large datasets. In fact, all major DBMS vendors have extended their product spectrum with column-oriented solutions to address the needs of analytical applications. The aim of this project is to develop and mature the spatial features of the column-store open-source MonetDB. It has established a track record in high-performance analytical applications and demonstrated its ability to inject database technology successfully in several science domains, such as astronomy, remote sensing, seismology, and navigation.</p>\n\n<p>The technology will be applied to a concrete use case of the Port of Rotterdam in which a 3D GIS is built to aid various multi-stakeholder construction projects where new structures are built in, on top of and around the existing port (underground) infrastructure. Extending and modifying the port is challenging as it is home to many different companies that often cover extensive areas and manage vast (underground) infrastructures such roads, pipes and cables. The port thus requires a 3D GIS that is able to store all harbor assets and analyze existing assets with future interventions and detect conflicts. The 3D GIS currently being built is aimed at collecting data from different sources and formats (BIM and GIS) and converting it to a common format to enable 3D operations and analyses such as 3D intersections, 3D buffers as well as simplification and generalization of GIS and (especially) BIM models for visualization purposes.</p>\n\n<p>The goals of the strategic partnership and the expected project outcome is as follows: database extension for storage and indexing of 3D point clouds with properties that are suitable for and take advantage of column-oriented internal data organization; database extension for storage and indexing of 3Dvoxels with properties that are suitable for and take advantage of column-storage; the extensions will be evaluated with data and processing requirements of the use case of port of Rotterdam.</p>\n\n<p>The development will rely as much as possible on existing open-source tools and libraries. The proposed (geo-) spatial data analytics tools will extend the eScience Technology Platform (eSTeP) and be offered as an associated technology available to the NLeSC projects and other eScience projects in national and international context.</p>\n", "expertise": ["Information Visualization", "Information Integration", "Databases"], "id": "/project/big-data-analytics-in-the-geo-spatial-domain", "engineer": ["/person/r.goncalves"], "@id": "http://software.esciencecenter.nl/project/big-data-analytics-in-the-geo-spatial-domain/", "dataMagnitude": "TB", "discipline": ["eScience Methodology"], "involvedOrganization": ["/organization/cwi", "/organization/monetdb", "/organization/geodan", "/organization/tu-delft", "/organization/vua", "/organization/fugro"], "endorsedBy": ["/organization/nlesc"], "name": "Big-Data-Analytics-in-the-Geo-Spatial-Domain", "logo": "/images/project/big-data-analytics-in-the-geo-spatial-domain.jpg", "competence": ["Optimized Data Handling", "Big Data Analytics"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "title": "Biomarker", "competence": ["Efficient Computing"], "slug": "biomarker", "uses": ["/software/xenon"], "coordinator": "/person/r.vannieuwpoort", "contactPerson": "/person/r.vannieuwpoort", "description": "<p>Better biomarkers through datasharing.\nDeveloping tools and services to combine datasets obtained by different medical centers.</p>\n", "expertise": ["Distributed Computing"], "engineer": ["/person/e.ranguelova"], "@id": "http://software.esciencecenter.nl/project/biomarker/", "discipline": ["Life Sciences & eHealth"], "logo": "/images/project/biomarker.jpg", "involvedOrganization": ["/organization/radboud.university.nijmegen", "/organization/nlesc"], "id": "/project/biomarker", "name": "biomarker", "nlescWebsite": "https://www.esciencecenter.nl/project/biomarker-boosting", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2018-06-01", "tagLine": "Candidate genes for traits: Enabling precision breeding", "slug": "candygene", "coordinator": "/person/l.ridder", "engineer": ["/person/a.kuzniar"], "startDate": "2015-06-01", "dataMagnitude": "TB", "competence": ["Optimized Data Handling", "Big Data Analytics"], "involvedOrganization": ["/organization/nlesc", "/organization/wur"], "name": "candYgene", "dataFormat": ["RDF serializations", "JSON-LD"], "title": "Candygene", "id": "/project/candygene", "uses": ["/software/fairdatapoint", "/software/xtas"], "expertise": ["Information Integration", "Linked Data", "Text Mining", "Databases", "Machine Learning"], "principalInvestigator": [{ "affiliation": ["/organization/wur", "/organization/dtl"], "photo": "https://www.vcard.wur.nl/WebServices/GetMedia.ashx?id=1700", "website": "http://www.finkers.tk", "name": "Richard Finkers" }], "@id": "http://software.esciencecenter.nl/project/candygene/", "description": "<p>Food demand is projected to increase by 50% in 2030. One way to tackle this challenge is by breeding new crops to ensure food security; crops, for example, that are more resistant to drought. Genetics research is increasingly focusing on mining genome annotations to identify the genes that are likely to be responsible for specific traits we would like to see improved. Since these annotated genome datasets are growing exponentially, and as humans are unable to quickly and easily convert this data into useful information, an eScience infrastructure will be designed to process all this data effectively and make it insightful.</p>\n", "discipline": ["Life Sciences & eHealth"], "infrastructure": "Compute cloud and/or cluster", "endorsedBy": ["/organization/nlesc"], "website": "https://www.eu-sol.wur.nl", "logo": "/images/project/candygene.jpg", "nlescWebsite": "https://www.esciencecenter.nl/project/prediction-of-candidate-genes-for-traits-using-interoperable-genome-annotat" }, { "schema": "http://software.esciencecenter.nl/schema/project", "title": "Compressing The Sky Into A Large Collection Of Statistical Models", "tagLine": "PathFinder project: Compressing the sky into a large collection of statistical models", "slug": "compressing-the-sky-into-a-large-collection-of-statistical-models", "uses": ["/software/monetdb"], "dataFormat": ["NetCDF"], "contactPerson": "/person/v.hees", "description": "<p>Time-domain astronomy opens up a new era of observational astronomy, covering the spectrum from radio and millimeter to optical wavelengths. The data avalanches from their instruments forces us to overhaul contemporary data storage, data management, and data analytics techniques.</p>\n\n<p>Rather than endlessly piling observations onto fleets of hard drives, raw observations could be replaced with more compact model-based representations founded in astrophysics. A well-fitting model has the potential of reducing the storage footprint by several orders of magnitude. The result should, however, be still easy to query and amendable for further analysis within a priori known statistical bounds.</p>\n\n<p>The scientific challenge is to find efficient algorithms to fit many statistical models in millions of seemingly independent observations. Their representation should provide the means to control the information loss that may result from statistical compression, as added noise could destroy effects to be discovered at a later stage in the data analytics pipeline.</p>\n\n<p>In the LOFAR Transients Key Science project a database management infrastructure is in place to take the output of the image production pipeline to populate the LOFAR catalog. This database is expected to grow at a rate of 50TB per year. One of the key limitations of such sizeable databases in the context of data exploration is the time to scan the data for events of interest. The scientist needs to learn what to ask.</p>\n\n<p>One way to improve the exploration phase is to exploit the statistical properties of the growing collection of observations and semantically compress them into parameterized formulae. An astrophysical object with a stable light curve can be replaced by its average flux and a Gaussian error dispersion model. Periodicallly varying objects can be classified and represented by deterministic components of their signal wave models.</p>\n\n<p>The eScience technology addressed is primarily aimed at Optimized Data Handling with a drive to cut down the cost of Big Data Analytics through proper (continuous) preprocessing of the observational data. The existing open-source database system MonetDB, supporting the LOFAR transient database, is extended.</p>\n\n<p>The particular approach towards semantic driven database compression, in combination with the Blaeu visual data exploration tool developed at CWI, is likely to open a vista of hitherto unseen approaches to understand and explain the characteristics of the astrophysical objects. The strong embedding in LOFAR, BlackGem and emerging SKA infrastructures secure a direct route towards scientific discoveries by the astronomers engaged.</p>\n", "expertise": ["Databases"], "id": "/project/compressing-the-sky-into-a-large-collection-of-statistical-models", "engineer": ["/person/v.hees"], "@id": "http://software.esciencecenter.nl/project/compressing-the-sky-into-a-large-collection-of-statistical-models/", "dataMagnitude": "GB", "discipline": ["eScience Methodology"], "involvedOrganization": ["/organization/cwi"], "endorsedBy": ["/organization/nlesc"], "name": "Compressing the Sky Into a Large Collection of Statistical Models", "logo": "/images/project/compressing-the-sky-into-a-large-collection-of-statistical-models.jpg", "competence": ["Optimized Data Handling", "Big Data Analytics"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "slug": "computational-chemistry-made-easy", "uses": ["/software/noodles", "/software/xenon"], "@id": "http://software.esciencecenter.nl/project/computational-chemistry-made-easy/", "contactPerson": "/person/l.ridder", "description": "\n", "title": "Computational Chemistry Made Easy", "logo": "/images/project/computational-chemistry-made-easy.jpg", "involvedOrganization": ["/organization/nlesc", "/organization/vua"], "endorsedBy": ["/organization/nlesc"], "name": "Computational Chemistry Made Easy", "id": "/project/computational-chemistry-made-easy" }, { "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2016-04-01", "tagLine": "A new approach to the history of parliamentary communication and discourse", "slug": "dilipad", "dataFormat": ["XML"], "contactPerson": "/person/j.vanderzwaan", "engineer": ["/person/j.vanderzwaan"], "startDate": "2014-12-18", "dataMagnitude": "GB", "nlescWebsite": "https://www.esciencecenter.nl/project/dilipad", "name": "Digging into Parliamentary Data (DiLiPaD)", "title": "Dilipad", "competence": ["Big Data Analytics"], "uses": ["/software/cptm", "/software/topic-coherence-for-dutch"], "expertise": ["Text Mining"], "principalInvestigator": [{ "affiliation": ["/organization/uva"], "website": "http://mashup2.science.uva.nl/marx/", "name": "Dr. Maarten Marx" }, { "affiliation": ["/organization/uva"], "website": "http://humanities.uva.nl/~kamps/", "name": "Dr. Jaap Kamps" }], "@id": "http://software.esciencecenter.nl/project/dilipad/", "description": "<p>The goals of the DiLiPad project were to:</p>\n\n<ol>\n  <li>Implement cross-perspective topic modeling (cptm)</li>\n  <li>Adapt cptm in order to be able to track changes in opinions over time</li>\n  <li>Validate the results on Dutch parliamentary proceeding</li>\n</ol>\n\n<p>Cross-perspective topic modeling is an existing topic modeling technique to\nextract viewpoints (opinions) from text data. The first step was to implement\nthe algorithm. This resulted in a Python module to do cross-perspective topic.</p>\n\n<p>Cross-perspective topic modeling requires the corpus to be divided in\nperspectives (in case of the Dilipad project, a perspective is a political party).\nTo take into account the time parameter, we decided to further divide the data\n(instead of having a perspective for a political party, we now have a perspective\nfor a political party during a government term).</p>\n\n<p>For the validation study, cross-perspective topic modeling was applied to an existing\ndataset of Dutch parliamentary proceedings. The results show that the\nmethod yields valid topics (content and criterion validity). While opinions\nwere found to be representative of the political parties\u2019 positions as expressed\nin party manifestos (content validity), we were unable to find correlation\nbetween opinions and positions on the left/right political spectrum (criterion validity).\nFurther work is required to determine whether differences between opinions\ncorrelate with other politically meaningful dimensions. We also propose to\ninvestigate the effect of improving topic and opinion quality on the validation\nresults.</p>\n", "discipline": ["Humanities & Social Sciences"], "involvedOrganization": ["/organization/nlesc", "/organization/uva"], "id": "/project/dilipad", "logo": "/images/project/dilipad.jpg", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "title": "Dive Plus", "tagLine": "Online exploration of heritage collections", "slug": "dive-plus", "coordinator": "/person/j.attema", "contactPerson": "/person/c.martinez", "description": "<h1 id=\"interacting-with-historical-events-in-linked-cultural-heritage\">Interacting with Historical Events in Linked Cultural Heritage</h1>\n\n<p>The shift to Digital Humanities has brought humanities scholars an unprecedented amount of historical information on the Web. Events, and the associated role of perspectives in event interpretation, take a pivotal role in humanities research. We often ask ourselves whether events and narratives provide context for interpretation of cultural heritage collections. Can event perspectives gathered through crowdsourcing provide the necessary diversity of perspectives on historical events?</p>\n\n<p>Similar to other users of digital data (consumers, content creators, teachers, publishers), scholars are faced with the challenge of how to find, link, and understand massive and diverse collections of historical information on the Web. Here, the theory of interpretation in the humanities sciences called hermeneutics needs to account for the interpretation of information in a digital environment.</p>\n\n<p>This project provides a basis for interpretation support in searching and browsing of heritage objects, where semantic information from existing collections plus open linked data vocabularies are linking collections of objects to the events, people, locations and concepts that are depicted or associated with those objects. An innovative interface allows for browsing this network of data in an intuitive fashion supporting both digital humanities scholars and general audiences in their online explorations.</p>\n", "expertise": ["Linked Data", "Information Integration"], "id": "/project/dive-plus", "engineer": ["/person/c.martinez"], "principalInvestigator": [{ "affiliation": ["/organization/uva"], "photo": "https://www.esciencecenter.nl/img/team/lora-aroyo-cropped-bw.jpg", "website": "http://www.cs.vu.nl/~laroyo/", "name": "Lora Aroyo" }], "nlescWebsite": "https://www.esciencecenter.nl/project/dive", "@id": "http://software.esciencecenter.nl/project/dive-plus/", "infrastructure": "Web platform", "competence": ["Optimized Data Handling"], "involvedOrganization": ["/organization/vua", "/organization/nlesc"], "endorsedBy": ["/organization/nlesc"], "name": "DIVE+", "logo": "/images/project/dive-plus.jpg", "discipline": ["Humanities & Social Sciences"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "title": "Drwatson", "tagLine": "Crowdsourcing gold standard data in the medical sciences", "slug": "drwatson", "coordinator": "/person/j.attema", "contactPerson": "/person/c.martinez", "description": "<h1 id=\"medical-experts-helping-machines-diagnose\">Medical experts helping machines diagnose</h1>\n\n<p>Crowdsourcing, the process of soliciting contributions from a large group of people, and especially from an online community, to obtain content, services or ideas, is increasingly used to subdivide tedious work. Annotating medical texts is one example of such tedious work.</p>\n\n<p>While cognitive computing systems such as IBM\u2019s Watson can process data and text together to give data more meaning and enable deeper analysis, these cognitive computing systems require large amounts of human annotated data (gold standard data) for evaluation, testing and training. Collecting this annotated data is the most expensive and time consuming part of building cognitive computing systems. The Dr. Watson project aims to motivate a community of medical professionals to build a collection of gold standard medical text annotations. It is the first larger scale pilot study in an innovative interdisciplinary research project using crowdsourcing, motivation and gaming techniques to engage medical professionals in the collection of valuable gold standard annotation data.</p>\n", "expertise": ["Linked Data"], "id": "/project/drwatson", "engineer": ["/person/c.martinez"], "principalInvestigator": [{ "affiliation": ["/organization/uva"], "photo": "https://www.esciencecenter.nl/img/team/lora-aroyo-cropped-bw.jpg", "website": "http://www.cs.vu.nl/~laroyo/", "name": "Lora Aroyo" }], "nlescWebsite": "https://www.esciencecenter.nl/project/dr.-watson", "@id": "http://software.esciencecenter.nl/project/drwatson/", "infrastructure": "Web platform", "competence": ["Big Data Analytics"], "involvedOrganization": ["/organization/vua", "/organization/nlesc"], "endorsedBy": ["/organization/nlesc"], "name": "Dr. Watson", "logo": "/images/project/drwatson.jpg", "discipline": ["Humanities & Social Sciences"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "tagLine": "e-MUSC: Enhancing Multiscale Computing with Sensitivity Analysis and Uncertainty Quantification", "slug": "e-musc", "dataFormat": null, "contactPerson": "http://software.esciencecenter.nl/person/l.veen", "engineer": ["http://software.esciencecenter.nl/person/l.veen"], "dataMagnitude": "GB", "title": "E Musc", "infrastructure": "Supercomputer", "competence": ["Big Data Analytics", "Efficient Computing"], "coordinator": "http://software.esciencecenter.nl/person/r.bakhshi", "nlescWebsite": "https://www.esciencecenter.nl/project/enhancing-protein-drug-binding-prediction", "name": "e-MUSC", "uses": ["http://software.esciencecenter.nl/project/simcity"], "expertise": ["Distributed Computing", "High Performance Computing"], "principalInvestigator": [{ "affiliation": ["http://software.esciencecenter.nl/organization/uva"], "photo": "https://www.esciencecenter.nl/img/team/alfons_hoekstra3.jpg", "website": "https://staff.fnwi.uva.nl/a.g.hoekstra/", "name": "Prof. Alfons Hoekstra", "description": "Prof. Alfons Hoekstra is an Associate Professor at the Computational Science Lab, University of Amsterdam and professor in Computational Biomedicine at the ITMO University in Saint Petersburg, Russia. His research focuses on multi-scale modelling and simulation, complex systems, high performance computing, and applications thereof in the biomedical domain." }], "@id": "http://software.esciencecenter.nl/project/e-musc/", "description": "<p>At the frontiers of contemporary science, many if not all of the quantitative research and engineering challenges with high socioeconomic impact \u2013 such as climate, energy, materials, health and disease, urbanization, economy, psychology, or sociology \u2013 are essentially multiscale system problems. Progress in most of these societal grand challenges is determined by our ability to design and implement multiscale models and simulations of the particular systems under study.</p>\n\n<p>This project will develop generic methods and efficient algorithms for sensitivity analysis and uncertainty quantification for multiscale modelling &amp; simulation, to implement these algorithms as high quality modules of the publically available Multi Scale Modelling and Simulation Framework, and to test, validate and apply the methods on a sufficiently large portfolio of multiscale applications.</p>\n\n<p>The framework must support the whole range of computing infrastructure, from the desktop, via cluster and clouds, to high-end HPC machines. The research and development will be executed in close collaboration with the recently started FET-HPC ComPat project. With some exceptions, sensitivity analysis and uncertainty quantification for multiscale modelling and simulation is currently almost lacking but very much needed.</p>\n\n<p>This project will have a significant impact by filling this gap and studying in detail the behaviour of error propagation in coupled single scale models, taking into account the different kinds of scale bridging that can be identified, and then applying that knowledge for sensitivity analysis and uncertainty quantification.</p>\n\n<p>The impact will be amplified by making these new developments available to the scientific community as high quality and computationally very efficient modules in the Multiscale Modelling and Simulation Framework.</p>\n\n<p>Image source: <a href=\"https://www.flickr.com/photos/argonne/9030312802/in/photolist-abKoXP-dbAs66-bWmUZw-eKYHoj-dbAr5T\">Argonne National Laboratory - Multiscale Blood Flow Simulations</a></p>\n", "involvedOrganization": ["http://software.esciencecenter.nl/organization/nlesc", "http://software.esciencecenter.nl/organization/uva"], "id": "/project/e-musc", "website": null, "logo": "https://www.esciencecenter.nl/img/projects/p60-large.jpg", "discipline": ["eScience Methodology"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "tagLine": "Virtual laboratories for inspiration and discovery in ecology", "slug": "eecology", "coordinator": "/person/e.ranguelova", "contactPerson": "/person/e.ranguelova", "engineer": ["/person/c.meijer", "/person/s.verhoeven", "/person/j.spaaks"], "title": "Eecology", "infrastructure": "Dedicated cluster", "nlescWebsite": "https://www.esciencecenter.nl/project/eecology", "involvedOrganization": ["/organization/uva", "/organization/nlesc"], "name": "eEcology", "dataFormat": ["CSV", "MATLAB"], "competence": ["Big Data Analytics"], "uses": ["/eecology-tracker-calendar", "/eecology-annotation", "/software/eecology-annotation", "/software/eecology-tracker-calendar", "/software/extjs-datetime"], "expertise": ["Machine Learning", "Information Visualization", "Scientific Visualization", "Handling Sensor Data", "Databases"], "principalInvestigator": [{ "affiliation": ["/organization/uva"], "photo": "https://www.esciencecenter.nl/img/team/willem-bouten-bw.jpg", "website": "http://www.uva.nl/over-de-uva/organisatie/medewerkers/content/b/o/w.bouten/w.bouten.html", "name": "Willem Bouten" }], "@id": "http://software.esciencecenter.nl/project/eecology/", "description": "<h1 id=\"bridging-the-gap-between-the-worlds-of-ecology-and-technology\">Bridging the gap between the worlds of ecology and technology</h1>\n\n<p>This project shows that ecology is evolving into a data and computationally intensive science with the amount of (heterogeneous) data included for analysis increasing rapidly with time. Traditionally, ecologists are not trained in coping with the massive amounts of data that result from data sharing, sensor networks and the incorporation of environmental data into ecological research. Generally, the methodologies ecologists use for management, visualization, exploration, analysis of data are often not suited to cope with large data sets. The challenge of the eEcology project is to bridge the gap between the worlds of ecology and technology. Virtual Labs (VLs) will help to bridge this gap as they support scientific collaboration through facilitating data access, data integrity and quality control, data post-processing, data storage and backup, data merging, data sharing, interactive data visualization, and data analysis.</p>\n\n<h1 id=\"the-bird-movement-modeling-virtual-lab\">The Bird Movement Modeling Virtual Lab</h1>\n\n<p>Most effort has gone into the Bird Movement Modeling Virtual Lab. This Virtual Lab has a growing international user community, whose users are mainly field biologists using the VL to track individual birds. In the VL, the track data from the UvA-BiTS system can be combined with, for example, landscape data, weather data, and tidal data to gain new insights on the influence of the environment on the bird\u2019s behavior.</p>\n", "discipline": ["Environment & Sustainability"], "dataMagnitude": "TB", "endorsedBy": ["/organization/nlesc"], "website": "http://www.uva-bits.nl/", "logo": "/images/project/eecology.jpg", "id": "/project/eecology" }, { "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2014-10-01", "tagLine": "Chemical Informatics for Metabolite Identification and Biochemical Network Reconstruction", "slug": "emetabolomics", "coordinator": "/person/r.vannieuwpoort", "contactPerson": "/person/s.verhoeven", "engineer": ["/person/s.verhoeven"], "startDate": "2011-10-01", "dataMagnitude": "TB", "nlescWebsite": "https://www.esciencecenter.nl/project/chemical-informatics-for-metabolite-identification-and-biochemical-network", "endorsedBy": ["/organization/nlesc"], "name": "eMetabolomics", "dataFormat": ["CSV", "JSON", "mzXML", "MGF", "sqlite3"], "title": "Emetabolomics", "competence": ["Big Data Analytics", "Efficient Computing"], "uses": ["/software/osmium", "/software/xenon", "/software/magma", "/software/rdkit"], "expertise": ["High Performance Computing", "Scientific Visualization"], "principalInvestigator": ["/person/l.ridder"], "@id": "http://software.esciencecenter.nl/project/emetabolomics/", "description": "<p>The eMetabolomics project is funded by the Netherlands eScience Center and is carried out at Wageningen University and the Netherlands eScience Center in collaboration with the Netherlands Metabolomics Centre. The project develops chemo-informatics based methods for metabolite identification and biochemical network reconstruction in an integrative metabolomics data analysis workflow.</p>\n", "discipline": ["Life Sciences & eHealth"], "infrastructure": "Cloud", "involvedOrganization": ["/organization/nlesc", "/organization/wur"], "publication": ["http://dx.doi.org/10.1002/rcm.6364", "http://dx.doi.org/10.1021/ac400861a"], "website": "http://www.emetabolomics.org", "logo": "/images/project/emetabolomics.jpg", "id": "/project/emetabolomics" }, { "schema": "http://software.esciencecenter.nl/schema/project", "tagLine": "Simulating molecular dynamics: Enhancing Protein-Drug Binding Prediction", "slug": "enhancing-protein-drug-binding-prediction", "dataFormat": ["PDB", "HDF5"], "contactPerson": "http://software.esciencecenter.nl/person/l.veen", "engineer": ["http://software.esciencecenter.nl/person/l.veen", "http://software.esciencecenter.nl/person/d.vankuppevelt"], "dataMagnitude": "GB", "title": "Enhancing Protein Drug Binding Prediction", "infrastructure": "Supercomputer", "competence": ["Big Data Analytics", "Efficient Computing"], "coordinator": "http://software.esciencecenter.nl/person/r.bakhshi", "nlescWebsite": "https://www.esciencecenter.nl/project/enhancing-protein-drug-binding-prediction", "name": "Enhancing Protein-Drug Binding Prediction", "uses": ["http://software.esciencecenter.nl/project/simcity", "http://www.gromacs.org/"], "expertise": ["Data Assimilation", "Scientific Visualization", "Distributed Computing", "High Performance Computing"], "principalInvestigator": [{ "affiliation": ["http://software.esciencecenter.nl/organization/vua"], "photo": "https://www.esciencecenter.nl/img/team/daan_geerke3.jpg", "website": "http://www.chem.vu.nl/en/research/division-molecular-toxicology/staff/Geerke/index.aspx", "name": "Dr. Daan Geerke", "description": "Dr. Daan Geerke is an Assistant Professor at VU University Amsterdam. His research focuses on developing improved models (force fields) to study biomolecular systems in silico to rationalize and predict interactions of drug candidates with target and off-target proteins." }], "@id": "http://software.esciencecenter.nl/project/enhancing-protein-drug-binding-prediction/", "description": "<p>Drugs typically exert their effects by binding to proteins. Accurate methods are therefore needed to predict protein-drug binding affinities or free energies. However, efficiently computing binding free energies is difficult, and affinity prediction is typically computationally too demanding for proteins of large flexibility. These include many proteins of high relevance to pharmaceutical scientists and toxicologists, such as large families of enzymes involved in drug safety or targeted by anti-cancer drugs.\n\u201cCombining advanced modelling and eScience technologies\u201d</p>\n\n<p>As a remedy, this project aims on efficient binding affinity prediction for flexible proteins on an unprecedented scale, by introducing and combining advanced modelling and eScience technologies. For that purpose smart algorithms, molecularsimulation methods, statistical approaches, and efficient computing and data handling techniques will be developed, to overcome current scientific and methodological challenges. These include appropriate and efficient conformational sampling, identification of relevant protein structures, and automatically assigning model interaction parameters and applicability domains.</p>\n\n<p>In this project methodologies will be realized as a heterogeneous efficient computing eScience workflow. For accurate calibration and extensive validation of these models, availability and handling of large sets of accurate experimental data is crucial. These will be available via direct collaborators in academia, TNO and industry (e.g., Bayer), who have shown strong interest into the workflow this project aims to make open source. The eScience workflow will enable accurate and efficient binding and affinity prediction in applied and industrial setting, e.g. in the context of discovery, design and optimization of drugs that bind to flexible proteins with key roles in cancer therapy or drug safety.</p>\n\n<p>Image source: <a href=\"http://www.samhertig.ch/blog/wp-content/uploads/2015/10/m4v1m2.jpg\">Drug binding to receptor protein by Sam Hertig</a></p>\n", "involvedOrganization": ["http://software.esciencecenter.nl/organization/nlesc", "http://software.esciencecenter.nl/organization/vua"], "id": "/project/enhancing-protein-drug-binding-prediction", "website": null, "logo": "https://www.esciencecenter.nl/img/projects/p61-large.jpg", "discipline": ["Life Sciences & eHealth"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "tagLine": "ERA-URBAN: Environmental Re-Analysis of Urban Areas: Quantifying high-resolution energy and water budgets of European cities", "slug": "era-urban", "coordinator": "/person/e.ranguelova", "contactPerson": "/person/r.vanharen", "engineer": ["/person/r.vanharen"], "title": "Era Urban", "infrastructure": "Supercomputer", "nlescWebsite": "https://www.esciencecenter.nl/project/era-urban", "involvedOrganization": ["/organization/nlesc", "/organization/wur"], "name": "ERA-URBAN", "dataFormat": ["NetCDF", "Little-R", "JSON", "CSV"], "competence": ["Big Data Analytics", "Efficient Computing"], "uses": ["/software/netcdf2littler", "/software/wrfpy", "/software/pyxenon"], "expertise": ["Data Assimilation", "Scientific Visualization", "Distributed Computing", "High Performance Computing", "Databases"], "principalInvestigator": [{ "affiliation": ["/organization/wur"], "photo": "https://www.esciencecenter.nl/img/team/bert-holtslag-cropped-bw.jpg", "description": "Prof. Bert Holtslag is affiliated to Wageningen University as Professor of Meteorology and as chair of the Meteorology and Air Quality Section. His particular interest is advancing the knowledge of the atmospheric boundary layer and the further understanding of the complex atmosphere-land interactions.", "name": "Bert Holtslag", "website": "https://www.wageningenur.nl/en/Persons/prof.dr.-AAM-Bert-Holtslag.htm" }], "@id": "http://software.esciencecenter.nl/project/era-urban/", "description": "<p>The ERA-URBAN project takes up this eScience challenge and develops an environmental re-analysis on the scale of the urban environment; a long-term archive of urban energy and water balances at very high resolution (100m). Developing such an archive is now feasible as a direct and immediate extension of the (modelling and observational) infrastructure that has been built within NLeSC\u2019s Summer in the City project.</p>\n\n<p>Summer in the City aims at forecasting urban weather and climate on a scale of 100 m using a detailed atmospheric model. It concentrates on two cities, Amsterdam and Wageningen, each studied in detail for one summer period. Generalizing its approach to multiple cities and extending its scope to precipitation and water balance is a next logical step as it allows the systematic and consistent study of urban hydrometeorological properties among cities in different climate types and local climate zones. This also allows to explore different characteristics of the landscape surrounding the urban areas, which is a prerequisite for answering urgent, currently open research questions.</p>\n\n<p>The goal of ERA-URBAN is to make the data in the long-term archive meaningful, insightful and useful for scientists, local-scale urban planners, policy makers, (local) companies and individual citizens. This requires a high performance computing effort by multi-model simulations, combined with data-assimilation of large volume multi-source hydrometeorological observations.</p>\n\n<p>Business partners in wind energy and water management will explore the practical applicability of ERA-URBAN, which will be made publically available for use in science, engineering, and consultancy.</p>\n", "discipline": ["Environment & Sustainability"], "dataMagnitude": "PB", "endorsedBy": ["/organization/nlesc"], "logo": "/images/project/era-urban.jpg", "id": "/project/era-urban" }, { "schema": "http://software.esciencecenter.nl/schema/project", "startDate": "2016-01-01", "tagLine": "Machine Learning for System Health Management in radio astronomy", "slug": "error-detection-and-error-localization", "coordinator": "/person/e.ranguelova", "contactPerson": "/person/e.ranguelova", "engineer": ["/person/c.meijer"], "dataMagnitude": "PB", "title": "Error Detection And Error Localization", "infrastructure": "LOFAR", "nlescWebsite": "https://www.esciencecenter.nl/project/error-detection-and-error-localization", "name": "Error Detection and Error Localization Approaches for Radio Telescope System Health Management", "competence": ["Big Data Analytics", "Efficient Computing"], "uses": ["/software/casacore"], "expertise": ["Handling Sensor Data", "Machine Learning", "Information Integration", "High Performance Computing"], "principalInvestigator": [{ "affiliation": ["/organization/astron"], "website": "https://www.astron.nl/r-d-laboratory/competence-and-support-groups/staff/albert-jan-boonstra/albert-jan-boonstra", "name": "Dr. Albert-Jan Boonstra" }], "@id": "http://software.esciencecenter.nl/project/error-detection-and-error-localization/", "description": "<p>In modern radio telescopes, System Health Management (SHM) systems are\ncrucial for (early) detection of errors and for remedying them. Due to\nthe increasing scale and complexity of the systems involved, the\neffectiveness and efficiency of current day SHM approaches are\nlimited. Therefore, intelligent automated SHM approaches would\nsignificantly improve the quality and availability of the\nobservational systems.</p>\n\n<p>This is not only beneficial for maintenance, operations, and cost. It\nalso is crucial for the scientific results, as accurate knowledge of\nthe state of the telescope is essential for calibrating the\nsystem. Data analytics and more specifically Machine Learning (ML)\nhave shown to be able to \u201clearn\u201d from data.</p>\n\n<p>The purpose of this project is to investigate the applicability of\nnovel approaches such as ML for SHM in radio astronomy. Although this\nproject focuses on application of this technology in radio astronomy,\nsimilar problems arise in scientific instruments across many\ndisciplines, such as high-energy physics, ecology, life sciences and\nurban planning.</p>\n\n<p>Similar problems also occur in large-scale simulations, for example in\nwater management, computational chemistry and climate science. In this\nalliance, a generic methodology will be developed which is also\napplicable in these fields.</p>\n", "discipline": ["Physics & Beyond"], "involvedOrganization": ["/organization/astron", "/organization/nlesc"], "id": "/project/error-detection-and-error-localization", "logo": "/images/project/error-detection-and-error-localization.jpg", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "slug": "esalsa", "uses": ["/software/xenon", "/software/magnesium"], "@id": "http://software.esciencecenter.nl/project/esalsa/", "contactPerson": "/person/j.maassen", "description": "\n", "coordinator": "/person/j.maassen", "title": "Esalsa", "logo": "/images/project/esalsa.jpg", "id": "/project/esalsa", "name": "eSalsa", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "tagLine": "An eScience infrastructure for Bayesian inverse modeling", "slug": "esibayes", "coordinator": "/person/s.branchett", "contactPerson": ["/person/j.spaaks", "/person/s.branchett"], "engineer": ["/person/j.spaaks"], "title": "Esibayes", "infrastructure": "surfSARA's LISA cluster", "nlescWebsite": "https://www.esciencecenter.nl/project/esibayes", "involvedOrganization": ["/organization/uva", "/organization/surfsara", "/organization/nlesc"], "name": "esibayes", "dataFormat": ["MATLAB"], "competence": ["Big Data Analytics", "Efficient Computing"], "uses": ["/software/mmsoda-toolbox-for-matlab"], "expertise": ["Machine Learning", "Data Assimilation", "Distributed Computing", "High Performance Computing"], "principalInvestigator": [{ "affiliation": ["/organization/uva"], "photo": "https://www.esciencecenter.nl/img/team/willem-bouten-bw.jpg", "website": "http://www.uva.nl/over-de-uva/organisatie/medewerkers/content/b/o/w.bouten/w.bouten.html", "name": "Willem Bouten" }], "@id": "http://software.esciencecenter.nl/project/esibayes/", "description": "<p>An eScience infrastructure for Bayesian inverse modeling</p>\n\n<p>We have developed a parallel MATLAB version of SODA (Vrugt et al., 2005) that makes use of MPI. The software package is called \u2018The MMSODA Toolbox for MATLAB\u2019, or MMSODA for short (MMSODA stands for MATLAB-MPI-SODA).</p>\n\n<p>MMSODA offers the functionality of a number of previously separate softwares, namely SCEM-UA (Vrugt <em>et al</em>., 2003b), SODA (Vrugt <em>et al.</em>, 2005a,b; Clark and Vrugt, 2006), MOSCEM-UA (Vrugt <em>et al.</em>, 2003a), multi-objective SODA (Vrugt <em>et al.</em>, 2008), the MPITB-parallel version of SCEM-UA implemented in Octave (Vrugt <em>et al.</em>, 2006b), and the MPITB-parallel version of SODA implemented in Octave (Vrugt <em>et al.</em>, 2006a). Additionally, MMSODA offers a parallel version of multi-objective SCEM-UA, and a parallel version of multi-objective SODA, both of which did not exist previously. Moreover, MMSODA does not use Octave when running in parallel, because Octave does not evaluate code as quickly as does MATLAB. MMSODA circumvents (in a legal fashion) the license requirements that are often an impediment to parallel computation by compiling the MATLAB code into a binary which can be run without any license. Compiling the binary, however, does require a license, both for the MATLAB program itself, as well as for the MATLAB Compiler Runtime Toolbox. Fortunately, the required licenses are available on most cluster environments targeting a scientific and engineering audience.</p>\n\n<p>In short, the acronyms mentioned above mean that: MMSODA can do parameter tuning with or without intermediate state updating by an ensemble Kalman Filter; that MMSODA supports both single-objective and multi-objective optimization; and that the optimization can be run either sequentially on a local machine, or in parallel on a cluster computer.</p>\n\n<p>The serial/parallel capability is particularly attractive, since it allows the users to set up their optimizations locally on their own machines, thus ensuring a familiar development environment without the need to make the code compatible with Octave syntax. When the user finishes setting up the optimization, running it on a cluster computer is simply a matter of copying the relevant directory to the cluster storage using standard tools (e.g. WinSCP) and compiling the software by executing a script that comes with the software. Furthermore, MMSODA is fully documented with HTML documentation which can be accessed in the same way as MATLAB\u2019s built-in commands, namely through the <code class=\"highlighter-rouge\">doc</code> command.</p>\n\n<p><em>References</em></p>\n\n<ul>\n  <li>J. A. Vrugt, H. V. Gupta, L. A. Bastidas, W. Bouten, and S. Sorooshian. Effective and efficient algorithm for multi-objective optimization of hydrologic models. Water Resources Research, 39(8):1214, 2003a. doi: 10.1029/2002WR001746.</li>\n  <li>J. A. Vrugt, H. V. Gupta, W. Bouten, and S. Sorooshian. A Shuffled Complex Evolution Metropolis algorithm for optimization and uncertainty assessment of hydrologic model parameters. Water Resources Research, 39(8):1201, 2003b. doi: 10.1029/2002WR001642.</li>\n  <li>Jasper A. Vrugt, Cees G. H. Diks, Hoshin V. Gupta, Willem Bouten, and Jacobus M. Verstraten. Improved treatment of uncertainty in hydrologic modeling: Combining the strengths of global optimization and data assimilation. Water Resources Research, 41:W01017, 2005a. doi: 10.1029/2004WR003059.</li>\n  <li>Jasper A. Vrugt, Bruce A. Robinson, and Velimir V. Vesselinov. Improved inverse modeling for flow and transport in subsurface media: Combined parameter and state estimation. Geophysical Research Letters, 32:L18408, 2005b. doi: 10.1029/2005GL023940.</li>\n  <li>Jasper A. Vrugt, Hoshin V. Gupta, Breand\u00e1nn \u00d3 Nuall\u00e1in, and Willem Bouten. Real-time data assimilation for operational ensemble streamflow forecasting. Journal of Hydrometeorology, 7(3):548\u2013575, 2006a. doi: 10.1175/JHM504.1.</li>\n  <li>Jasper A. Vrugt, Breand\u00e1nn \u00d3 Nuall\u00e1in, Bruce A. Robinson, Willem Bouten, Stefan C. Dekker, and Peter M. A. Sloot. Application of parallel computing to stochastic parameter estimation in environmental models. Computers &amp; Geosciences, 32:1139\u20131155, 2006b. doi:10.1016/j.cageo.2005.10.015.</li>\n  <li>Jasper A. Vrugt, Philip H. Stauffer, Th. W\u00f6hling, Bruce A. Robinson, and Velimir V. Vesselinov. Inverse modeling of subsurface flow and transport properties: A review with new developments. Vadose Zone Journal, 7(2):843\u2013864, 2008. doi: 10.2136/vzj2007.0078.</li>\n</ul>\n", "discipline": ["eScience Methodology"], "dataMagnitude": "GB", "endorsedBy": ["/organization/nlesc"], "logo": "/images/project/esibayes.jpg", "id": "/project/esibayes" }, { "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2015-12-31", "tagLine": "Global water information when it matters", "slug": "ewatercycle", "coordinator": "/person/j.maassen", "contactPerson": "/person/n.drost", "engineer": ["/person/n.drost"], "startDate": "2012-05-01", "dataMagnitude": "TB", "competence": ["Efficient Computing"], "involvedOrganization": ["/organization/nlesc", "/organization/tu-delft", "/organization/uu"], "name": "eWaterCycle: Data-intensive modeling of the global water cycle", "dataFormat": ["NetCDF"], "title": "Ewatercycle", "id": "/project/ewatercycle", "uses": ["/software/openda", "/software/cesium-ncwms", "/software/cesium"], "expertise": ["High Performance Computing"], "principalInvestigator": [{ "affiliation": ["/organization/tu-delft"], "website": "http://www.citg.tudelft.nl/index.php?id=19972&L=1", "name": "Prof. dr. Nick van de Giesen" }], "@id": "http://software.esciencecenter.nl/project/ewatercycle/", "description": "<p>If you would know that ten days from now a flood will be at your doorstep, what would you do? You would have time to prepare emergency measures but also move your belongings to higher grounds. It might even be possible to sacrifice inexpensive farmland to save a central business district. Ten days can make a major difference. This is exactly the aim of the eWaterCycle project: to predict flood and drought events 10 days in advance, worldwide and in high resolution. The featured movie shows a setting in which the city of Mandalay is saved from a hypothetical flood. The model can act as an early warning system and enable companies, people and governments to prepare for the rising water.</p>\n\n<p>Providing vital information to the world\u2019s population</p>\n\n<p>With climate change, growing population and increasing pressures on land usage, water management is quickly becoming one of the world\u2019s major problems. Increased urbanization of delta areas in particular is making more and more people vulnerable to flooding.</p>\n\n<p>The Dutch have historical expertise and interest in water management. In the eWaterCycle project, researchers from Delft University of Technology, Utrecht University, and the Netherlands eScience Center are cooperating to build a high resolution, realistic model of the World\u2019s supply of fresh water. Using this model it will not only be possible to build a flood early warning system, but also predict the effect of unsustainable water supply usage, provide support to local governments in making decisions on water protection measures, and provide other information vital to the World\u2019s population.</p>\n", "discipline": ["Environment & Sustainability"], "infrastructure": "Supercomputer", "endorsedBy": ["/organization/nlesc"], "website": "http://ewatercycle.org", "logo": "/images/project/ewatercycle.jpg", "nlescWebsite": "http://www.esciencecenter.nl/project/ewatercycle" }, { "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2015-06-30", "tagLine": "Tracing emotion styles in theater texts", "slug": "from-sentiment-mining-to-mining-embodied-emotions", "dataFormat": ["XML", "KAF"], "contactPerson": "/person/j.vanderzwaan", "engineer": ["/person/j.vanderzwaan"], "startDate": "2015-03-01", "dataMagnitude": "MB", "nlescWebsite": "https://www.esciencecenter.nl/project/from-sentiment-mining-to-mining-embodied-emotions", "name": "Emotional styles on the Dutch stage between 1600-1800", "title": "From Sentiment Mining To Mining Embodied Emotions", "competence": ["Big Data Analytics"], "uses": ["/software/heem-dataset"], "expertise": ["Text Mining", "Machine Learning", "Information Visualization"], "principalInvestigator": [{ "affiliation": ["/organization/vua"], "website": "http://www.fgw.vu.nl/nl/over-de-faculteit/medewerkers/medewerkers-i-l/prof-dr-i-leemans/index.aspx", "name": "Prof. Inger Leemans" }], "@id": "http://software.esciencecenter.nl/project/from-sentiment-mining-to-mining-embodied-emotions/", "description": "<p>The goals of the project were to develop a methodology to identify changes\nover time in the relationship between emotional expressions and body parts in\n(historical) texts and  to apply this methodology to 17th and 18th century\nDutch theatre texts.</p>\n\n<p>The most important contribution (eScience-wise) is that we demonstrate that\na multi-label text classification approach to learning complex emotion models\non historical data is feasible. There are two parts to this contribution: 1)\nin contrast to related work on emotion mining, our emotion model is more complex\n(i.e., contains many more labels (42 instead of 6 or 8)), and 2) related work on\nemotion/sentiment mining uses modern and mostly web-based texts. The historical\ntexts used in the embodied emotions project pose specific challenges (spelling\nvariation and the lack of NLP tools that work on historical text).\nThese results were published in IEEE eScience 2015.</p>\n\n<h2 id=\"approach\">Approach</h2>\n\n<ol>\n  <li>Select (and prepare) corpus</li>\n  <li>Create annotation schema</li>\n  <li>Annotate texts</li>\n  <li>Compare manual annotation to existing sentiment mining techniques</li>\n  <li>Do machine learning with annotated texts and analyze the results</li>\n</ol>\n\n<p>A lot of time was spend on data selection and curation. The annotation schema\nwas created by the domain experts. It consists of 42 labels\non two layers (emotion labels and concept types). Existing work on emotion mining\nuses much simpler emotion models (6 to 8 labels). Details about the emotion model\ncan be found in the IEEE eScience paper and the domain papers.</p>\n\n<p>The annotation corpus was annotated by domain experts. To check the consistency\nand reliability of the annotations, an inter-annotator study was carried out.\nThe results of this study show that annotating texts using our annotation scheme\nwas quite difficult. See the IEEE eScience paper for details.</p>\n\n<p>The manual annotations were compared to existing sentiment mining techniques,\nincluding Linguistic Inquiry and Word Count (LIWC)\na dictionary method that counts the occurences of words in different\n(psychological) categories, including postive and negative emotions.</p>\n\n<p>For the machine learning part of the project, we followed the approach used in\nthe SpuDisc project; the problem of predicting labels from our emotion model was\ntreated as a multi-label text classification task. We experimented with two\nalgorithms for multi-label classification: Binary Relevance (BR) and\nRandom k-Labelsets (RAkEL). Linear Support Vector Machines (SVM) using\nstandard bag-of-words features with tf-idf weighting and stop\nword removal were trained for both classification algorithms.\nWe also experimented with spelling normalization. More details about our method\nand results can be found in the IEEE eScience paper.</p>\n\n<p>The text classifiers trained were applied to a corpus of 250 texts. The results\nwere analysed to gain insight on how emotions and the embodiment of emotions\nchange over time.</p>\n", "discipline": ["Humanities & Social Sciences"], "involvedOrganization": ["/organization/nlesc", "/organization/vua", "/organization/meertens"], "id": "/project/from-sentiment-mining-to-mining-embodied-emotions", "publication": ["http://dx.doi.org/10.1109/eScience.2015.18"], "logo": "/images/project/from-sentiment-mining-to-mining-embodied-emotions.jpg", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "tagLine": "Making breakthroughs in data-driven research", "slug": "generic-escience-technologies", "coordinator": "/person/r.vannieuwpoort", "contactPerson": "/person/r.vannieuwpoort", "engineer": ["/person/r.vannieuwpoort"], "dataMagnitude": "TB", "startDate": "2013-01-01", "infrastructure": "DAS-5", "nlescWebsite": "https://www.esciencecenter.nl/project/generic-escience-technologies", "name": "Generic eScience Technologies", "title": "Generic Escience Technologies", "competence": ["Big Data Analytics", "Efficient Computing"], "expertise": ["Accelerated Computing", "Linked Data"], "principalInvestigator": [{ "affiliation": ["/organization/uva"], "website": "http://delaat.net/", "name": "Prof. Cees de Laat" }], "@id": "http://software.esciencecenter.nl/project/generic-escience-technologies/", "description": "<p>This project addresses several research challenges in computer science\nspecifically needed to make breakthroughs in data-driven research. The\nproject is focused on the data explosion problem, which is one of the\nmost important challenges in almost all areas of science. The sheer\nvolume and the distributed nature of many data sets lead to\ncomplicated technical problems around data transport and\ndata-processing. The data also becomes more complex and heterogeneous,\nespecially when different data sets are combined from various\ninstruments and databases, which is typical for system-level\nsciences. In particular, this complexity makes it a challenge to\nextract semantically useful information from the data.</p>\n\n<p>The parallel and distributed computing environments on which\napplications have to run also are changing drastically at all levels,\nfrom processor architectures (multi-cores like GPUs) to networking\n(hybrid networks, sensor networks), storage architectures, and\nmiddleware (virtualization and Clouds). The project divides focus\nbetween the volume aspect of the data explosion (big data) and the\ncomplexity aspect (heterogeneous data). One postdoc works on\ninfrastructure innovation and distributed data processing (especially\non many-cores such as GPUs) and a second focuses on information\nmanagement, in particular complexity analysis of scientific data sets\nfor various disciplines.</p>\n", "discipline": ["eScience Methodology"], "involvedOrganization": ["/organization/uva", "/organization/vua", "/organization/cwi", "/organization/nlesc"], "id": "/project/generic-escience-technologies", "logo": "/images/project/generic-escience-technologies.jpg", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2016-04-01", "tagLine": "Visualizing Dutch presence in the Eternal City", "slug": "hadrianus", "dataFormat": ["Tabular text", "Images"], "contactPerson": "/person/p.bos", "engineer": ["/person/p.bos"], "startDate": "2014-09-01", "dataMagnitude": "GB", "nlescWebsite": "https://www.esciencecenter.nl/project/handrianvs-a-digital-gateway-to-the-dutch-presence-in-rome-through-the-ages", "involvedOrganization": ["/organization/nlesc", "/organization/knir", "/organization/uva"], "name": "Hadrianus", "title": "Hadrianus", "competence": ["Optimized Data Handling"], "expertise": ["Linked Data", "Information Visualization"], "principalInvestigator": [{ "affiliation": ["/organization/knir"], "website": "http://www.knir.it/en/arthur-weststeijn.html", "name": "Dr. Arthur Weststeijn" }, { "affiliation": ["/organization/uva", "/organization/knir"], "website": "http://www.uva.nl/over-de-uva/organisatie/medewerkers/content/d/o/m.j.e.vandendoel/m.j.e.vandendoel.html", "name": "Dr. Marieke van den Doel" }], "@id": "http://software.esciencecenter.nl/project/hadrianus/", "description": "<p>A digital gateway to the Dutch presence in Rome through the ages</p>\n", "discipline": ["Humanities & Social Sciences"], "infrastructure": "OpenLink Virtuoso for hosting and serving the Linked Data view on the data", "id": "/project/hadrianus", "logo": "/images/project/hadrianus.jpg", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2019-04-01", "tagLine": "Project combines the worldwide data within the most general models of Dark Matter.", "slug": "idark", "coordinator": "/person/r.bakhshi", "contactPerson": "/person/f.diblen", "description": "\n", "expertise": ["Accelerated Computing", "Information Visualization"], "id": "/project/idark", "engineer": ["/person/f.diblen"], "principalInvestigator": [{ "affiliation": ["/organization/radboud.university.nijmegen"], "website": "http://www.nikhef.nl/~scaron", "name": "Dr. Sascha Caron" }], "nlescWebsite": "http://www.esciencecenter.nl/project/idark", "@id": "http://software.esciencecenter.nl/project/idark/", "competence": ["Efficient Computing", "Optimized Data Handling"], "logo": "/images/project/idark.jpg", "involvedOrganization": ["/organization/nlesc", "/organization/radboud.university.nijmegen", "/organization/uva", "/organization/upv", "/organization/icl"], "title": "Idark", "endorsedBy": ["/organization/nlesc"], "name": "iDark", "startDate": "2016-04-01", "discipline": ["Physics & Beyond", "eScience Methodology"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "tagLine": "Improving Open-Source Photogrammetric Workflows for Processing Big Datasets", "slug": "improving-photogrammetry", "uses": ["/software/micmac", "/software/noodles", "/software/pycoeman", "/software/pymicmac"], "@id": "http://software.esciencecenter.nl/project/improving-photogrammetry/", "contactPerson": "/person/o.rubi", "engineer": ["/person/o.rubi"], "title": "Improving Photogrammetry", "description": "<p>Aerial imagery over urban areas is increasingly being used to provide detailed imagery and 3D models to support many applications such as map updating, urban planning and water management. The size of such photogrammetric projects is increasing rapidly, causing a scramble for hardware with more memory and processing power. A conventional UAV (Unmanned Aerial Vehicle) flight can collect thousands of images and conventional photogrammetric sensors can acquire images of more than 200 Megapixels in size.</p>\n\n<p>Nowadays, the need of high performance hardware represents one of the main bottlenecks in the development of efficient automated applications exploiting photogrammetry over large areas. This Path-Finding Project will implement three tools for processing of large datasets able to run on consumer-grade computers.</p>\n\n<p>Two case studies are used to test the developed tools. The first considers how to make photogrammetric workflows accessible to end-users lacking advanced hardware, such as city planners in developing countries. In 2015, 16.000 images covering 150 hectare were collected over informal settlements in Kigali, Rwanda using a low-cost UAV. To analyze the potential of UAVs to provide accurate geo-information to support informal settlement upgrading projects, the workflow should be completed using consumer-grade computers.</p>\n\n<p>The second case study is related to mapping applications. Recently, projects have been developed to update national 3D models, for example the Dutch digital height model (AHN), through DIM from aerial images. The goal is to automatically process this enormous block using a consumer-grade PC. The dataset over Rotterdam will be used for this task.</p>\n", "involvedOrganization": ["/organization/utwente", "/organization/ign", "/organization/nlesc"], "id": "/project/improving-photogrammetry", "name": "Improving Open-Source Photogrammetric Workflows for Processing Big Datasets", "logo": "/images/project/improving-photogrammetry.jpg", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2016-12-31", "tagLine": "Handling data assimilation on a large scale", "slug": "large-scale-data-assimilation", "coordinator": "/person/j.maassen", "contactPerson": "/person/n.drost", "engineer": ["/person/n.drost"], "startDate": "2015-01-01", "dataMagnitude": "TB", "competence": ["Efficient Computing"], "involvedOrganization": ["/organization/nlesc", "/organization/tu-delft", "/organization/deltares"], "name": "Large Scale Data Assimilation", "dataFormat": ["NetCDF"], "title": "Large Scale Data Assimilation", "id": "/project/large-scale-data-assimilation", "uses": ["/software/openda", "/software/xenon"], "expertise": ["High Performance Computing"], "principalInvestigator": [{ "affiliation": ["/organization/tu-delft"], "website": "http://www.citg.tudelft.nl/index.php?id=19972&L=1", "name": "Prof. dr. Nick van de Giesen" }], "@id": "http://software.esciencecenter.nl/project/large-scale-data-assimilation/", "description": "<p>The operational global hydrological model built in the eWaterCycle project has all central features, such as near real-time data assimilation and global coverage. An important feature of the eWaterCycle system is its ability to predict flooding. One of the biggest challenges remaining is the scaling up of this system, in particular the Data Assimilation. In this project methods and software will be developed for handling DA on a large scale. The result will be an operational global model that produces detailed flood predictions around the globe.</p>\n", "discipline": ["Environment & Sustainability"], "infrastructure": "Supercomputer", "endorsedBy": ["/organization/nlesc"], "logo": "/images/project/large-scale-data-assimilation.jpg", "nlescWebsite": "https://www.esciencecenter.nl/project/large-scale-data-assimilation" }, { "schema": "http://software.esciencecenter.nl/schema/project", "title": "Massive Biological Data Clustering Reporting And Visualization Tools", "slug": "massive-biological-data-clustering-reporting-and-visualization-tools", "uses": ["/software/cclustera"], "id": "/project/massive-biological-data-clustering-reporting-and-visualization-tools", "contactPerson": "/person/s.georgievska", "description": "<p>A stepping stone for an online service for identification and classification of fungal species.</p>\n", "expertise": ["Information Visualization"], "nlescWebsite": "https://www.esciencecenter.nl/project/massive-biological-data-clustering-reporting-and-visualization-tools", "@id": "http://software.esciencecenter.nl/project/massive-biological-data-clustering-reporting-and-visualization-tools/", "discipline": ["Life Sciences & eHealth"], "involvedOrganization": ["/organization/cbs-knaw"], "endorsedBy": ["/organization/nlesc"], "name": "Massive Biological Data Clustering, Reporting and Visualization Tools", "logo": "/images/project/massive-biological-data-clustering-reporting-and-visualization-tools.jpg", "competence": ["Big Data Analytics"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "tagLine": "Massive Point-Clouds for eSciences", "slug": "massive-point-clouds-for-esciences", "uses": ["/software/monetdb", "/software/datavaults", "/software/pdal", "/software/potreeconverter", "/software/massivepotreeconverter", "/software/ahn2webviewer", "/software/potree", "/software/liblas"], "@id": "http://software.esciencecenter.nl/project/massive-point-clouds-for-esciences/", "contactPerson": "/person/o.rubi", "id": "/project/massive-point-clouds-for-esciences", "engineer": ["/person/o.rubi", "/person/r.goncalves", "/person/m.vanmeersbergen", "/person/s.verhoeven"], "title": "Massive Point Clouds For Esciences", "description": "<p>We are witnessing an increased significance of point clouds for societal and scientific applications, such as in smart cities, 3D urban modeling, flood modeling, dike monitoring, forest mapping, and digital object preservation in history and art. Modern Big Data acquisition technologies, such as laser scanning from airborne, mobile, or static platforms, dense image matching from photos, or multi-beam echo-sounding, have the potential to generate point clouds with billions (or even trillions) of elevation/depth points. One example is the height map of the Netherlands (the  AHN2 dataset), which consists of no less than 640.000.000.000 height values.</p>\n\n<p>The main problem with these point clouds is that they are simply too big (several terabytes) to be handled efficiently by common ICT infrastructures. At this moment researchers are unable to use this point cloud Big Data to its full potential because of a lack of tools for data management, dissemination, processing, and visualization.</p>\n\n<p>The goal is a scalable (more data and users without architectural change) and generic solution: keep all current standard object-relational database management system (DBMS) and integrate with existing spatial vector and raster data functionality. Core support for point cloud data types in the DBMS is needed, besides the existing vector and raster data types. Furthermore, a new and specific web-services protocol for point cloud data is investigated, supporting progressive transfer based on multi-resolution. Based on user requirements analysis a point cloud benchmark is specified. Oracle, PostgreSQL, MonetDB and file based solutions are analyzed and compared. After identifying weaknesses in existing DBMSs, R&amp;D activities will be conducted in order to realize improved solutions, in close cooperation with the various DBMS developers. The non-academic partners in this project (Rijkswaterstaat, Fugro and Oracle) will deliver their services and expertise and provide access to data and software (development).</p>\n", "involvedOrganization": ["/organization/tu-delft", "/organization/cwi", "/organization/fugro", "/organization/oracle", "/organization/rijkswaterstaat", "/organization/potree"], "publication": ["http://dx.doi.org/10.14778/2824032.2824110", "http://dx.doi.org/10.1016/j.cag.2015.01.007"], "name": "Massive Point Clouds for eSciences", "logo": "/images/project/massive-point-clouds-for-esciences.jpg", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "title": "Microscopy", "tagLine": "Studying subcellular structures and functions", "slug": "microscopy", "uses": ["/software/kernel_tuner"], "coordinator": "/person/w.vanhage", "contactPerson": "/person/b.vanwerkhoven", "description": "<p>Optical nanoscopy is a powerful technique used in biology to study \nsubcellular structures and functions via specifically targeted \nfluorescent labels. Localization microscopy in particular offers a much \nbetter resolution (~10-50 nm) than conventional microscopy (~250 nm) \nwhile being relatively undemanding on the experimental setup and the \nsubsequent image analysis.</p>\n\n<p>The next revolution in imaging towards 1 nm resolution must realize a \nbig increase of the labelling density. Only then can subcellular \nstructures be imaged at the molecular level to study the molecular \nmachinery of the cell. Relaxing the required labelling density using a \npriori information by data fusion of many identical entities is one of \nthe challenges in the field.</p>\n\n<p>This idea, taken from cryo-Electron Microscopy, has already lead to new \ninsights in the structure of the Nuclear Pore Complex. However, due to \nthe computational complexity this work is just starting. More so, \nalgorithms and image processing from the field of electron microscopy \ncannot be translated into light microscopy due to the very different \nimage formation. The data here consist out of localizations of \nfluorophores per particle which yields a list of x, y, z positions, a \npoint cloud, with associated (anisotropic) measurement uncertainties sx, \nsy and sz, where sx= sy but sx\u2260 sz due to the imaging modality. These \nmeasurement uncertainties are different for each point in the cloud, due \nto the fluctuations in the detected photon signal and thus cannot be \nignored in the registration for optimal performance.</p>\n\n<p>The computational complexity arises (1) from the large number of \nparticles ~103-104, (2) the large number of points per particle ~103 and \n(3) from the evaluation of the most suited cost function, the \nBhattacharyya distance, for registration that takes the measurement \nuncertainty into account.</p>\n\n<p>Typically computation times for a full tree would be months on a \nmulti-core server where acquisition times are at most one afternoon. \nThis project will be scientifically embedded into an ERC consolidator \ngrant (to BR) on optical nanoscopy.</p>\n\n<p>We want to develop an image processing framework that is multi-core and \nGPU capable for fast computation of the whole workflow including multi \npoint-cloud registration. In order to do so, and disseminate the \nalgorithm and the code, we want to implement the multi-point-cloud \ntemplate-free registration based on our existing and well-used image \nanalysis library DIPlib. However, first we need to invest in updating \nthe core of the library, now 20 years old, to support multi-threading \nand GPU computing in a flexible, easy to access, and long term \nsupportable way.</p>\n", "expertise": ["Accelerated Computing", "High Performance Computing"], "id": "/project/microscopy", "engineer": ["/person/b.vanwerkhoven"], "nlescWebsite": "https://www.esciencecenter.nl/project/parallelisation-of-multi-point-cloud-registration", "@id": "http://software.esciencecenter.nl/project/microscopy/", "discipline": ["Physics & Beyond"], "involvedOrganization": ["/organization/tu-delft", "/organization/nlesc"], "endorsedBy": ["/organization/nlesc"], "name": "Parallelisation of multi point-cloud registration", "logo": "/images/project/p071-large.jpg", "competence": ["Efficient Computing"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "title": "Neutrino", "tagLine": "Observing processes that are inaccessible to optical telescopes", "slug": "neutrino", "uses": ["/software/kernel_tuner"], "coordinator": "/person/j.maassen", "contactPerson": "/person/b.vanwerkhoven", "description": "<p>A new era in the exploration of the Universe has begun. The distant Universe has so far only been accessible to us via photons of different wavelengths. But with the recent discovery of high-energetic extraterrestrial neutrinos new and unique opportunities arise to observe processes that are inaccessible to optical telescopes.</p>\n\n<p>The KM3NeT neutrino telescope, currently under construction In the Mediterranean Sea, enables researchers to fully exploit this new opportunity. The Mediterranean Sea appears to be an ideal place for this future installation: it provides water of excellent optical properties at the right depth and excellent shore-based infrastructure for marine operations and on-shore data processing. Light created by particles in neutrino interactions in the Earth or in water is collected with a large 3-dimensional grid of sensitive photo detectors. All information from the detectors is sent to shore for further filtering and processing.</p>\n\n<p>The current hardware and time constraints do not allow the most detailed processing of the information come from the detectors. This means that not all interesting event signatures will be stored. Current algorithms focus on the selection of specific signatures in the hit correlations which are expected from high energetic interactions. If we can enhance the strict filtering to a full online event reconstruction, so that we can retrieve accurate information on the potential neutrino candidates in real time, the data could be recorded more efficiently.</p>\n\n<p>An accurate online reconstruction of the detailed event properties can also provide interesting neutrino triggers or feedback of external triggers to other astronomical facilities like optical or gamma ray observatories. At these observatories these signals can immediately be followed up to not miss out on interesting events in the Universe.</p>\n", "expertise": ["Distributed Computing", "Accelerated Computing", "High Performance Computing"], "id": "/project/neutrino", "engineer": ["/person/h.spreeuw", "/person/d.remenska", "/person/b.vanwerkhoven"], "nlescWebsite": "https://www.esciencecenter.nl/project/real-time-detection-of-neutrinos-from-the-distant-universe", "@id": "http://software.esciencecenter.nl/project/neutrino/", "discipline": ["eScience Methodology"], "involvedOrganization": ["/organization/nikhef", "/organization/nlesc", "/organization/leiden-university"], "endorsedBy": ["/organization/nlesc"], "name": "Real-time detection of neutrinos from the distant Universe", "logo": "/images/project/neutrino.jpg", "competence": ["Optimized Data Handling", "Big Data Analytics", "Efficient Computing"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2017-06-01", "tagLine": "ODEX4all: Open discovery and exchange for all", "slug": "odex4all", "coordinator": "/person/l.ridder", "engineer": ["/person/a.kuzniar"], "startDate": "2015-06-01", "dataMagnitude": "TB", "competence": ["Optimized Data Handling"], "involvedOrganization": ["/organization/nlesc", "/organization/lumc", "/organization/dtl", "/organization/wur"], "name": "ODEX4all", "dataFormat": ["RDF serializations", "JSON-LD"], "title": "Odex4all", "id": "/project/odex4all", "uses": ["/software/fairdatapoint"], "expertise": ["Information Integration", "Linked Data", "Databases"], "principalInvestigator": [{ "affiliation": ["/organization/lumc", "/organization/dtl"], "photo": "https://www.esciencecenter.nl/img/team/barend-mons-cropped-bw.jpg", "description": "Prof. Barend Mons is Professor of BioSemantics and founder of the BioSemantics group at the LUMC. Next to his leading role in the research of the group, Barend plays a leading role in the international development of 'FAIR data stewardship' for biomedical data. For instance, he is head-of-node of Elixir-NL. Elixir is a pan-European project to develop and foster bioinformatics infrastructure across the member states. The focus of the contribution of the BioSemantics group is on developing an interoperability backbone for biomedical applications in general and rare disease in particular.", "name": "Barend Mons", "website": "http://biosemantics.humgen.nl" }], "@id": "http://software.esciencecenter.nl/project/odex4all/", "description": "<p>The ODEX4all project aims at the development and sustainability of an environment where diverse sources of (big) data are published so that both computers and humans can \u2018understand\u2019 and process them effectively. To that end, semantic web and computer sciences are combined.</p>\n", "discipline": ["Life Sciences & eHealth"], "infrastructure": "Cloud", "endorsedBy": ["/organization/nlesc"], "logo": "/images/project/odex4all.jpg", "nlescWebsite": "https://www.esciencecenter.nl/project/odex4all" }, { "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2016-03-01", "tagLine": "Modern Big Data front and backends in the hunt for Dark Matter.", "slug": "pandas-root", "coordinator": "/person/j.maassen", "contactPerson": "/person/d.remenska", "engineer": ["/person/d.remenska"], "startDate": "2015-06-20", "dataMagnitude": "TB", "competence": ["Optimized Data Handling", "Efficient Computing"], "name": "Giving pandas ROOT To Chew On", "dataFormat": ["JSON", "ROOT binary format", "pandas DataFrames"], "title": "Pandas Root", "id": "/project/pandas-root", "uses": ["/software/root-conda-recipes", "/software/pyroot", "/software/root"], "expertise": ["Linked Data", "High Performance Computing"], "principalInvestigator": [{ "jobTitle": "PostDoc", "affiliation": ["/organization/nikhef"], "name": "Dr. Christopher Tunnell", "website": "http://www.nikhef.nl/~decowski/Group.html" }], "@id": "http://software.esciencecenter.nl/project/pandas-root/", "description": "<p>This project presents a way to harmonize two ecosystems: High Energy Physics (domain-specific) and the Big Data Analytics (generic). The goal is to organize software and data such that researchers can work with existing particle physics infrastructure, yet still use modern communal Big Data tools.</p>\n", "discipline": ["Physics & Beyond"], "involvedOrganization": ["/organization/nlesc", "/organization/nikhef"], "endorsedBy": ["/organization/nlesc"], "website": "http://www.xenon1t.org", "logo": "/images/project/pandas-root.jpg", "nlescWebsite": "https://www.esciencecenter.nl/project/giving-pandas-a-root-to-chew-on" }, { "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2016-04-01", "tagLine": "Visualizing relations between politics and media during 'Verzuiling' in the Netherlands", "slug": "pidimehs", "coordinator": "/person/j.attema", "contactPerson": "/person/p.bos", "engineer": ["/person/p.bos"], "startDate": "2014-09-01", "dataMagnitude": "TB", "competence": ["Big Data Analytics"], "involvedOrganization": ["/organization/nlesc", "/organization/university.of.groningen", "/organization/uva", "/organization/surfsara"], "name": "PIDIMEHS: Pillarization and depillarization tested in digitized media historical sources", "dataFormat": ["JSON", "XML"], "title": "Pidimehs", "id": "/project/pidimehs", "uses": ["/software/pidilib"], "expertise": ["Text Mining", "Information Retrieval", "Information Visualization", "Data Assimilation"], "principalInvestigator": [{ "affiliation": ["/organization/university.of.groningen"], "website": "http://www.huubwijfjes.nl/", "name": "Prof. Huub Wijfjes" }, { "affiliation": ["/organization/university.of.groningen"], "website": "http://www.rug.nl/staff/g.voerman/", "name": "Prof. Gerrit Voerman" }], "@id": "http://software.esciencecenter.nl/project/pidimehs/", "description": "<p>Visualizing relations between politics and media during \u2018Verzuiling\u2019 in the Netherlands. For further information and results see:</p>\n\n<ul>\n  <li>the <a href=\"https://www.esciencecenter.nl/project/pidimehs\">NLeSC project site</a>;</li>\n  <li>the <a href=\"https://www.kb.nl/organisatie/kb-fellowship/huub-wijfjes\">KB-NIAS fellowship page of Huub Wijfjes</a>;</li>\n  <li><a href=\"http://ceur-ws.org/Vol-1632/paper_8.pdf\">our paper for the HistoInformatics 2016 workshop proceedings</a>;</li>\n  <li>the <a href=\"http://dx.doi.org/10.17026/dans-xzj-vhgd\">newspaper selection and indicator dataset at DANS</a>.</li>\n</ul>\n", "discipline": ["Humanities & Social Sciences"], "infrastructure": "Elasticsearch for indexing and searching newspaper data, iPython notebook for interactive analysis", "endorsedBy": ["/organization/nlesc"], "logo": "/images/project/pidimehs.jpg", "nlescWebsite": "https://www.esciencecenter.nl/project/pidimehs" }, { "schema": "http://software.esciencecenter.nl/schema/project", "tagLine": "PRIMAVERA: Process-based climate simulation: Advances in high-resolution modelling and European climate risk assessment", "slug": "primavera", "dataFormat": ["NetCDF", "Grib", "HDF5", "CSV"], "contactPerson": "http://software.esciencecenter.nl/person/r.bakhshi", "engineer": ["http://software.esciencecenter.nl/person/r.bakhshi", "http://software.esciencecenter.nl/person/g.vandenoord"], "dataMagnitude": "PB", "title": "Primavera", "infrastructure": "Supercomputer", "nlescWebsite": "https://www.esciencecenter.nl/project/primavera", "name": "PRIMAVERA", "competence": ["Big Data Analytics", "Efficient Computing"], "uses": null, "expertise": ["Data Assimilation", "Scientific Visualization", "Distributed Computing", "High Performance Computing"], "principalInvestigator": [{ "affiliation": ["http://software.esciencecenter.nl/organization/knmi"], "photo": "https://simpleclimate.files.wordpress.com/2013/03/rein2.jpg", "website": "https://www.knmi.nl/over-het-knmi/onze-mensen/rein-haarsma", "name": "Dr. Rein Haarsma", "description": "Dr. Rein Haarsma is a senior scientist at R&D Weather and Climate Modeling, KNMI. His research expertise is large-scale atmospheric dynamics, ocean-atmosphere interactions and tropical cyclones." }], "@id": "http://software.esciencecenter.nl/project/primavera/", "description": "<p>Many of the most pressing questions about regional climate change urgently require advances in process simulation. For example, to what extent are recent heat waves, floods and droughts in Europe attributable to natural variability or human influences on the global climate system? How will the risk of such high impact events change over the next few decades and beyond?</p>\n\n<p>The extent to which it is possible to provide robust answers to these questions relies fundamentally on the fidelity of the climate models that are used to address them. However, fidelity is insufficient in itself: we must be able to justify why a particular model produces a particular prediction at the process level.</p>\n\n<p>Many years of experience, first in numerical weather prediction and, equally albeit only recently, in climate simulation, have demonstrated that advances in the explicit simulation of key processes are essential to achieving sustained progress and to provide robust answers. High-resolution has been identified as one essential element of the development of GCMs to reproduce key climate processes with higher fidelity than conventional GCMs, thus enabling detailed process understanding.</p>\n\n<p>PRIMAVERA is a European Union Horizon2020 project that aims to develop a new generation of advanced and well-evaluated high-resolution global climate models, capable of simulating and predicting regional climate with unprecedented fidelity, for the benefit of governments, business and society in general.</p>\n", "involvedOrganization": ["http://software.esciencecenter.nl/organization/nlesc", "http://software.esciencecenter.nl/organization/knmi"], "id": "/project/primavera", "website": null, "logo": "https://www.esciencecenter.nl/img/projects/p64-large.jpg", "discipline": ["Environment & Sustainability"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "title": "Sherlock", "tagLine": "Sherlock is an NLeSC-wide project in which all eScience Research engineers of the NLeSC work together.", "slug": "sherlock", "uses": ["/software/rig", "/software/metrochartjs", "/software/matrix-of-scatter", "/software/spiraljs", "/software/punchcardjs"], "dataFormat": ["JSON"], "contactPerson": "/person/j.maassen", "description": "<p>Sherlock is an NLeSC-wide project in which all eScience Research engineers of the NLeSC work together. The goals of Sherlock are:</p>\n\n<ul>\n  <li>Team building: get to know your (new) colleagues, their interests, skills, knowledge, etc.</li>\n  <li>Knowledge sharing &amp; development: learn from each other and collectively learn new skills.</li>\n  <li>eStep: producing generic tools, knowledge and research for eStep.</li>\n  <li>Boost the parent project: give a project access to the skills and knowledge 30 engineers.</li>\n</ul>\n\n<p>For Sherlock the parent project is <a href=\"https://www.esciencecenter.nl/project/a-jungle-computing-approach-to-large-scale-online-forensic-analysis\">A Jungle Computing Approach to Large Scale Online Forensic Analyis</a>, a cooperation with the <a href=\"http://www.nederlandsforensischinstituut.nl/\">NFI</a> and the HPDC group at\n<a href=\"http://www.cs.vu.nl/en/research/computer-systems/hpdc/\">VU University</a>.</p>\n\n<p>Sherlock is about <a href=\"https://en.wikipedia.org/wiki/Digital_forensics\">Digital Forensics</a>, more specifically about finding digital evidence in large amounts of data. Finding such evidence requires analyis of large amounts of text and multimedia data and means of clustering, visualising and searching through the results.</p>\n\n<h2 id=\"team-topics\">Team Topics</h2>\n\n<p>The Sherlock teams will work on the following topics:</p>\n\n<ul>\n  <li><a href=\"https://github.com/NLeSC/Sherlock/blob/master/topics/analyzing_document_collections/analyzing_large_document_collections.md\">Analyzing large document collections</a></li>\n  <li>(ABANDONED <a href=\"https://github.com/NLeSC/Sherlock/blob/master/topics/concept_search/README.md\">Concept search</a>)</li>\n  <li><a href=\"https://github.com/nlesc-sherlock/Sherlock/blob/master/topics/data_cleaning_toolkit/README.md\">Data Cleaning Toolkit</a></li>\n  <li><a href=\"https://github.com/NLeSC/Sherlock/blob/master/topics/deeplearning/deeplearning4computervision.md\">Deep learning for computer vision</a></li>\n  <li><a href=\"https://github.com/NLeSC/Sherlock/tree/master/topics/timeline-visualization\">Visualization of timelines</a></li>\n  <li><a href=\"https://github.com/NLeSC/Sherlock/blob/master/topics/clusteranalysis/readme.md\">Cluster analysis</a></li>\n  <li><a href=\"https://github.com/NLeSC/Sherlock/blob/master/topics/data_tools_integration/README.md\">Tool and data integration</a></li>\n</ul>\n", "expertise": ["Text Mining", "Machine Learning", "Information Visualization", "Information Retrieval", "Computer Vision", "Distributed Computing", "High Performance Computing"], "id": "/project/sherlock", "engineer": ["/person/j.vanderzwaan", "/person/j.spaaks"], "@id": "http://software.esciencecenter.nl/project/sherlock/", "dataMagnitude": "GB", "discipline": ["eScience Methodology"], "logo": "/images/project/sherlock.png", "involvedOrganization": ["/organization/nlesc", "/organization/nfi"], "endorsedBy": ["/organization/nlesc"], "name": "Sherlock", "website": "https://github.com/nlesc-sherlock", "startDate": "2015-10-20", "competence": ["Big Data Analytics", "Optimized Data Handling", "Efficient Computing"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "title": "Shico", "tagLine": "Understanding the past through the history of concepts", "slug": "shico", "uses": ["/software/texcavator"], "coordinator": "/person/j.attema", "contactPerson": "/person/c.martinez", "description": "<h1 id=\"word-vector-text-mining-change-and-continuity-in-conceptual-history\">Word vector text mining change and continuity in conceptual history</h1>\n\n<p>Historical concepts (such as citizenship, democracy, evolution, health, liberty, security, trust, etc.) are essential to our understanding of the past. The history of concepts is a well-established field of research for historians, philosophers and linguists alike. However, there is little agreement on the nature of conceptual change, continuity and replacement, or on the proper methodology to distinguish between core concepts and the marginal vocabularies that are attached to them in certain historical contexts. Currently the notion that concepts are stable unit-ideas that constitute the continuous foundation of changing historical debates, just as chemical elements can form different molecules, is being revaluated.</p>\n", "expertise": ["Text Mining", "Information Visualization", "Scientific Visualization", "Information Retrieval"], "id": "/project/shico", "engineer": ["/person/c.martinez"], "principalInvestigator": [{ "affiliation": ["/organization/uu"], "website": "http://www.uu.nl/medewerkers/JvanEijnatten/", "name": "Prof. Joris van Eijnatten" }, { "affiliation": ["/organization/uu"], "website": "http://www.uu.nl/staff/JVerheul/", "name": "Dr. Jaap Verheul" }], "nlescWebsite": "https://www.esciencecenter.nl/project/mining-shifting-concepts-through-time-shico", "@id": "http://software.esciencecenter.nl/project/shico/", "infrastructure": "Web platform", "competence": ["Optimized Data Handling"], "involvedOrganization": ["/organization/uu", "/organization/nlesc"], "endorsedBy": ["/organization/nlesc"], "name": "Mining Shifting Concepts Through Time (ShiCo)", "logo": "/images/project/shico.jpg", "discipline": ["Humanities & Social Sciences"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "tagLine": "SIM-CITY: Decision support for urban social economic complexity", "slug": "simcity", "coordinator": "/person/w.vanhage", "contactPerson": "/person/j.borgdorff", "engineer": ["/person/j.borgdorff"], "title": "Simcity", "dataMagnitude": "TB", "competence": ["Efficient Computing"], "involvedOrganization": ["/organization/nlesc", "/organization/uva"], "endorsedBy": ["/organization/nlesc"], "name": "SIM-CITY", "dataFormat": ["GeoJSON", "JSON", "OpenGeoSpatial XML", "OSM XML", "CSV", "XML (simulation-specific)"], "id": "/project/simcity", "uses": ["/software/xenon", "/software/pyxenon", "/software/common-sense", "/software/picas", "/software/couchdb", "/software/docker-couch-admin"], "expertise": ["Information Visualization", "Scientific Visualization", "Handling Sensor Data", "Information Integration", "Distributed Computing"], "principalInvestigator": [{ "affiliation": ["/organization/uva", "/organization/itmo", "/organization/ntu"], "photo": "https://www.esciencecenter.nl/img/team/peter-sloot-cropped-bw.jpg", "description": "Prof. Peter Sloot is Distinguished Research Professor at the University of Amsterdam. He studies 'natural information processing' in complex systems by computational modeling and simulation as well as through formal methods.", "name": "Peter Sloot", "website": "http://www.peter-sloot.com" }], "@id": "http://software.esciencecenter.nl/project/simcity/", "description": "<p>SIM-CITY will study and develop an agent-based complex network system to interactively explore socio-economic scenarios that can support decision makers of large urban areas, notably greater Amsterdam in the Netherlands and Bangalore in India. The research will provide a decision support infrastructure for three case studies - the Relationship between the Urban Poor and the City in an Increasingly Urbanizing World; Dense City Infectious Disease Pressure; and Evacuation Strategies in Case of Emergencies. In the last case study for example, geographical information system data about the road network in the city will be collected, along with spatial data from the different emergency services, and the capabilities of the emergency services (for example for hospitals: specialty of the hospital, number of beds, number of ambulances, etc.). This will then have to be overlaid with the traffic data we wish to collect through the traffic authorities in the city.</p>\n", "discipline": ["Humanities & Social Sciences"], "infrastructure": "Clouds and clusters", "publication": ["http://dx.doi.org/10.1016/j.procs.2015.05.399"], "website": "http://simcity.amsterdam-complexity.nl", "logo": "/images/project/simcity.jpg", "nlescWebsite": "https://www.esciencecenter.nl/project/sim-city" }, { "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2016-09-01", "tagLine": "Forecasting and mapping human thermal comfort in urban areas", "slug": "summer-in-the-city", "coordinator": ["/person/e.ranguelova"], "contactPerson": "/person/j.attema", "engineer": ["/person/j.attema"], "startDate": "2013-01-21", "dataMagnitude": "TB", "competence": ["Efficient Computing", "Optimized Data Handling"], "involvedOrganization": ["/organization/wur"], "name": "Summer in the City", "dataFormat": ["NetCDF", "GRIB", "CSV"], "title": "Summer In The City", "id": "/project/summer-in-the-city", "expertise": ["High Performance Computing", "Information Visualization", "Information Integration", "Handling Sensor Data"], "principalInvestigator": [{ "affiliation": ["/organization/wur"], "website": "http://www.wageningenur.nl/en/Persons/prof.dr.-AAM-Bert-Holtslag.htm", "name": "Prof. dr. Bert Holtslag" }], "@id": "http://software.esciencecenter.nl/project/summer-in-the-city/", "description": "<p>Forecasting and mapping human thermal comfort in urban areas.</p>\n", "discipline": ["Environment & Sustainability"], "infrastructure": "Supercomputer for perfoming weather forecasts", "endorsedBy": ["/organization/nlesc"], "publication": ["http://dx.doi.org/10.1109/eScience.2015.21"], "logo": "/images/project/summer-in-the-city.jpg", "nlescWebsite": "https://www.esciencecenter.nl/project/summer-in-the-city" }, { "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2015-03-20", "tagLine": "Facilitating and supporting large-scale text mining in the field of digital humanities", "slug": "texcavator", "dataFormat": ["XML"], "contactPerson": "/person/j.vanderzwaan", "engineer": ["/person/j.vanderzwaan"], "startDate": "2013-12-04", "dataMagnitude": "GB", "competence": ["Big Data Analytics"], "involvedOrganization": ["/organization/nlesc", "/organization/uva", "/organization/uu", "/organization/surfsara"], "name": "Texcavator", "title": "Texcavator", "id": "/project/texcavator", "uses": ["/software/texcavator", "/software/xtas"], "expertise": ["Information Retrieval", "Text Mining", "Distributed Computing", "Information Visualization"], "principalInvestigator": [{ "affiliation": ["/organization/uu"], "website": "http://www.uu.nl/medewerkers/JvanEijnatten/", "name": "Prof. Joris van Eijnatten" }, { "affiliation": ["/organization/uu"], "website": "http://www.uu.nl/staff/AHLMPieters/", "name": "Prof. Toine Pieters" }, { "affiliation": ["/organization/uu"], "website": "http://www.uu.nl/staff/JVerheul/", "name": "Dr. Jaap Verheul" }], "@id": "http://software.esciencecenter.nl/project/texcavator/", "description": "<p>Texcavator is a text mining application used for historical research. It is an\ninterface to an Elasticsearch index (specifically, an ES index containing the\nKB newspaper archive from 1850 - 1990) that allows users to perform full text\nsearches and to visualize the results (in word clouds and/or time lines).\nTexcavator was build on top of previous applications (WAHSP and Biland).\nThe goals of this project were:</p>\n\n<ol>\n  <li>Improvement of the overall stability and maintainability of the software</li>\n  <li>Analysis and improvement of scalability</li>\n</ol>\n\n<p>Most time was spend on refactoring the back end. The quality of the original\nTexcavator software was very low; it was clearly organically grown (instead of\nengineered) and documentation and unit tests were lacking.</p>\n\n<p>One of the main problems was scalability of word cloud generation.\nIn the old version of Texcavator, this could take hours (even though the\nmaximum number of documents was limited to 10000 documents) and often failed\nwithout giving an error message.\nWe wanted to use standard Elasticsearch functionality to generate the word\nclouds (i.e., terms aggregations). However, this proved to be infeasible,\nbecause of the large amount of words in the data set (the number of unique\nwords in the corpus is too big (mostly due to OCR mistakes) to keep in memory,\nwhich is required to be able to use terms aggregations). We came up with two\nalternative approaches: term vector word clouds and tag word clouds and\nimplemented the term vector word clouds. Word cloud generation is now faster\n(minutes instead of hours).</p>\n\n<p>After the test version of Texcavator was put online, a user session was\norganized to test the performance of Texcavator when multiple users use the\napplication at the same time and to identify other problems with the\napplication. The session was a success in the sense that multiple users\n(~10) were able to use the application at the same time without noticable\neffects on performance (Texcavator remained responsive).</p>\n", "discipline": ["Humanities & Social Sciences"], "infrastructure": "Elasticsearch for indexing and searching newspaper data", "endorsedBy": ["/organization/nlesc"], "logo": "/images/project/texcavator.jpg", "nlescWebsite": "https://www.esciencecenter.nl/project/texcavator" }, { "schema": "http://software.esciencecenter.nl/schema/project", "tagLine": "Towards Large-Scale Cloud-Resolving Climate Simulations: A new 3d-super-parameterization approach", "slug": "towards-large-scale-cloud-resolving-climate-simulations", "dataFormat": ["NetCDF", "Grib", "HDF5", "CSV"], "contactPerson": "/person/g.vandenoord", "engineer": ["http://software.esciencecenter.nl/person/g.vandenoord"], "dataMagnitude": "GB", "title": "Towards Large Scale Cloud Resolving Climate Simulations", "infrastructure": "Supercomputer", "competence": ["Big Data Analytics", "Efficient Computing"], "coordinator": "http://software.esciencecenter.nl/person/r.bakhshi", "nlescWebsite": "https://www.esciencecenter.nl/project/primavera", "name": "Towards Large-Scale Cloud-Resolving Climate Simulations", "uses": null, "expertise": ["Data Assimilation", "Scientific Visualization", "Distributed Computing", "High Performance Computing"], "principalInvestigator": [{ "affiliation": ["http://software.esciencecenter.nl/organization/cwi", "http://software.esciencecenter.nl/organization/uva"], "photo": "https://www.esciencecenter.nl/img/team/Daan-Crommelin-eScience.jpg", "website": "http://homepages.cwi.nl/~dtc/", "name": "Prof. Daan Crommelin", "description": "Prof. Daan Crommelin is leader of the Scientific Computing research group at CWI Amsterdam, and professor at the KdV Institute for Mathematics, University of Amsterdam. His research interests include stochastic and computational methods for multiscale dynamical systems, rare event simulation, applications in atmosphere\u2010ocean-climate science and energy networks." }], "@id": "http://software.esciencecenter.nl/project/towards-large-scale-cloud-resolving-climate-simulations/", "description": "<p>Clouds and convection processes are important for the climate system, yet they are not explicitly resolved in global climate models due to computational limitations. The approximate parameterized representation of these processes is the main source of model uncertainty in climate models and has hampered progress in our understanding of the interaction between clouds and the large-scale circulation for decades.</p>\n\n<p>We will pursue a new 3d-super-parameterization (3d-SP) approach to overcome this conundrum. This approach builds further on super-parameterization (SP) approach, proposed 15 years ago. We will nest 3-dimensional Large Eddy Simulation (LES) models into the grid columns of a Global Circulation Model.</p>\n\n<p>This way, the parameterized descriptions of clouds, convection and turbulence with all their shortcomings will be replaced by a realistic 3-dimensional simulation technique for these processes.</p>\n\n<p>Although computationally more expensive than traditional parameterizations and conventional super-parameterization, this approach is ideally suited to take full advantage of present-day parallel computers because of the minimal communication between the LES models and will be much more efficient than a direct simulation on the large scale at the resolution of the nested LES model.</p>\n\n<p>This project team will use state-of-the-art high performance computing (HPC) technologies to make this approach feasible and within reach of modern supercomputers. Furthermore, the team plans to employ recently developed algorithmic approaches to further speed up computations.</p>\n\n<p>The overarching goal is to develop and explore a computational tool that is able to realistically resolve the interaction between the large-scale atmospheric circulation and the smaller scale cloud and convective processes.</p>\n\n<p>Image source: <a href=\"http://eol.jsc.nasa.gov/SearchPhotos/photo.pl?mission=ISS016&amp;roll=E&amp;frame=27426\">Perhaps the most impressive of cloud formations, cumulonimbus (from the Latin for \u201cpile\u201d and \u201crain cloud\u201d) clouds form due to vigorous convection (rising and overturning) of warm, moist, and unstable air \u2013 by NASA</a></p>\n", "involvedOrganization": ["http://software.esciencecenter.nl/organization/nlesc", "http://software.esciencecenter.nl/organization/cwi", "http://software.esciencecenter.nl/organization/knmi"], "id": "/project/towards-large-scale-cloud-resolving-climate-simulations", "website": null, "logo": "https://www.esciencecenter.nl/img/projects/p56-large.jpg", "discipline": ["Environment & Sustainability"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2015-09-01", "tagLine": "Analysis of social media messages", "slug": "twinl", "dataFormat": ["CSV", "JSON"], "contactPerson": "/person/e.tjongkimsang", "engineer": ["/person/e.tjongkimsang"], "startDate": "2013-02-01", "dataMagnitude": "TB", "competence": ["Big Data Analytics"], "involvedOrganization": ["/organization/nlesc", "/organization/radboud.university.nijmegen", "/organization/surfsara"], "name": "TwiNL", "title": "Twinl", "id": "/project/twinl", "uses": ["/software/twiqs.nl"], "expertise": ["Text Mining", "Information Retrieval"], "principalInvestigator": [{ "affiliation": ["/organization/radboud.university.nijmegen"], "website": "http://antalvandenbosch.ruhosting.nl/", "name": "Prof. Antal van den Bosch" }], "@id": "http://software.esciencecenter.nl/project/twinl/", "description": "<p>Developing a centralized service for gathering, storing, and analyzing Twitter messages</p>\n", "discipline": ["Humanities & Social Sciences"], "infrastructure": "Cloud for data ingestion and retrieval, Hadoop for indexing and searching", "endorsedBy": ["/organization/nlesc"], "logo": "/images/project/twinl.jpg", "nlescWebsite": "https://www.esciencecenter.nl/project/twinl" }, { "schema": "http://software.esciencecenter.nl/schema/project", "endDate": "2015-04-30", "tagLine": "Developing a 4D geographic information system for archaeological purposes", "slug": "viaappia-patty", "dataFormat": ["Octree"], "contactPerson": "/person/o.rubi", "engineer": ["/person/o.rubi", "/person/m.vanmeersbergen", "/person/s.verhoeven", "/person/n.drost", "/person/j.attema", "/person/r.vannieuwpoort"], "startDate": "2013-10-01", "dataMagnitude": "GB", "nlescWebsite": "https://www.esciencecenter.nl/project/mapping-the-via-appia-in-3d", "name": "Mapping the Via Appia in 3D", "title": "Viaappia Patty", "competence": ["Optimized Data Handling", "Big Data Analytics"], "uses": ["/software/pattyvis", "/software/pattydata", "/software/pattyanalytics", "/software/sfm", "/software/potree", "/software/xenon", "/software/potreeconverter", "/software/python-pcl"], "expertise": ["Databases", "Handling Sensor Data", "Scientific Visualization"], "principalInvestigator": [{ "affiliation": ["/organization/vua"], "website": "http://www.feweb.vu.nl/gis/organisation/staff2.asp?id=72", "name": "MA, Maurice de Kleijn" }], "@id": "http://software.esciencecenter.nl/project/viaappia-patty/", "description": "<p>The \u201cMapping the Via Appia\u201d project aims at a thorough inventory and analysis of the Roman interventions in this suburban landscape. The research focuses on a section of two kilometers that covers parts of the fifth and sixth miles of the Via Appia, supplemented with a research area that covers the hinterland as far as nearly one kilometer northeast and about 2.5 kilometers southwest of the road. Based on the physical remains in combination with historical sources, archaeologists aim to reconstruct the functioning of the road in antiquity. The study area contains more than 2000 archaeological objects directly alongside the road. The biggest difficulty for the archaeologists is that the archaeological remains are scattered alongside the road and often not in situ.</p>\n\n<p>In trying to interpret the \u201clife\u201d of these remains, the researchers document all the archaeological objects in the field in high detail; decorations, traces of erosion, cuts and location are considered to form key elements. However, in order to query this dataset systematically and to develop 3D reconstructions, the researchers need a 3D Geographic Information System. Being able to virtually explore the area in a 3D landscape and highlight attributive information given in the field provides tooling which aids the archaeologists to reconstruct the road. Show for example all objects that contain a specific type of marble and have a certain type of architectural feature dating to a specific period allows archaeologists to reconstruct the objects and their relationship to past landscapes. However, a 3D Information System in which highly detailed features can be stored, spatially analyzed, and integrated with conventional geospatial information has, due to the lack of computational power, not yet been produced for a complex research area.</p>\n\n<p>Being able to virtually explore the area in a 3D landscape and highlight attributive information given in the field provides tooling which aids the archaeologists to reconstruct the road.</p>\n\n<p>The Mapping the Via Appia project gives the opportunity to develop a 4D (3D + time) Geographic Information System for archaeological purposes. The use of a 4D GIS in archaeology is not yet widespread. 4D GIS in general is still very much in development, challenging this project to be progressive and innovative. The project aims to develop a highly detailed 4D GIS enabling archaeologists to analyze complex archaeological sites and landscapes.\nresults.</p>\n", "discipline": ["Humanities & Social Sciences"], "involvedOrganization": ["/organization/nlesc", "/organization/vua", "/organization/fugro", "/organization/radboud.university.nijmegen", "/organization/university.of.groningen", "/organization/spinlab", "/organization/knir", "/organization/potree"], "id": "/project/viaappia-patty", "publication": ["http://dx.doi.org/10.1016/j.daach.2016.03.001", "http://dx.doi.org/10.1080/17538947.2016.1205673"], "logo": "/images/project/viaappia-patty.jpg", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "startDate": "2014-12-18", "tagLine": "Strengthening the methodology of digital humanities", "slug": "visualizing-uncertainty-and-perspectives", "dataFormat": ["XML", "JSON"], "contactPerson": "/person/m.vanmeersbergen", "engineer": ["/person/m.vanmeersbergen", "/person/j.vanderzwaan"], "title": "Visualizing Uncertainty And Perspectives", "dataMagnitude": "MB", "nlescWebsite": "https://www.esciencecenter.nl/project/visualizing-uncertainty-and-perspectives", "name": "Visualizing Uncertainty and Perspectives", "competence": ["Big Data Analytics"], "uses": ["/software/storyteller", "/software/heem-dataset"], "expertise": ["Information Visualization", "Text Mining"], "principalInvestigator": [{ "affiliation": ["/organization/vua"], "website": "http://vossen.info/", "name": "Prof. Piek Vossen" }], "@id": "http://software.esciencecenter.nl/project/visualizing-uncertainty-and-perspectives/", "description": "<p>Subjectivity and uncertainty form an integral part of Humanities research, sometimes even of the research object. Topics include subjectivity of authors (this chronicle\u2019s writer is pro Burgundian), the nature of data (this chronicle likely mentions battles, but unlikely mentions raping and pillaging) and the time in which the data was created (\u2018a lot of people\u2019 usually is summarised as \u201c10.000 people\u201d in the late Middle-Ages). Text dominantly reflects interpersonal and subjective points of view rather than objective facts. In addition, language is often imprecise or underspecified resulting in another level of subjectivity (for example spatial information is not well captured in language and perceptual values are expressed through scalar and relative words). Even humanities scholars aiming to be objective generally bring their own perspective and view of the past, a text tradition or painting.</p>\n\n<p>This project develops a tool that visualizes subjectivity, perspective and uncertainty to make them controllable variables. The tool allows users to compare information from different sources representing alternative perspectives and visualize subjectivity and uncertainty. Such a visualization enables improved and comprehensive source criticism, provides new directions of research and strengthens the methodology of digital humanities.</p>\n", "discipline": ["Humanities & Social Sciences"], "involvedOrganization": ["/organization/nlesc", "/organization/vua"], "id": "/project/visualizing-uncertainty-and-perspectives", "logo": "/images/project/visualizing-uncertainty-and-perspectives.jpg", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/project", "title": "What Works When For Whom", "tagLine": "Advancing therapy change process research", "slug": "what-works-when-for-whom", "dataFormat": ["XML", "JSON"], "contactPerson": "/person/j.vanderzwaan", "description": "<p>Mental illnesses, like depression and anxiety, are among the leading causes of the global burden of disease. E-mental health (EMH) interventions, such as web-based psychotherapy treatments, are increasingly used to improve access to psychotherapy for a wider audience. Whereas different EMH interventions tend to be equally effective, the responsiveness to a specific treatment shows large individual differences. The personalization of treatments is seen as the major road for improvement.</p>\n\n<p>Because most EMH interventions use language for communication between counselors and clients, assessing language use provides an important avenue for opening the black box of what happens within therapy. EMH also makes data of the linguistic interactions between client and counselor available on an unprecedented large scale. The objective of this interdisciplinary project is to use eScience methods and tools, in particular natural language processing, visualization and multivariate analysis methods, to analyze patterns in therapy-related textual features in e-mail correspondence between counselor and client.</p>\n", "expertise": ["Text Mining", "Information Visualization"], "id": "/project/what-works-when-for-whom", "engineer": ["/person/j.vanderzwaan"], "principalInvestigator": [{ "affiliation": ["/organization/utwente"], "website": "https://www.utwente.nl/bms/pgt/en/emp/sools/", "name": "Dr. Anneke Sools" }], "nlescWebsite": "https://www.esciencecenter.nl/project/what-works-when-for-whom", "@id": "http://software.esciencecenter.nl/project/what-works-when-for-whom/", "dataMagnitude": "MB", "competence": ["Big Data Analytics"], "logo": "/images/project/what-works-when-for-whom.jpg", "involvedOrganization": ["/organization/nlesc", "/organization/utwente"], "endorsedBy": ["/organization/nlesc"], "name": "What Works When for Whom?", "startDate": "2016-06-01", "discipline": ["Life Sciences & eHealth"] }], "report": [{ "schema": "http://software.esciencecenter.nl/schema/report", "title": "Data-Stewardship in the Big Data Era", "author": ["/organization/nlesc"], "description": "<p>The purpose of this document is to propose a series of actions to NWO as it formulates its policies on\ndata-stewardship.</p>\n", "@id": "http://software.esciencecenter.nl/report/data-stewardship/", "cover": "/assets/report/covers/data-stewardship.png", "date": "2013-01-01T00:00:00+00:00", "slug": "data-stewardship", "link": "/assets/report/content/DataStewardship_Final.pdf", "id": "/report/data-stewardship" }, { "schema": "http://software.esciencecenter.nl/schema/report", "title": "Modern Data Management Solutions", "author": [{ "name": "Milena Ivanova" }], "description": "<p>This document comprises a short overview of modern data management technology.</p>\n", "@id": "http://software.esciencecenter.nl/report/modern-data-management/", "cover": "/assets/report/covers/Modern_Data_Management-cover.png", "date": "2014-07-08T00:00:00+00:00", "slug": "modern-data-management", "link": "/assets/report/content/Modern_Data_Management.pdf", "id": "/report/modern-data-management" }, { "schema": "http://software.esciencecenter.nl/schema/report", "title": "Large Scale Computer Vision", "author": ["/person/e.ranguelova"], "description": "<p>The goal of this document is to present a focused partial overview of the state of the art in large\nscale computer vision (CV).</p>\n", "@id": "http://software.esciencecenter.nl/report/large-scale-computer-vision/", "cover": "/assets/report/covers/LargeScaleComputerVision-cover.png", "date": "2015-08-12T00:00:00+00:00", "slug": "large-scale-computer-vision", "link": "/assets/report/content/LargeScaleComputerVision.pdf", "id": "/report/large-scale-computer-vision" }, { "schema": "http://software.esciencecenter.nl/schema/report", "title": "Point cloud data management systems - DBMS and file-based solutions", "author": [{ "name": "Oscar Martinez-Rubi" }], "description": "<p>This document serves as usage guides for the available point cloud data management systems, including (i) DataBase Management Systems (DBMS) such as PostgreSQL, Oracle and MonetDB and (ii) file-based solutions such as LAStools.</p>\n", "@id": "http://software.esciencecenter.nl/report/pcdms_usage_guide/", "cover": "/assets/report/covers/pcdms_usage_guide.png", "date": "2015-10-28T00:00:00+00:00", "slug": "pcdms_usage_guide", "link": "/assets/report/content/pcdms_usage_guide.pdf", "id": "/report/pcdms_usage_guide" }, { "schema": "http://software.esciencecenter.nl/schema/report", "title": "Tutorial - Distributed Computing with Xenon", "author": ["/person/j.spaaks"], "description": "<p>This document aims to help users without much prior knowledge about Java programming and without much experience in using remote systems to understand the basics of how to use the Xenon library.</p>\n", "@id": "http://software.esciencecenter.nl/report/xenon-tutorial/", "cover": "/assets/report/covers/xenon-tutorial-cover.png", "date": "2016-02-01T00:00:00+00:00", "slug": "xenon-tutorial", "link": "/assets/report/content/xenon-tutorial.pdf", "id": "/report/xenon-tutorial" }, { "schema": "http://software.esciencecenter.nl/schema/report", "title": "Research Software at the Heart of Discovery", "author": ["/organization/nlesc", "/organization/dans"], "description": "<p>This document sets out the need for increased attention to academic software-sustainability and\nresearch software practice in general.</p>\n", "@id": "http://software.esciencecenter.nl/report/software-sustainability/", "cover": "/assets/report/covers/software-sustainability.png", "date": "2016-02-16T00:00:00+00:00", "slug": "software-sustainability", "link": "/assets/report/content/Software_Sustainability_DANS_NLeSC_2016.pdf", "id": "/report/software-sustainability" }, { "schema": "http://software.esciencecenter.nl/schema/report", "title": "CERN ROOT conda recipes", "author": ["/person/d.remenska"], "description": "<p>Conda recipes for building CERN ROOT binaries (with Python support) and its dependencies, to provide \u201cpythonic\u201d interface to the ROOT I/O format. It is an outcome of a pathfinder project is a collaboration between the XENON dark matter experiment and the Netherlands eScience center.</p>\n", "@id": "http://software.esciencecenter.nl/report/rootcondarecipes/", "cover": "/assets/report/covers/root-conda-cover.png", "date": "2016-03-01T00:00:00+00:00", "slug": "rootcondarecipes", "link": "https://nlesc.gitbooks.io/cern-root-conda-recipes/content/", "id": "/report/rootcondarecipes" }, { "schema": "http://software.esciencecenter.nl/schema/report", "title": "Summer in the City", "author": ["/person/j.attema"], "description": "<p>This document forms the technical documentation for the Summer in the City project (ESOCCS12.013). The project is a collaboration between Wageningen University and the Netherlands eScience center. The project ran from 2013 to 2016.</p>\n", "@id": "http://software.esciencecenter.nl/report/summerinthecity/", "cover": "/assets/report/covers/summerinthecity-cover.png", "date": "2016-03-01T00:00:00+00:00", "slug": "summerinthecity", "link": "https://nlesc.gitbooks.io/summerinthecity/content/", "id": "/report/summerinthecity" }, { "schema": "http://software.esciencecenter.nl/schema/report", "title": "Wood Image Classification - Initial Results", "author": ["/person/e.ranguelova"], "description": "<p>This report gives some initial findings on how to automatically classify microscopy images of sections of wood species, given a set of annotated or labelled examples.</p>\n", "@id": "http://software.esciencecenter.nl/report/wood-image-classification/", "cover": "/assets/report/covers/WoodImageClassificationInitialResults-cover.png", "date": "2016-05-26T00:00:00+00:00", "slug": "wood-image-classification", "link": "/assets/report/content/WoodImageClassificationInitialResults.pdf", "id": "/report/wood-image-classification" }, { "schema": "http://software.esciencecenter.nl/schema/report", "title": "NLeSC Guide", "author": ["/organization/nlesc"], "description": "<p>A guide to projects and software developent at the Netherlands eScience Center. It both serves as a source of information for exactly how we work at NLeSC, and as a basis for discussions and reaching consensus on this topic.\nThis guide is a work in progress.</p>\n", "@id": "http://software.esciencecenter.nl/report/guide/", "cover": "/assets/report/covers/guide-cover.png", "date": "2016-08-29T00:00:00+00:00", "slug": "guide", "link": "https://nlesc.gitbooks.io/guide/content/", "id": "/report/guide" }, { "schema": "http://software.esciencecenter.nl/schema/report", "title": "Tie-points reduction tools in MicMac - Description and experiments", "author": [{ "name": "Oscar Martinez-Rubi" }], "description": "<p>This report describes the tools for tie-points reduction implemented within MicMac.\nThis work has been carried out during the project Improving Open-Source Photogrammetric Workflows for Processing Big Datasets\nThe report contains a description of the algorithms as well as the definition and execution of a set of experiments to assess the new tools.</p>\n", "@id": "http://software.esciencecenter.nl/report/report-tie-points/", "cover": "/assets/report/covers/report-tie-points.png", "date": "2016-10-18T00:00:00+00:00", "slug": "report-tie-points", "link": "/assets/report/content/report-tie-points.pdf", "id": "/report/report-tie-points" }], "organization": [{ "schema": "http://software.esciencecenter.nl/schema/organization", "tagLine": "Netherlands Institute for Radio Astronomy", "slug": "astron", "@id": "http://software.esciencecenter.nl/organization/astron/", "userOf": ["/software/casacore"], "title": "Astron", "description": "<p>ASTRON is the Netherlands Institute for Radio Astronomy. Its mission\nis to make discoveries in radio astronomy happen, via the development\nof novel and innovative technologies, the operation of world-class\nradio astronomy facilities, and the pursuit of fundamental\nastronomical research.</p>\n", "logo": "/images/organization/astron.gif", "involvedIn": ["/project/beyond-the-data-explosion", "/project/error-detection-and-error-localization", "/project/aa-alert"], "ownerOf": ["/software/casacore"], "website": "http://www.astron.nl/", "name": "ASTRON", "id": "/organization/astron" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Cbs Knaw", "tagLine": "An institute of the Royal Netherlands Academy of Arts and Sciences", "description": "<p>The Fungal Biodiversity Centre (CBS) is an independent research institute of the Royal Netherlands Academy of Arts and Sciences, situated on the campus of the largest university in the Netherlands (Utrecht). It studies fungal biodiversity in the widest sense, focusing on three priority areas, agriculture, human health, and industry (indoor air and food). Presently there are 6 research groups with a total of about 80 employees. The institute maintains a large culture collection of fungi and yeasts, and research groups such as those of Pedro Crous (Evolutionary Phytopathology), Robert Samson (Applied and Industrial Mycology), Sybren de Hoog (Origins of Pathogenicity in Clinical Fungi), Teun Boekhout (Yeast and Basidiomycete Research), Ronald de Vries (Fungal Physiology) and Vincent Robert (Bioinformatics).</p>\n", "@id": "http://software.esciencecenter.nl/organization/cbs-knaw/", "involvedIn": ["/project/massive-biological-data-clustering-reporting-and-visualization-tools"], "slug": "cbs-knaw", "name": "CBS-KNAW Fungal Biodiversity Centre", "website": "http://www.cbs.knaw.nl/", "logo": "/images/organization/cbs-knaw.png", "id": "/organization/cbs-knaw" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Commit", "tagLine": "COMMIT A Public-private ICT research community", "description": "<p>COMMIT</p>\n", "@id": "http://software.esciencecenter.nl/organization/commit/", "involvedIn": ["/project/3d-geospatial-data-exploration-for-modern-risk-management-systems"], "slug": "commit", "name": "COMMIT", "website": "http://www.commit-nl.nl/", "logo": "/images/organization/commit.png", "id": "/organization/commit" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Cwi", "tagLine": "Centrum Wiskunde & Informatica", "description": "<p>CWI is the national research institute for mathematics and computer science in the Netherlands and is an institute of the Netherlands Organisation for Scientific Research (NWO). The institute was founded in 1946 and is located at Amsterdam Science Park.</p>\n", "@id": "http://software.esciencecenter.nl/organization/cwi/", "involvedIn": ["/project/generic-escience-technologies", "/project/3d-geospatial-data-exploration-for-modern-risk-management-systems", "/project/big-data-analytics-in-the-geo-spatial-domain", "/project/massive-point-clouds-for-esciences", "/project/compressing-the-sky-into-a-large-collection-of-statistical-models", "/project/towards-large-scale-cloud-resolving-climate-simulations"], "slug": "cwi", "name": "CWI", "website": "http://www.cwi.nl/", "logo": "/images/organization/cwi.png", "id": "/organization/cwi" }, { "linkedInUrl": "https://www.linkedin.com/company/dans", "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Dans", "authorOfReport": ["/report/software-sustainability"], "slug": "dans", "@id": "http://software.esciencecenter.nl/organization/dans/", "description": "<p>DANS bevordert duurzame toegang tot digitale onderzoeksgegevens en stimuleert dat onderzoekers gegevens duurzaam archiveren en hergebruiken.</p>\n", "name": "Data Archiving and Networked Services (DANS)", "website": "http://www.dans.knaw.nl", "logo": "/images/organization/dans.jpg", "id": "/organization/dans" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Deltares", "tagLine": "Deltares", "description": "<p>Deltaris is an independent applied research institure in the field of water and soil, globally working on smart innovations, solution and applications for people, environment and society.</p>\n", "@id": "http://software.esciencecenter.nl/organization/deltares/", "involvedIn": ["/project/3d-geospatial-data-exploration-for-modern-risk-management-systems", "/project/large-scale-data-assimilation"], "slug": "deltares", "name": "Deltares", "website": "http://www.deltares.nl", "logo": "/images/organization/deltares.jpe", "id": "/organization/deltares" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Dtl", "description": "<p>DTL is a nationwide platform formed by an increasing number of life science partner institutions and companies in the Netherlands. The overall aim of DTL is to coordinate super-institutional approaches to enable integrated life sciences research through the combined deployment of different analytical techniques and/or parallel analyses, including computational approaches, on the various molecular and structural organisational levels in cells, tissues and organisms.</p>\n", "@id": "http://software.esciencecenter.nl/organization/dtl/", "involvedIn": ["/project/odex4all"], "slug": "dtl", "name": "Dutch Techcenter for Life Sciences (DTL)", "website": "http://www.dtls.nl", "logo": "/images/organization/dtl.png", "id": "/organization/dtl" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Ecmwf", "slug": "ecmwf", "@id": "http://software.esciencecenter.nl/organization/ecmwf/", "description": "\n", "name": "ECMWF", "id": "/organization/ecmwf" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Fugro", "tagLine": "Fugro Nederland", "description": "<p>Fugro</p>\n", "@id": "http://software.esciencecenter.nl/organization/fugro/", "involvedIn": ["/project/3d-geospatial-data-exploration-for-modern-risk-management-systems", "/project/big-data-analytics-in-the-geo-spatial-domain", "/project/massive-point-clouds-for-esciences", "/project/viaappia-patty"], "slug": "fugro", "name": "Fugro", "website": "http://www.fugro.nl/", "logo": "/images/organization/fugro.png", "id": "/organization/fugro" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Geodan", "tagLine": "Geodan", "description": "<p>Geodan</p>\n", "@id": "http://software.esciencecenter.nl/organization/geodan/", "involvedIn": ["/project/3d-geospatial-data-exploration-for-modern-risk-management-systems", "/project/big-data-analytics-in-the-geo-spatial-domain"], "slug": "geodan", "name": "Geodan", "website": "http://www.geodan.com", "logo": "/images/organization/geodan.gif", "id": "/organization/geodan" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Huygens", "tagLine": "Unraveling history with new technology", "description": "<p>A democratic society like the Netherlands needs right-minded, actively engaged citizens who have a good sense of their own identity and are able to make responsible decisions. However, it is difficult to get citizens involved in their society if they have no idea of how it came into being, and no understanding of its workings. Cultural participation and solid, up-to-date education in history, language and cultural subjects are of crucial importance in this context. And the foundations of these matters are laid by high-quality humanities research. As the Netherlands\u2019 foremost humanities research institute, the Huygens Institute of Netherlands History (Huygens ING) plays a prominent role in this process.</p>\n", "@id": "http://software.esciencecenter.nl/organization/huygens/", "involvedIn": ["/project/beyond-the-book"], "slug": "huygens", "name": "Huygens ING", "website": "https://www.huygens.knaw.nl/", "logo": "/images/organization/huygens.png", "id": "/organization/huygens" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Icl", "description": "\n", "@id": "http://software.esciencecenter.nl/organization/icl/", "involvedIn": ["/project/idark"], "slug": "icl", "name": "Imperial College London", "website": "http://www.imperial.ac.uk", "logo": "/images/organization/icl.jpg", "id": "/organization/icl" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Ign", "description": "\n", "@id": "http://software.esciencecenter.nl/organization/ign/", "involvedIn": ["/project/improving-photogrammetry"], "slug": "ign", "ownerOf": ["/software/micmac"], "name": "Institut national de l\u2019information g\u00e9ographique et foresti\u00e8re", "website": "http://www.ign.fr/", "logo": "/images/organization/ign.jpg", "id": "/organization/ign" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Jhu", "tagLine": "Johns Hopkins University", "slug": "jhu", "logo": "/images/organization/jhu.png", "@id": "http://software.esciencecenter.nl/organization/jhu/", "description": "<p>JHU</p>\n", "website": "https://www.jhu.edu", "name": "JHU", "id": "/organization/jhu" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Knir", "tagLine": "Koninklijk Nederlands Instituut in Rome", "description": "<p>Koninklijk Nederlands Instituut in Rome</p>\n", "@id": "http://software.esciencecenter.nl/organization/knir/", "involvedIn": ["/project/hadrianus", "/project/viaappia-patty"], "slug": "knir", "name": "Koninklijk Nederlands Instituut in Rome", "website": "http://www.knir.it/", "logo": "/images/organization/knir.png", "id": "/organization/knir" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "tagLine": "Koninklijk Nederlands Meteorologisch Instituut", "slug": "knmi", "@id": "http://software.esciencecenter.nl/organization/knmi/", "description": "<p>The Royal Netherlands Meteorological Institute (KNMI) is the Dutch national weather service. Primary tasks of KNMI are weather forecasting, and monitoring of weather, climate, air quality and seismic activity. KNMI is also the national research and information centre for meteorology, climate, air quality, and seismology.</p>\n", "userOf": ["/software/openifs", "/software/cdo"], "title": "Knmi", "name": "Koninklijk Nederlands Meteorologisch Instituut", "involvedIn": ["/project/primavera", "/project/towards-large-scale-cloud-resolving-climate-simulations"], "website": "http://www.knmi.nl/", "logo": "/images/organization/knmi.png", "id": "/organization/knmi" }, { "linkedInUrl": "https://www.linkedin.com/company/leiden-university", "schema": "http://software.esciencecenter.nl/schema/organization", "twitterUrl": "https://twitter.com/UniLeidenNews", "tagLine": "Leiden University", "slug": "leiden-university", "@id": "http://software.esciencecenter.nl/organization/leiden-university/", "involvedIn": ["/project/amuse", "/project/abcmuse", "/project/neutrino"], "title": "Leiden University", "description": "<p>Leiden University was founded in 1575 and is one of Europe\u2019s leading international research universities. It has seven faculties in the arts, sciences and social sciences, spread over locations in Leiden and The Hague. The University has over 5,500 staff members and 25,800 students. The motto of the University is \u2018Praesidium Libertatis\u2019 - Bastion of Freedom.</p>\n", "logo": "/images/organization/leiden-university.png", "researchgateUrl": "https://www.researchgate.net/institution/Leiden_University", "ownerOf": ["/software/amuse"], "website": "https://www.universiteitleiden.nl/en/", "name": "Leiden University", "id": "/organization/leiden-university" }, { "linkedInUrl": "https://www.linkedin.com/company/lumc", "schema": "http://software.esciencecenter.nl/schema/organization", "slug": "lumc", "@id": "http://software.esciencecenter.nl/organization/lumc/", "description": "<p>LUMC is a modern university medical center for research, education and patient care with a high quality profile and a strong scientific orientation. Its unique research practice, ranging from pure fundamental medical research to applied clinical research, places LUMC among the world top. This enables LUMC to offer patient care and education that is in line with the latest international insights and standards \u2013 and helps it to improve medicine and healthcare both internally and externally.</p>\n", "userOf": ["/software/fairdatapoint"], "title": "Lumc", "name": "Leiden University Medical Center (LUMC)", "involvedIn": ["/project/odex4all"], "website": "https://www.lumc.nl/", "logo": "/images/organization/lumc.png", "id": "/organization/lumc" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Meertens", "description": "<p>The Meertens Institute, established in 1926, has been a research institute of the Royal Netherlands Academy of Arts and Sciences (KNAW) since 1952. We study the diversity in language and culture in the Netherlands.</p>\n", "@id": "http://software.esciencecenter.nl/organization/meertens/", "involvedIn": ["/project/from-sentiment-mining-to-mining-embodied-emotions"], "slug": "meertens", "name": "Meertens Institute", "website": "http://www.meertens.knaw.nl", "logo": "/images/organization/meertens.png", "id": "/organization/meertens" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Monetdb", "tagLine": "MonetDB Solutions", "description": "<p>MonetDB Solutions</p>\n", "@id": "http://software.esciencecenter.nl/organization/monetdb/", "involvedIn": ["/project/3d-geospatial-data-exploration-for-modern-risk-management-systems", "/project/big-data-analytics-in-the-geo-spatial-domain"], "slug": "monetdb", "name": "MonetDB Solutions", "website": "http://monetdbsolutions.com/", "logo": "/images/organization/monetdb.png", "id": "/organization/monetdb" }, { "linkedInUrl": "https://www.linkedin.com/company/nederlands-forensisch-instituut", "schema": "http://software.esciencecenter.nl/schema/organization", "twitterUrl": "https://twitter.com/nedforinst", "tagLine": "In feiten het beste", "slug": "nfi", "@id": "http://software.esciencecenter.nl/organization/nfi/", "userOf": ["/project/sherlock", "/software/metrochartjs", "/software/spiraljs", "/software/punchcardjs"], "title": "Nfi", "description": "<p>Het Nederlands Forensisch Instituut (NFI) bevordert het optimaal functioneren van de rechtshandhaving en rechtspleging vanuit een focus op natuurwetenschappelijke informatieposities.</p>\n\n<p>Het NFI is het oudste en breedst geori\u00ebnteerde forensisch onderzoeksinstituut van Nederland. Door continu te investeren in kennis en innovatie speelt het NFI in op actuele maatschappelijke, technologische en wetenschappelijke ontwikkelingen. Het NFI loopt hierin ook internationaal gezien voorop.</p>\n\n<p>Het NFI verleent diensten aan opdrachtgevers van binnen \u00e9n buiten de strafrechtsketen, zoals het Openbaar Ministerie (OM) en de politie. Ook kan een advocaat in een strafzaak de zaakofficier of de rechter-commissaris verzoeken om het NFI een onderzoek te laten uitvoeren. Het NFI levert daarnaast diensten aan andere personen of instanties, zoals het Joegoslavi\u00eb Tribunaal, de Immigratie- en Naturalisatiedienst, buitenlandse politie of justitie, of aan bijzondere opsporingsdiensten. NFI-deskundigen kunnen ook in civiele rechtszaken - al dan niet op verzoek van een advocaat - worden benoemd door de</p>\n", "logo": "/images/organization/nfi.gif", "involvedIn": ["/project/sherlock", "/project/a-jungle-computing-approach-to-large-scale-online-forensic-analysis"], "website": "http://www.nederlandsforensischinstituut.nl/", "name": "Nederlands Forensisch Instituut", "id": "/organization/nfi" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "tagLine": "National Institute for Subatomic Physics", "slug": "nikhef", "@id": "http://software.esciencecenter.nl/organization/nikhef/", "description": "<p>Nikhef is the National Institute for Subatomic Physics. Our research is aimed at particle and astroparticle physics.</p>\n", "userOf": ["/software/root-conda-recipes", "/software/root", "/software/pyroot", "/software/gaudi", "/software/mcatnlo", "/software/roofit", "/software/paxer"], "title": "Nikhef", "name": "NIKHEF", "involvedIn": ["/project/automated-parallel-calculation-of-collaborative-statistical-models", "/project/pandas-root", "/project/neutrino"], "website": "http://www.nikhef.nl/", "logo": "/images/organization/nikhef.jpg", "id": "/organization/nikhef" }, { "linkedInUrl": "https://www.linkedin.com/company/netherlands-escience-center", "schema": "http://software.esciencecenter.nl/schema/organization", "twitterUrl": "https://twitter.com/esciencecenter", "tagLine": "Netherlands eScience Center", "slug": "nlesc", "@id": "http://software.esciencecenter.nl/organization/nlesc/", "userOf": ["/software/harmony", "/software/openifs", "/software/dales", "/software/mcfly", "/software/ec-earth", "/software/cdo", "/software/autosubmit", "/software/oxfrei-dataset", "/software/casacore", "/software/xenon", "/software/kernel_tuner", "/software/metrochartjs", "/software/noodles", "/software/recipy", "/software/pattyvis", "/software/cptm", "/software/common-sense", "/software/xtas", "/software/rig", "/software/storyteller", "/software/mmsoda-toolbox-for-matlab", "/software/fairdatapoint", "/software/cclustera", "/software/salient-region-detectors", "/software/potree", "/software/potreeconverter", "/software/pattydata", "/software/pdal", "/software/massivepotreeconverter", "/software/micmac", "/software/ahn2webviewer", "/software/pattyanalytics", "/software/sfm", "/software/magnesium", "/software/python-pcl", "/software/amuse", "/software/topic-coherence-for-dutch", "/software/heem-dataset", "/software/differential-evolution", "/software/liblas", "/software/docker-couch-admin", "/software/spiraljs", "/software/punchcardjs"], "organizationOf": ["/person/s.verhoeven", "/person/j.maassen", "/person/n.drost", "/person/r.vannieuwpoort", "/person/j.hidding", "/person/b.weel", "/person/j.borgdorff", "/person/a.kuzniar", "/person/j.vanderzwaan", "/person/o.rubi"], "researchgateUrl": "https://www.researchgate.net/institution/Netherlands_eScience_Center", "title": "Nlesc", "authorOfReport": ["/report/guide", "/report/software-sustainability", "/report/data-stewardship"], "description": "<p>Historically, scientific domains were defined by their own unique tools (microscopes, telescopes, distillation glass). Nowadays, the most important tool in all scientific disciplines is the computer. In this digital era, eScience is the developing discipline that provides the domain overarching software instruments (software, workflows and protocols) to support diverse scientific initiatives - making possible the creation of new, even unforeseen, applications - with the potential to transform current scientific practice, optimize scientific investments and significantly accelerate scientific discovery. eScience has the potential to underpin all scientific endeavor in the same way that applied mathematics currently does.</p>\n\n<p>The Netherlands eScience Center (NLeSC) is tasked with coordinating a collaborative scientific program, working with both academia and industry, to conduct funded projects fostering the development of overarching tools for the benefit of a broad scientific community. The success of NLeSC will be measurable by the growing adoption of eScience tools as a fundamental approach within diverse research domains. Based on its multidisciplinary collaborations and technological advances, NLeSC aims to become recognized as one of the leading eScience expertise centers in the world.</p>\n", "logo": "/images/organization/nlesc.jpg", "involvedIn": ["/project/arena", "/project/primavera", "/project/beyond-the-data-explosion", "/project/computational-chemistry-made-easy", "/project/enhancing-protein-drug-binding-prediction", "/project/e-musc", "/project/simcity", "/project/biomarker", "/project/emetabolomics", "/project/towards-large-scale-cloud-resolving-climate-simulations", "/project/twinl", "/project/odex4all", "/project/candygene", "/project/dilipad", "/project/texcavator", "/project/from-sentiment-mining-to-mining-embodied-emotions", "/project/pandas-root", "/project/hadrianus", "/project/pidimehs", "/project/era-urban", "/project/automated-parallel-calculation-of-collaborative-statistical-models", "/project/visualizing-uncertainty-and-perspectives", "/project/sherlock", "/project/what-works-when-for-whom", "/project/eecology", "/project/esibayes", "/project/idark", "/project/viaappia-patty", "/project/improving-photogrammetry", "/project/error-detection-and-error-localization", "/project/aa-alert", "/project/generic-escience-technologies", "/project/ewatercycle", "/project/large-scale-data-assimilation", "/project/amuse", "/project/a-jungle-computing-approach-to-large-scale-online-forensic-analysis", "/project/3d-e-chem", "/project/dive-plus", "/project/drwatson", "/project/shico", "/project/beyond-the-book", "/project/neutrino", "/project/microscopy"], "ownerOf": ["/software/oxfrei-dataset", "/software/fairdatapoint", "/software/xenon", "/software/eastroviz", "/software/noodles", "/software/metrochartjs", "/software/cptm", "/software/recipy", "/software/eecology-annotation", "/software/osmium", "/software/xtas", "/software/eecology-tracker-calendar", "/software/rig", "/software/twiqs.nl", "/software/texcavator", "/software/pyxenon", "/software/magma", "/software/mcfly", "/software/extjs-datetime", "/software/storyteller", "/software/kernel_tuner", "/software/mmsoda-toolbox-for-matlab", "/software/cclustera", "/software/salient-region-detectors", "/software/massivepotreeconverter", "/software/ahn2webviewer", "/software/pattydata", "/software/pattyvis", "/software/pattyanalytics", "/software/sfm", "/software/magnesium", "/software/python-pcl", "/software/topic-coherence-for-dutch", "/software/heem-dataset", "/software/cesium-ncwms", "/software/ewaterleaf", "/software/differential-evolution", "/software/pidilib", "/software/3d-e-chem-vm", "/software/knime-archetype", "/software/knime-gpcrdb", "/software/knime-klifs", "/software/knime-molviewer", "/software/chemical-analytics-platform", "/software/pycoeman", "/software/pymicmac", "/software/docker-couch-admin", "/software/spiraljs", "/software/punchcardjs"], "website": "http://www.esciencecenter.nl/", "name": "Netherlands eScience Center", "id": "/organization/nlesc" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Ntu", "slug": "ntu", "logo": "/images/organization/ntu.gif", "@id": "http://software.esciencecenter.nl/organization/ntu/", "description": "<p>Young and research-intensive, Nanyang Technological University (NTU Singapore) is ranked 13th globally. It is also placed 1st amongst the world\u2019s best young universities.</p>\n\n<p>The university has colleges of Engineering, Business, Science, Humanities, Arts, &amp; Social Sciences, and an Interdisciplinary Graduate School. It also has a medical school, Lee Kong Chian School of Medicine, set up jointly with Imperial College London.</p>\n", "website": "http://www.ntu.edu.sg", "name": "Nanyang Technical University", "id": "/organization/ntu" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Oracle", "tagLine": "Oracle Corporation", "description": "<p>Oracle</p>\n", "@id": "http://software.esciencecenter.nl/organization/oracle/", "involvedIn": ["/project/massive-point-clouds-for-esciences"], "slug": "oracle", "name": "Oracle", "website": "https://www.oracle.com/database/index.html", "logo": "/images/organization/oracle.png", "id": "/organization/oracle" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "tagLine": "Potree", "slug": "potree", "@id": "http://software.esciencecenter.nl/organization/potree/", "description": "<p>Potree</p>\n", "title": "Potree", "logo": "/images/organization/potree.png", "involvedIn": ["/project/massive-point-clouds-for-esciences", "/project/viaappia-patty"], "ownerOf": ["/software/potree", "/software/potreeconverter"], "website": "http://potree.org", "name": "Potree", "id": "/organization/potree" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Radboud.university.nijmegen", "description": "<p>Radboud University is a broad, international oriented university that aspires to be one of the best in Europe. Together with Radboudumc, we have created an intellectual environment that inspires and challenges our students and staff so that  they can extend the scope of academic disciplines and benefit society.</p>\n", "@id": "http://software.esciencecenter.nl/organization/radboud.university.nijmegen/", "involvedIn": ["/software/twiqs.nl", "/project/twinl", "/project/idark", "/project/viaappia-patty", "/project/biomarker", "/project/3d-e-chem"], "slug": "radboud.university.nijmegen", "ownerOf": ["/software/twiqs.nl", "/software/3d-e-chem-vm", "/software/knime-archetype", "/software/chemical-analytics-platform", "/software/knime-gpcrdb", "/software/knime-klifs", "/software/knime-molviewer"], "name": "Radboud University Nijmegen", "website": "http://www.ru.nl/", "logo": "/images/organization/radboud.university.nijmegen.png", "id": "/organization/radboud.university.nijmegen" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Rijkswaterstaat", "tagLine": "Rijkswaterstaat", "description": "<p>Rijkswaterstaat is responsible for the design, construction, management and maintenance of the main infrastructure facilities in the Netherlands. This includes the main road network, the main waterway network and watersystems.</p>\n", "@id": "http://software.esciencecenter.nl/organization/rijkswaterstaat/", "involvedIn": ["/project/massive-point-clouds-for-esciences"], "slug": "rijkswaterstaat", "name": "Rijkswaterstaat", "website": "http://www.rijkswaterstaat.nl/", "logo": "/images/organization/rijkswaterstaat.png", "id": "/organization/rijkswaterstaat" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Spinlab", "description": "<p>The Spatial Information Laboratory (SPINlab) is the centre for research and education in Geo-Information Science at VU University Amsterdam.</p>\n\n<p>The mission of the SPINLab is to develop an internationally recognised research and education portfolio in the areas of Geo-Information Science and Technology. The lab is part of the Department of Spatial Economics and is chaired by Prof.dr. Henk J. Scholten.</p>\n", "@id": "http://software.esciencecenter.nl/organization/spinlab/", "involvedIn": ["/project/viaappia-patty"], "slug": "spinlab", "name": "SPINlab", "website": "https://spinlab.vu.nl", "logo": "/images/organization/spinlab.jpg", "id": "/organization/spinlab" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Surfsara", "description": "<p>SURFsara creates a bridge between research and advanced ICT. We do so with a passion for scientific research in our DNA and with extensive expertise contained in our high-performance infrastructure. This enables us to facilitate scientific research and develop initiatives for the business community.</p>\n", "@id": "http://software.esciencecenter.nl/organization/surfsara/", "involvedIn": ["/project/twinl", "/software/twiqs.nl", "/project/texcavator", "/project/pidimehs", "/project/esibayes"], "slug": "surfsara", "ownerOf": ["/software/twiqs.nl", "/software/picas"], "name": "SURFsara", "website": "https://www.surf.nl/en/about-surf/subsidiaries/surfsara/", "logo": "/images/organization/surfsara.png", "id": "/organization/surfsara" }, { "linkedInUrl": "https://www.linkedin.com/company/tno", "schema": "http://software.esciencecenter.nl/schema/organization", "tagLine": "Nederlandse organisatie voor Toegepast-Natuurwetenschappelijk Onderzoek", "slug": "tno", "@id": "http://software.esciencecenter.nl/organization/tno/", "userOf": ["/software/common-sense"], "title": "Tno", "description": "\n", "logo": "/images/organization/tno.jpg", "researchgateUrl": "https://www.researchgate.net/institution/TNO", "ownerOf": ["/software/common-sense"], "website": "http://www.tno.nl/", "name": "TNO", "id": "/organization/tno" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Tu Delft", "description": "<p>TU Delft cooperates with many other educational and research institutions, both in the Netherlands and abroad. The high quality of our research and teaching is renowned. TU Delft has numerous contacts with governments, trade associations, consultancies, industry and small and medium-sized companies.</p>\n", "@id": "http://software.esciencecenter.nl/organization/tu-delft/", "involvedIn": ["/project/large-scale-data-assimilation", "/project/ewatercycle", "/project/microscopy", "/project/massive-point-clouds-for-esciences", "/project/big-data-analytics-in-the-geo-spatial-domain"], "slug": "tu-delft", "name": "Delft University of Technology", "website": "http://www.tudelft.nl", "logo": "/images/organization/tu-delft.png", "id": "/organization/tu-delft" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Tudelft", "slug": "tudelft", "logo": "http://www.tudelft.nl/fileadmin/Default/Templates/images/logo.gif", "@id": "http://software.esciencecenter.nl/organization/tudelft/", "description": "\n", "website": "http://tudelft.nl", "name": "Delft University of Technology", "id": "/organization/tudelft" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "tagLine": "University of Groningen", "slug": "university.of.groningen", "@id": "http://software.esciencecenter.nl/organization/university.of.groningen/", "description": "<p>University of Groningen.</p>\n", "userOf": ["/software/pidilib"], "title": "University.of.groningen", "name": "University of Groningen", "involvedIn": ["/project/pidimehs", "/project/viaappia-patty"], "website": "http://www.rug.nl/", "logo": "/images/organization/university.of.groningen.png", "id": "/organization/university.of.groningen" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "University.of.southampton", "description": "<p>The University of Southampton is a world-class university built on the quality and diversity of our community. Our staff place a high value on excellence and creativity, supporting independence of thought, and the freedom to challenge existing knowledge and beliefs through critical research and scholarship. Through our education and research we transform people\u2019s lives and change the world for the better.</p>\n", "@id": "http://software.esciencecenter.nl/organization/university.of.southampton/", "involvedIn": ["/software/recipy"], "slug": "university.of.southampton", "name": "University of Southampton", "website": "http://www.southampton.ac.uk/", "logo": "/images/organization/university.of.southampton.svg", "id": "/organization/university.of.southampton" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Upv", "description": "\n", "@id": "http://software.esciencecenter.nl/organization/upv/", "involvedIn": ["/project/idark"], "slug": "upv", "name": "Universitat Polit\u00e8cnica de Val\u00e8ncia", "website": "http://www.upv.es", "logo": "/images/organization/upv.png", "id": "/organization/upv" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "title": "Utwente", "description": "<p>The University of Twente is a modern, entrepreneurial university, leading in the area of new technologies and a catalyst for change, innovation and progress in society. Our strength lies in our capacity to combine. After all, the most interesting and relevant innovations take place at the cutting edge of technologies and their impact on humanity and societies.</p>\n", "@id": "http://software.esciencecenter.nl/organization/utwente/", "involvedIn": ["/project/what-works-when-for-whom", "/project/improving-photogrammetry"], "slug": "utwente", "name": "University of Twente", "website": "https://www.utwente.nl/", "logo": "/images/organization/utwente.png", "id": "/organization/utwente" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "slug": "uu", "@id": "http://software.esciencecenter.nl/organization/uu/", "description": "<p>Utrecht University is an international research university of the highest\nquality and the alma mater of many leading names, academics and scientists who\nhave made an important contribution to the quality of society.</p>\n", "userOf": ["/software/texcavator"], "title": "Uu", "name": "Utrecht University", "involvedIn": ["/project/texcavator", "/project/ewatercycle", "/project/abcmuse", "/project/shico"], "ownerOf": ["/software/texcavator"], "website": "http://www.uu.nl", "logo": "/images/organization/uu.svg", "id": "/organization/uu" }, { "schema": "http://software.esciencecenter.nl/schema/organization", "slug": "uva", "@id": "http://software.esciencecenter.nl/organization/uva/", "description": "<p>The UvA is a broad, research-intensive institution rooted in the history of Amsterdam, an internationally oriented academic community that can compete with leading universities in the Netherlands and around the world. The UvA provides academic training in all areas of science and scholarship, and welcomes students and staff - from all backgrounds, cultures and faiths - who wish to devote their talents to the development and transfer of academic knowledge as a rich cultural resource and foundation for sustainable progress.</p>\n", "userOf": ["/software/eecology-annotation", "/software/xtas", "/software/eecology-tracker-calendar", "/software/extjs-datetime"], "title": "Uva", "name": "University of Amsterdam", "involvedIn": ["/project/e-musc", "/project/generic-escience-technologies", "/project/simcity", "/project/hadrianus", "/project/pidimehs", "/project/dilipad", "/project/texcavator", "/project/eecology", "/project/esibayes", "/project/idark", "/project/arena"], "ownerOf": ["/software/eecology-annotation", "/software/cptm", "/software/xtas", "/software/eecology-tracker-calendar", "/software/texcavator", "/software/extjs-datetime", "/software/google-earth-toolbox-for-matlab", "/software/mmsoda-toolbox-for-matlab", "/software/topic-coherence-for-dutch"], "website": "http://www.uva.nl", "logo": "/images/organization/uva.jpg", "id": "/organization/uva" }, { "linkedInUrl": "https://www.linkedin.com/company/vrije-universiteit-amsterdam", "schema": "http://software.esciencecenter.nl/schema/organization", "twitterUrl": "https://twitter.com/vuamsterdam", "tagLine": "VU University Amsterdam", "slug": "vua", "@id": "http://software.esciencecenter.nl/organization/vua/", "userOf": ["/software/noodles"], "organizationOf": ["/software/heem-dataset"], "researchgateUrl": "https://www.researchgate.net/institution/VU_University_Amsterdam", "title": "Vua", "description": "\n", "logo": "/images/organization/vua.png", "involvedIn": ["/project/generic-escience-technologies", "/project/computational-chemistry-made-easy", "/project/enhancing-protein-drug-binding-prediction", "/project/from-sentiment-mining-to-mining-embodied-emotions", "/project/visualizing-uncertainty-and-perspectives", "/project/big-data-analytics-in-the-geo-spatial-domain", "/project/viaappia-patty", "/project/a-jungle-computing-approach-to-large-scale-online-forensic-analysis", "/project/3d-e-chem", "/project/dive-plus", "/project/drwatson"], "ownerOf": ["/software/heem-dataset", "/software/3d-e-chem-vm", "/software/knime-archetype", "/software/chemical-analytics-platform", "/software/knime-gpcrdb", "/software/knime-klifs", "/software/knime-molviewer"], "website": "http://www.vu.nl/", "name": "VU University Amsterdam", "id": "/organization/vua" }, { "linkedInUrl": "https://www.linkedin.com/edu/wageningen-university-15454", "schema": "http://software.esciencecenter.nl/schema/organization", "twitterUrl": "https://twitter.com/WageningenUR", "tagLine": "WUR provides education and generates knowledge in the domain of healthy food and living environment", "slug": "wur", "@id": "http://software.esciencecenter.nl/organization/wur/", "userOf": ["/software/netcdf2littler", "/software/wrfpy", "/software/fairdatapoint"], "researchgateUrl": "https://www.researchgate.net/institution/Wageningen_University", "title": "Wur", "description": "<p>WUR is a collaboration between Wageningen University and the DLO foundation. It\u2019s mission is \u2018to explore the potential of nature to improve the quality of life\u2019. A staff of 6,500 and 10,000 students from over 100 countries work everywhere around the world in the domain of healthy food and living environment for governments and the business community-at-large.</p>\n", "logo": "/images/organization/wur.jpg", "involvedIn": ["/project/summer-in-the-city", "/project/era-urban", "/project/emetabolomics", "/project/era-urban", "/project/summer-in-the-city", "/project/candygene", "/project/odex4all"], "ownerOf": ["/software/osmium", "/software/magma"], "website": "http://www.wageningenur.nl/", "name": "Wageningen University and Research Centre (WUR)", "id": "/organization/wur" }], "person": [{ "linkedInUrl": "https://www.linkedin.com/in/arnold-kuzniar-06312210", "schema": "http://software.esciencecenter.nl/schema/person", "title": "A.kuzniar", "slug": "a.kuzniar", "email": "a.kuzniar@esciencecenter.nl", "contactPersonOf": ["/software/fairdatapoint"], "affiliation": ["/organization/nlesc"], "userOf": ["/software/fairdatapoint"], "githubUrl": "https://github.com/arnikz", "@id": "http://software.esciencecenter.nl/person/a.kuzniar/", "description": "<p>Arnold studied Molecular Biology at the Comenius University in Bratislava, Slovakia. In the last year of his masters, he received a scholarship to study bioinformatics at the Wageningen University and Research Centre (WUR), the Netherlands. He completed his thesis on comparative genomics of White spot syndrome (shrimp) virus isolates. During this period he also developed bioinformatics tools to mine these genomes for epidemiologically relevant biomarkers.</p>\n\n<p>Arnold obtained his PhD in Bioinformatics at the Laboratory of Bioinformatics, WUR. His PhD research was on scalable orthology-based cluster detection in fully sequenced genomes and on the integration of protein orthology/family data resources. In close collaboration with SURFsara, he used the Dutch Life Science Grid to compute a comprehensive map of corresponding (orthologous) proteins across species from all three domains of life.</p>\n\n<p>In 2011 Arnold moved to Switzerland and joined the Department of Ecology and Evolution at the University of Lausanne, Swiss Institute of Bioinformatics. He worked on an e-Science project aimed at speeding up the detection of positive selection in animal genomes using the Swiss Multi Science Grid (SMSCG).</p>\n\n<p>In 2012 Arnold returned to the Netherlands and carried out research in computational mass spectrometry(MS)-based proteomics at the Department of Genetics at the Erasmus Medical Center in Rotterdam. Here he focused on reliable MS-based detection of cellular responses (pathways) upon exposure to non-ionizing electromagnetic fields. To facilitate the MS data handling and statistical analyses, Arnold developed the <a href=\"http://www.bioinformatics.nl/piqmie\">PIQMIe</a> proteomics web server.</p>\n\n<p>At the Netherlands eScience Center, Arnold works on the ODEX4all and candYgene projects, which involve Linked Data/Semantic Web technologies, worlflows and Big data analytics.</p>\n", "photo": "/images/person/a.kuzniar.jpg", "name": "Arnold Kuzniar", "researchgateUrl": "https://www.researchgate.net/profile/Arnold_Kuzniar", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-arnold-kuzniar", "ORCID": "http://orcid.org/0000-0003-1711-7961", "endorsedBy": ["/organization/nlesc"], "jobTitle": "eScience Research Engineer", "engineerOf": ["/project/odex4all", "/project/candygene"], "contributorOf": ["/software/fairdatapoint"], "id": "/person/a.kuzniar" }, { "linkedInUrl": "https://nl.linkedin.com/in/ben-van-werkhoven-3010528b", "schema": "http://software.esciencecenter.nl/schema/person", "title": "B.vanwerkhoven", "id": "/person/b.vanwerkhoven", "slug": "b.vanwerkhoven", "@id": "http://software.esciencecenter.nl/person/b.vanwerkhoven/", "email": "b.vanwerkhoven@esciencecenter.nl", "contactPersonOf": ["/software/kernel_tuner", "/project/neutrino", "/project/microscopy"], "affiliation": ["/organization/nlesc"], "userOf": ["/software/kernel_tuner", "/software/xenon"], "githubUrl": "https://github.com/benvanwerkhoven", "jobTitle": "eScience Research Engineer", "description": "<p>Ben van Werkhoven did his BSc in Computer Science and a research masters in Parallel and Distributed Computer Systems at the VU University Amsterdam. The focus of his PhD research was developing programming models and performance models for the efficiently using Graphics Processing Units within Supercomputing applications.</p>\n\n<p>Ben\u2019s main research interests involve increasing application performance with the use of Graphics Processing Units and increasing our understanding of the performance behavior of large GPU applications.</p>\n", "name": "Ben van Werkhoven", "researchgateUrl": "https://www.researchgate.net/profile/Ben_Van_Werkhoven", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-ben-van-werkhoven", "engineerOf": ["/project/a-jungle-computing-approach-to-large-scale-online-forensic-analysis", "/project/neutrino", "/project/microscopy"], "ownerOf": ["/software/kernel_tuner"], "photo": "/images/person/b.vanwerkhoven.jpg", "contributorOf": ["/software/kernel_tuner", "/software/xenon", "/software/pattyvis"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/person", "contributorOf": ["/software/noodles", "/software/common-sense"], "slug": "b.weel", "@id": "http://software.esciencecenter.nl/person/b.weel/", "description": "<p>Berend did his BSc. in Computer Science and MSc. in Technical Artificial Intelligence at the VU University Amsterdam. He did his PhD on artificial evolution of robot organisms. The idea behind his thesis was the creation of real world objects that evolve, in this case robot organisms.</p>\n\n<p>In particular he aimed to allow robots to evolve their bodies and minds to adapt to their environment and tasks.</p>\n\n<p>For his research he developed, tested and compared algorithms for such systems in simulation. He then developed a complete ecosystem for robot organisms in which the bodies and minds of these robot organisms evolved using these algorithms.</p>\n", "affiliation": ["/organization/nlesc"], "userOf": ["/software/couchdb"], "githubUrl": "https://github.com/bpmweel", "title": "B.weel", "nlescWebsite": "https://www.esciencecenter.nl/profile/berend-weel-msc", "researchgateUrl": "https://www.researchgate.net/profile/Berend_Weel", "jobTitle": "eScience Research Engineer", "photo": "/images/person/b.weel.jpg", "name": "Berend Weel", "id": "/person/b.weel" }, { "linkedInUrl": "https://www.linkedin.com/in/carlosmartinezortiz", "schema": "http://software.esciencecenter.nl/schema/person", "title": "C.martinez", "slug": "c.martinez", "id": "/person/c.martinez", "email": "c.martinez@esciencecenter.nl", "contactPersonOf": ["/software/common-sense", "/project/beyond-the-book", "/project/dive-plus", "/project/drwatson", "/project/shico"], "affiliation": ["/organization/nlesc"], "githubUrl": "https://github.com/c-martinez", "@id": "http://software.esciencecenter.nl/person/c.martinez/", "description": "<p>Carlos obtained his BSc in computer engineering at La Salle University in Mexico City. At the University of Exeter, he obtained his MSc in applied artificial intelligence and PhD on the topic of shape descriptors for image classification.</p>\n\n<p>Carlos has worked on various research projects at the University of Exeter and Plymouth University in collaboration with industrial partners such as C3 Resources Ltd, eCow Ltd and the Met Office. These projects involved scientific research in the areas of video processing, machine learning and statistical modeling. The commercial outcomes of this research covered a wide range of applications such as automatic detection of abnormal energy consumption in buildings, video tracking of dairy cows, modeling high performance storage systems and segmentation of medical images. Before moving to the United Kingdom, he worked as a web developer and team leader at an eMarketing company, Interalia Digital, for different clients such as Coca-Cola Mexico, Coca-Cola Brazil and Nike Mexico.</p>\n", "name": "Carlos Martinez-Ortiz", "researchgateUrl": "https://www.researchgate.net/profile/Carlos_Martinez_Ortiz", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-carlos-martinez-ortiz", "engineerOf": ["/project/beyond-the-book", "/project/dive-plus", "/project/drwatson", "/project/shico"], "jobTitle": "eScience Research Engineer", "photo": "/images/person/c.martinez.jpg", "contributorOf": ["/software/common-sense", "/software/pattyanalytics", "/software/python-pcl"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/person", "id": "/person/c.meijer", "slug": "c.meijer", "@id": "http://software.esciencecenter.nl/person/c.meijer/", "email": "c.meijer@esciencecenter.nl", "contactPersonOf": ["/software/mcfly"], "affiliation": ["/organization/nlesc"], "userOf": ["/software/casacore", "/software/mcfly"], "githubUrl": "https://github.com/cwmeijer", "title": "C.meijer", "description": "<p>Christiaan has studied Psychology, Physics and Artificial Intelligence, all at the University of Amsterdam (UvA). Christiaan received his MSc in both Psychology and Artificial Intelligence, track Intelligent Systems. In his thesis he applied reinforcement learning to the problem of learning new behavior in the field of robotics. His specialties include machine learning, computer vision, reinforcement learning and deep learning.</p>\n\n<p>During and after his study, he worked at Conclusion Learning Centers developing a Learning Management System (LMS). For this system he developed various new functionalities. These include a recommender system that recommends users products based on their previous behavior and setting up new catalog search functionality using Elastic Search.</p>\n\n<p>In 2013 Christiaan joined the Netherlands eScience Center as an eScience Research Engineer.</p>\n", "name": "Christiaan Meijer", "nlescWebsite": "https://www.esciencecenter.nl/profile/christiaan-meijer-msc", "engineerOf": ["/project/eecology", "/project/error-detection-and-error-localization"], "jobTitle": "eScience Research Engineer", "photo": "/images/person/c.meijer.jpg", "contributorOf": ["/software/xenon", "/software/mcfly"], "endorsedBy": ["/organization/nlesc"] }, { "linkedInUrl": "https://www.linkedin.com/in/remenska", "schema": "http://software.esciencecenter.nl/schema/person", "title": "D.remenska", "slug": "d.remenska", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-daniela-remenska", "email": "d.remenska@esciencecenter.nl", "contactPersonOf": ["/project/pandas-root", "/software/root-conda-recipes"], "affiliation": ["/organization/nlesc"], "githubUrl": "https://github.com/remenska", "@id": "http://software.esciencecenter.nl/person/d.remenska/", "authorOfReport": ["/report/rootcondarecipes"], "description": "<p>Daniela graduated from the Institute of Informatics in Macedonia as an informatics engineer. During her last year of study, she was also a lab assistant at the institute, teaching basic computer science courses. After graduating, she worked about one and a half year as a Java software developer for a large company specializing in enterprise medical software.</p>\n\n<p>Daniela moved to the Netherlands in October 2008. She obtained a PDEng (Professional Doctorate in Engineering) degree in software technology from the Eindhoven University of Technology in 2010. She carried out her final software design project on the topic of Optimization of Large Scale HEP Data Analysis at NIKHEF, which has to do with efficient access to high energy physics data gathered from the Large Hadron Collider at CERN.</p>\n\n<p>She started her PhD studies in 2010 as a joint initiative between NIKHEF and the VU University Amsterdam. Her thesis is focused on bridging the gap between common software engineering practices and model verification techniques, with a focus on concurrent and distributed systems.</p>\n\n<p>Her interests have been shifting ever since she owned a PC: from astronomy, dark matter and black holes (high school), to simulation, probability and stochastic theory (university), to distributed/grid systems.</p>\n\n<p>Daniela joined the Netherlands eScience Center in June 2015.</p>\n", "photo": "/images/person/d.remenska.jpg", "name": "Daniela Remenska", "endorsedBy": ["/organization/nlesc"], "engineerOf": ["/project/pandas-root", "/project/neutrino"], "ownerOf": ["/software/root-conda-recipes"], "jobTitle": "eScience Research Engineer", "contributorOf": ["/software/root-conda-recipes"], "id": "/person/d.remenska" }, { "linkedInUrl": "https://nl.linkedin.com/in/dafne-van-kuppevelt-45416753", "schema": "http://software.esciencecenter.nl/schema/person", "title": "D.vankuppevelt", "ownerOf": null, "id": "/person/d.vankuppevelt", "slug": "d.vankuppevelt", "@id": "http://software.esciencecenter.nl/person/d.vankuppevelt/", "email": "d.vankuppevelt@esciencecenter.nl", "contactPersonOf": null, "affiliation": ["/organization/nlesc"], "contributorOf": ["/software/salient-region-detectors", "/software/mcfly"], "userOf": ["/software/mcfly"], "githubUrl": "https://github.com/dafnevk", "jobTitle": "eScience Research Engineer", "nlescWebsite": "https://www.esciencecenter.nl/profile/dafne-van-kuppevelt-msc", "engineerOf": ["/project/enhancing-protein-drug-binding-prediction"], "endorsedBy": ["/organization/nlesc"], "photo": null, "name": "Dafne van Kuppevelt", "description": "<p>Dafne studied Computer Science and Mathematics at Utrecht University. During her master studies, she focused on Machine Learning and Data Analytics. Her master thesis was on recognizing product names using Conditional Random Fields, which she developed during her internship at VigLink in San Francisco.</p>\n\n<p>After graduation, Dafne worked at ING as a Data Scientist, where she further developed her skills in Machine Learning and applied them to different business problems. She also got interested in distributed Machine Learning for big data sets, using tools like Spark.</p>\n" }, { "coordinatorOf": ["/project/arena", "/project/era-urban", "/project/eecology", "/project/summer-in-the-city", "/software/salient-region-detectors", "/project/error-detection-and-error-localization"], "title": "E.ranguelova", "slug": "e.ranguelova", "schema": "http://software.esciencecenter.nl/schema/person", "email": "e.ranguelova@esciencecenter.nl", "contactPersonOf": ["/project/eecology", "/project/error-detection-and-error-localization", "/software/salient-region-detectors", "/software/oxfrei-dataset"], "affiliation": ["/organization/nlesc"], "githubUrl": "https://github.com/elboyran", "@id": "http://software.esciencecenter.nl/person/e.ranguelova/", "authorOfReport": ["/report/large-scale-computer-vision", "/report/wood-image-classification"], "description": "<p>Elena finished MS in Computer engineering and MS in Applied computer science at Technical University, Sofia, Bulgaria and worked for 2 years at the Institute of Information Technologies, Bulgarian Academy of Sciences. In 2003 she received a PhD degree in Computer Science with specialization in image processing from Trinity College, Dublin, Ireland. Her thesis is dedicated to 3D texture analysis and modeling with application to MRI brain images.</p>\n\n<p>Since 2003 she works in the Netherlands on variety of interdisciplinary projects and application areas. Between 2003 and 2007 she was at the Signals and Images group at Centrum Wiskunde en Informatica (CWI), Amsterdam, as a post-doctoral researcher. Elena worked on European and NWO projects for photo-identification of cetaceans and has developed an automated system used by the marine biologists in their research. A paper on saliency detector used for the photo-identification has been awarded a best paper award at GVIP\u2019 in 2005.</p>\n\n<p>In 2007 she worked at the Multimedia group of the Dutch center for applied research TNO on object recognition tools for assisting the police investigators in their work. Between 2008 and 2012 she has worked as part of the R&amp;D team of Prime Vision, B.V., Delft on OCR and indicia recognition projects for the postal industry. In 2012 Elena has also worked at the Software Engineering group at CWI on a project for automatic monitoring via camera and other sensor networks for assessing the risk of forest fires in cultural heritage regions of Southern Europe.</p>\n\n<p>Elena joined the Netherlands eScience Center as eScience engineer in January 2013 to work on multidisciplinary projects with computer vision and machine learning components.</p>\n", "photo": "/images/person/e.ranguelova.jpg", "name": "Elena Ranguelova", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-elena-ranguelova", "engineerOf": ["/project/biomarker"], "endorsedBy": ["/organization/nlesc"], "jobTitle": "eScience Coordinator", "contributorOf": ["/software/salient-region-detectors", "/software/pattydata", "/software/oxfrei-dataset"], "id": "/person/e.ranguelova" }, { "schema": "http://software.esciencecenter.nl/schema/person", "contributorOf": ["/software/twiqs.nl"], "ownerOf": ["/software/twiqs.nl"], "id": "/person/e.tjongkimsang", "slug": "e.tjongkimsang", "@id": "http://software.esciencecenter.nl/person/e.tjongkimsang/", "contactPersonOf": ["/software/twiqs.nl", "/project/twinl"], "affiliation": ["/organization/nlesc", "/organization/meertens"], "githubUrl": "https://github.com/eriktks", "title": "E.tjongkimsang", "description": "<p>Erik studied electrical engineering at the Delft University of Technology and obtained a PhD degree from the University of Groningen, after a project in which he compared three machine learning algorithms for building models for Dutch monosyllabic words. He successively obtained research and teaching positions as a computational linguist at the universities of Uppsala (Sweden), Antwerp (Belgium), Amsterdam (UvA) and Groningen, before joining the eScienceCenter as an eScience engineer in 2012. Erik is working on a project in which he develops tools for analyzing Twitter data.</p>\n\n<p>I have a background in computational linguistics and have worked as a researcher and teacher at the universities of Groningen, Uppsala, Antwerp, Tilburg and Amsterdam (UvA). At the Netherlands eScience Center I am developing tools for analyzing messages from the social network Twitter. The target users for the tools are university researchers and students.</p>\n\n<p>NLeSC Responsibility:</p>\n\n<ul>\n  <li>eScience engineer: for the project TwiNL (September 2012 - February 2013)</li>\n</ul>\n", "engineerOf": ["/project/twinl"], "jobTitle": "eScience Research Engineer", "website": "http://ifarm.nl/erikt/", "name": "Erik Tjong Kim Sang", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/person", "title": "F.diblen", "id": "/person/f.diblen", "slug": "f.diblen", "@id": "http://software.esciencecenter.nl/person/f.diblen/", "email": "f.diblen@esciencecenter.nl", "contactPersonOf": ["/project/idark"], "affiliation": ["http://sofware.esciencecenter.nl/organization/nlesc"], "jobTitle": "eScience Research Engineer", "description": "\n", "engineerOf": ["/project/idark"], "contributorOf": ["/software/spiraljs", "/software/metrochartjs", "/software/punchcardjs"], "name": "Faruk Diblen", "endorsedBy": ["/organization/nlesc"] }, { "linkedInUrl": "https://www.linkedin.com/in/gijs-van-den-oord", "schema": "http://software.esciencecenter.nl/schema/person", "title": "G.vandenoord", "description": "<p>Gijs van den Oord studied theoretical physics and mathematics at Utrecht University. In his master thesis, he investigated the relation between super-membranes and matrix models in string theory. After that he started a PhD in particle phenomenology at the Radboud University and Nikhef, where he developed expertise in high-performance computing, numerical simulation and the Monte Carlo method. With his C++ code he was able to simulate weak boson scattering in Higgsless models at the Large Hadron Collider.</p>\n\n<p>After his graduation, Gijs has worked as a consultant in scientific software development. He has helped creating the DeltaShell framework at Deltares, embedding hydrological computational codes into object-oriented wrappers to facilitate visualization and coupling. Here he has also contributed to D-Flow Flexible Mesh, a shallow-water equation solver on unstructured grids.</p>\n\n<p>Recently Gijs has started working on Primavera, a project with KNMI to study the EC-Earth climate model at high resolution, and a project with CWI and KNMI that aims to couple cloud-resolving large-eddy simulations to global atmospheric climate codes.</p>\n", "slug": "g.vandenoord", "email": "g.vandenoord@esciencecenter.nl", "contactPersonOf": ["/project/towards-large-scale-cloud-resolving-climate-simulations"], "affiliation": ["/organization/nlesc"], "contributorOf": null, "userOf": null, "githubUrl": "https://github.com/c-martinez", "@id": "http://software.esciencecenter.nl/person/g.vandenoord/", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-gijs-van-den-oord", "photo": null, "researchgateUrl": null, "endorsedBy": ["/organization/nlesc"], "engineerOf": ["/project/towards-large-scale-cloud-resolving-climate-simulations", "/project/primavera"], "ownerOf": null, "jobTitle": "eScience Research Engineer", "name": "Gijs van den Oord", "id": "/person/g.vandenoord" }, { "schema": "http://software.esciencecenter.nl/schema/person", "slug": "h.spreeuw", "@id": "http://software.esciencecenter.nl/person/h.spreeuw/", "description": "<p>Hanno graduated in astronomy on the search and detection of low frequency radio transients with LOFAR. This involved the development of (Python) code for source extraction in radio maps.</p>\n\n<p>Prior to his defence he was a postdoc at the Dutch National Weather Institute (K.N.M.I.) where he analyzed trends in over a century of Dutch precipitation data. After that, he returned to his Ph.D. supervisor to write documentation for his LOFAR source extraction software. Subsequently, Hanno worked for 4.5 years at the radiotherapy department of the Dutch National Cancer Institute (N.K.I) to develop software for real time 3D dose reconstruction from portal images. This software will be used for quality assurance and as a \u2018safety net\u2019 for patients.</p>\n\n<p>Hanno joined the NLeSC in 2015.</p>\n", "affiliation": ["/organization/nlesc"], "userOf": ["/software/casacore", "/software/kernel_tuner"], "githubUrl": "https://github.com/HannoSpreeuw", "title": "H.spreeuw", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-hanno-spreeuw", "engineerOf": ["/project/neutrino"], "photo": "https://www.esciencecenter.nl/img/team/hanno-spreeuw-web.jpg", "name": "Hanno Spreeuw", "id": "/person/h.spreeuw" }, { "linkedInUrl": "https://www.linkedin.com/in/jiskattema", "schema": "http://software.esciencecenter.nl/schema/person", "title": "J.attema", "slug": "j.attema", "coordinatorOf": ["/project/aa-alert", "/project/dive-plus", "/project/shico", "/project/drwatson", "/project/beyond-the-book", "/project/pidimehs", "/project/automated-parallel-calculation-of-collaborative-statistical-models"], "email": "j.attema@esciencecenter.nl", "contactPersonOf": ["/software/xtas", "/project/summer-in-the-city", "/project/aa-alert", "/software/python-pcl", "/software/pattyanalytics"], "affiliation": ["/organization/nlesc"], "githubUrl": "https://github.com/jiskattema", "@id": "http://software.esciencecenter.nl/person/j.attema/", "authorOfReport": ["/report/summerinthecity"], "description": "<p>Jisk studied physics at the University of Groningen, graduating with honors from the theoretical physics program. After that he did his PhD on the topic of numerical solid state physics at the university of Nijmegen. His thesis focuses on the search for new (magnetic) materials for use in the semiconductor industry; this by using computational methods (density functional theory). This ignited his passion for high performance computing and big data. After finishing his PhD Jisk worked at SURFsara, the national HPC and e-science support center.</p>\n\n<p>Crossing the line between physics and computation science again, Jisk worked several years at the Dutch national weather office (KNMI). As a member of the regional climate department he worked on improving and optimizing the (regional scale) climate model, as well as repurposing the high-resolution weather model for climate research. He also contributed to the KNMI climate scenarios for the Netherlands, and then joined the NLeSC to work as engineer on the Summer in the City project.</p>\n\n<p>Jisk is also eScience Coordinator for the digital humanities and social sciences projects, aswell as some physics and beyond projects.</p>\n", "photo": "/images/person/j.attema.jpg", "name": "Jisk Attema", "researchgateUrl": "https://www.researchgate.net/profile/Jisk_Attema", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-jisk-attema", "engineerOf": ["/project/summer-in-the-city", "/project/aa-alert", "/project/viaappia-patty"], "endorsedBy": ["/organization/nlesc"], "jobTitle": "eScience Coordinator", "contributorOf": ["/software/pattyanalytics", "/software/python-pcl"], "id": "/person/j.attema" }, { "linkedInUrl": "https://www.linkedin.com/in/jorisborgdorff", "schema": "http://software.esciencecenter.nl/schema/person", "twitterUrl": "https://twitter.com/bobbyutreg", "slug": "j.borgdorff", "email": "j.borgdorff@esciencecenter.nl", "title": "J.borgdorff", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-joris-borgdorff", "jobTitle": "eScience Research Engineer", "name": "Joris Borgdorff", "description": "<p>Joris studied mathematics and computer science at Utrecht University. He did his PhD on distributed multiscale computing at the University of Amsterdam in the Computational Science Lab. His thesis ranges from multiscale modeling methodology to the performance of distributed multiscale simulations; its application ranges from biomedical research to the simulation of fusion plasma physics. It also resulted in the public domain distributed multiscale simulation runtime environment MUSCLE 2. Because the research was embedded in the European MAPPER project, the formalisms and software found uptake in several application domains and grid middleware.</p>\n\n<p>Before his PhD, Joris was a visiting researcher at SACEMA in South Africa to work on an epidemiological model combining HIV and TB disease dynamics. He adapted another model on sexually transmitted diseases so it was simulated with volunteer computing, using BOINC.</p>\n\n<p>Joris joined the Netherlands eScience Center as an eScience engineer to work on the SIM-CITY project, aiming to combine disparate data sources to improve urban modeling. His interest is primed toward work that has an added value for society.</p>\n", "contactPersonOf": ["/software/pyxenon", "/project/simcity", "/software/picas", "/software/couchdb", "/software/docker-couch-admin"], "affiliation": ["http://sofware.esciencecenter.nl/organization/nlesc"], "userOf": ["/software/xenon", "/software/pyxenon", "/software/picas", "/software/couchdb"], "githubUrl": "https://github.com/blootsvoets", "@id": "http://software.esciencecenter.nl/person/j.borgdorff/", "contributorOf": ["/software/xenon", "/software/pyxenon", "/software/osmium", "/software/pattyanalytics", "/software/python-pcl", "/software/common-sense", "/software/picas", "/software/docker-couch-admin"], "researchgateUrl": "https://www.researchgate.net/profile/Joris_Borgdorff", "engineerOf": ["/project/simcity"], "endorsedBy": ["/organization/nlesc"], "photo": "/images/person/j.borgdorff.jpg", "website": "http://www.jorisborgdorff.nl/", "id": "/person/j.borgdorff" }, { "schema": "http://software.esciencecenter.nl/schema/person", "title": "J.hidding", "id": "/person/j.hidding", "slug": "j.hidding", "@id": "http://software.esciencecenter.nl/person/j.hidding/", "email": "j.hidding@esciencecenter.nl", "contactPersonOf": ["/software/noodles"], "affiliation": ["/organization/nlesc"], "userOf": ["/software/pyxenon", "/software/noodles"], "jobTitle": "eScience Research Engineer", "description": "<p>Johan studied astrophysics at the University of Groningen, Kapteyn Astronomical Institute. He is finishing his PhD thesis on the dynamics of the large-scale structure of the Universe. In this work he used tessellation techniques from computational geometry to model and visualise the complex patterns that we find throughout the Universe.</p>\n", "contributorOf": ["/software/pyxenon", "/software/noodles", "/software/spiraljs", "/software/metrochartjs", "/software/punchcardjs"], "photo": "/images/person/j.hidding.jpg", "name": "Johannes Hidding", "endorsedBy": ["/organization/nlesc"] }, { "linkedInUrl": "https://nl.linkedin.com/in/jason-maassen-6795ba4", "schema": "http://software.esciencecenter.nl/schema/person", "slug": "j.maassen", "@id": "http://software.esciencecenter.nl/person/j.maassen/", "email": "j.maassen@esciencecenter.nl", "coordinatorOf": ["/project/pandas-root", "/project/ewatercycle", "/project/large-scale-data-assimilation", "/project/esalsa", "/project/amuse", "/project/abcmuse", "/project/neutrino"], "title": "J.maassen", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-jason-maassen", "ownerOf": ["/software/xenon", "/software/magnesium", "/project/sherlock"], "name": "Jason Maassen", "description": "<p>Jason studied Computer Science at the VU University Amsterdam, where he graduated cum laude in 1998. The focus of his PhD research (1998-2003) was on developing object oriented programming models for parallel and distributed \nprogramming. Between 2003 and 2012 he has participated in several research projects, where he has looked at a range of topics related to large scale distributed computing. During this time he has developed a monitoring system for a world-wide \nGrid, robust communication libraries, programming models for computing on heterogenous distributed systems, and several eScience applications that use dynamically allocatable lightpaths.</p>\n\n<p>Jason joined the NLeSC in 2012, where he has worked as an eScience Engineer on the eSalsa, Extreme Climate Change and Jungle Computing projects. From 2013 to 2015 he was an eScience Coordinator managing several eScience Engineers \nand projects. From 2016 on he is the Technology Lead for the Efficient Computing expertise area at the Netherlands eScience Center.</p>\n", "contactPersonOf": ["/software/xenon", "/software/magnesium", "/project/sherlock", "/project/abcmuse", "/project/esalsa", "/project/a-jungle-computing-approach-to-large-scale-online-forensic-analysis"], "affiliation": ["/organization/nlesc"], "userOf": ["/software/xenon", "/software/magnesium"], "githubUrl": "https://github.com/jmaassen", "jobTitle": "Technology Lead Efficient Computing", "contributorOf": ["/software/xenon", "/software/sfm", "/software/magnesium"], "researchgateUrl": "https://www.researchgate.net/profile/Jason_Maassen", "engineerOf": ["/project/a-jungle-computing-approach-to-large-scale-online-forensic-analysis"], "endorsedBy": ["/organization/nlesc"], "photo": "/images/person/j.maassen.jpg", "id": "/person/j.maassen" }, { "schema": "http://software.esciencecenter.nl/schema/person", "title": "J.spaaks", "slug": "j.spaaks", "nlescWebsite": "https://www.esciencecenter.nl/profile/drs-jurriaan-spaaks", "email": "j.spaaks@esciencecenter.nl", "contactPersonOf": ["/software/metrochartjs", "/software/google-earth-toolbox-for-matlab", "/software/differential-evolution", "/software/matrix-of-scatter", "/software/mmsoda-toolbox-for-matlab", "/project/esibayes", "/software/spiraljs", "/software/punchcardjs"], "affiliation": ["/organization/nlesc"], "userOf": ["/software/metrochartjs", "/software/google-earth-toolbox-for-matlab", "/software/differential-evolution", "/software/matrix-of-scatter", "/software/mmsoda-toolbox-for-matlab", "/software/spiraljs", "/software/punchcardjs"], "githubUrl": "https://github.com/jspaaks", "@id": "http://software.esciencecenter.nl/person/j.spaaks/", "authorOfReport": ["/report/xenon-tutorial"], "description": "<p>Jurriaan\u2019s main responsibility as an eScience engineer is the implementation of inverse modeling algorithms such as DREAM, SCEM-UA, and SODA on cluster computers while improving the usability of these algorithms in the cluster environment.</p>\n\n<p>After completing his BSc and MSc in Earth Sciences at the University of Amsterdam, Jurriaan worked as a PhD in the Computational Geo-Ecology group of Willem Bouten (<a href=\"http://ibed.uva.nl/research/research-groups/content/computational-geo-ecology/computational-geo-ecology.html\">link</a>). The thesis work covers the application of inverse modeling algorithms such as DREAM, SCEM-UA, and SODA (<a href=\"http://faculty.sites.uci.edu/jasper/publications/\">link</a>) for improved diagnosis of model structure error in hydrological models (<a href=\"http://www.hydrol-earth-syst-sci.net/17/3455/2013/hess-17-3455-2013.pdf\">link</a>).</p>\n\n<p>Jurriaan divides his time working as an eScience engineer for the Netherlands eScience Center and writing up his PhD thesis. His most recent accomplishments for the Netherlands eScience Center include implementing single-objective and multi-objective variants of SCEM-UA and of SODA on SURFsara\u2019s cluster computer LISA within the eSiBayes project (<a href=\"https://www.esciencecenter.nl/project/esibayes\">link</a>, <a href=\"https://github.com/NLeSC/esibayes\">source code</a>). Jurriaan is currently involved in the data assimilation of satellite observations for the eWaterCycle project (<a href=\"http://www.youtube.com/watch?v=fOZYCBY3yz4\">video</a>) using OpenDA (<a href=\"http://www.openda.org/\">link</a>), which attempts to simulate the soil water dynamics for the entire globe on a fine resolution.</p>\n\n<p>Besides inverse modeling and dynamic models, Jurriaan has also worked on visualization of spatial data. For this he co-developed the GoogleEarth Toolbox for MATLAB, which has become one of the most popular downloads in the domain of Earth Sciences (<a href=\"http://www.mathworks.nl/matlabcentral/fileexchange/12954-google-earth-toolbox\">link</a>).</p>\n", "photo": "/images/person/j.spaaks.jpg", "name": "Jurriaan H. Spaaks", "endorsedBy": ["/organization/nlesc"], "engineerOf": ["/project/sherlock", "/project/eecology", "/project/esibayes"], "ownerOf": ["/software/google-earth-toolbox-for-matlab", "/software/differential-evolution", "/software/matrix-of-scatter", "/software/mmsoda-toolbox-for-matlab"], "jobTitle": "eScience Research Engineer", "contributorOf": ["/software/metrochartjs", "/software/sfm", "/software/google-earth-toolbox-for-matlab", "/software/differential-evolution", "/software/matrix-of-scatter", "/software/mmsoda-toolbox-for-matlab", "/software/spiraljs", "/software/punchcardjs"], "id": "/person/j.spaaks" }, { "linkedInUrl": "https://nl.linkedin.com/in/jvdzwaan", "schema": "http://software.esciencecenter.nl/schema/person", "title": "J.vanderzwaan", "slug": "j.vanderzwaan", "id": "/person/j.vanderzwaan", "email": "j.vanderzwaan@esciencecenter.nl", "contactPersonOf": ["/software/cptm", "/project/dilipad", "/project/texcavator", "/software/texcavator", "/project/from-sentiment-mining-to-mining-embodied-emotions", "/software/recipy", "/software/rig", "/project/what-works-when-for-whom", "/software/topic-coherence-for-dutch", "/software/heem-dataset"], "affiliation": ["/organization/nlesc"], "githubUrl": "https://github.com/jvdzwaan", "@id": "http://software.esciencecenter.nl/person/j.vanderzwaan/", "description": "<p>Janneke van der Zwaan has a background in Artificial Intelligence (2006, University of Amsterdam, cum laude). During her Master\u2019s project, she worked on medical text classification in cooperation with the Dutch national network and registry of histo- and cytopathology (Stichting PALGA). She also completed a\nMaster\u2019s specialization in Science Communication (2008, VU University).</p>\n\n<p>In 2014, she obtained a PhD in Human-Computer Interaction at Delft University of Technology.\nThe goal of her research was to understand how Embodied Conversational Agents (ECAs) can provide social support in non task-oriented settings.</p>\n\n<p>Currently, Janneke works as an eScience Research Engineer at the Netherlands eScience Center.\nHer main expertise is text mining.</p>\n", "name": "Janneke van der Zwaan", "researchgateUrl": "https://www.researchgate.net/profile/Janneke_Van_der_Zwaan", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-janneke-van-der-zwaan", "engineerOf": ["/project/dilipad", "/project/texcavator", "/project/from-sentiment-mining-to-mining-embodied-emotions", "/project/visualizing-uncertainty-and-perspectives", "/project/sherlock", "/project/what-works-when-for-whom"], "jobTitle": "eScience Research Engineer", "photo": "/images/person/j.vanderzwaan.jpg", "contributorOf": ["/software/cptm", "/software/texcavator", "/software/recipy", "/software/rig", "/software/pattyvis", "/software/storyteller", "/software/topic-coherence-for-dutch", "/software/heem-dataset"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/person", "id": "/person/l.buitinck", "slug": "l.buitinck", "@id": "http://software.esciencecenter.nl/person/l.buitinck/", "description": "<p>As an eScience engineer, Lars works on the project Search Public Discourse (SPuDisc). Lars holds an MA degree in information science from the University of Groningen and worked there on optimized storage and query facilities for linguistic treebanks.</p>\n\n<p>Lars worked at the University of Amsterdam as a software engineer, building storage and search engines for projects with the NIOD Institute for War, Holocaust and Genocide Studies, and the xTAS scalable text analysis server.</p>\n\n<p>Lars is also a core developer of the scikit-learn machine learning and data mining toolkit, and a regular contributor to the NumPy and SciPy libraries for high-performance numerical computing in Python.</p>\n\n", "affiliation": ["/person/l.buitinck"], "title": "L.buitinck", "nlescWebsite": "https://www.esciencecenter.nl/profile/drs.-lars-buitinck", "jobTitle": "eScience Research Engineer", "name": "Lars Buitinck", "contributorOf": ["/software/cptm", "/software/rig", "/software/pattyanalytics", "/software/python-pcl", "/software/pidilib"], "endorsedBy": ["/organization/nlesc"] }, { "linkedInUrl": "https://nl.linkedin.com/in/lodekulik", "schema": "http://software.esciencecenter.nl/schema/person", "title": "L.kulik", "slug": "l.kulik", "@id": "http://software.esciencecenter.nl/person/l.kulik/", "email": "l.kulik@esciencecenter.nl", "affiliation": ["/organization/nlesc"], "contributorOf": ["/software/pattyvis"], "jobTitle": "Communications Advisor", "description": "<p>Lode holds a Master\u2019s degree in Conflict Resolution and Governance. That\u2019s where he learned to appreciate listening to different sides of a story. This appreciation slowly but surely turned into a passion for the field of communication. First at the EVS Foundation of the Dutch Labour Party, where he was communications manager. Later at Amnesty International\u2019s Movies that Matter, where Lode developed the digital communications strategy and an ambassadors program.</p>\n\n<p>In June 2013 Lode joined the Netherlands eScience Center as communications advisor.</p>\n", "nlescWebsite": "https://www.esciencecenter.nl/profile/lode-kulik-msc", "id": "/person/l.kulik", "photo": "/images/person/l.kulik.jpg", "name": "Lode Kulik", "endorsedBy": ["/organization/nlesc"] }, { "coordinatorOf": ["/project/candygene", "/project/odex4all", "/project/3d-e-chem"], "title": "L.ridder", "id": "/person/l.ridder", "slug": "l.ridder", "schema": "http://software.esciencecenter.nl/schema/person", "email": "l.ridder@esciencecenter.nl", "contactPersonOf": ["/software/magma", "/project/computational-chemistry-made-easy"], "affiliation": ["/organization/nlesc", "/organization/wur"], "contributorOf": ["/software/magma"], "userOf": ["/software/magma", "/software/osmium", "/software/noodles"], "@id": "http://software.esciencecenter.nl/person/l.ridder/", "description": "<p>Lars\u2019 research interests cover (bio)chemical informatics and simulations. He is responsible as engineer and project coordinator in multiple projects in the life-sciences and chemistry domains.</p>\n\n<p>Lars studied Molecular Sciences at Wageningen University, graduating with honors in 1996. He obtained his PhD at the Wageningen University on Computational Studies of Enzyme Catalysis. In 2000, he was awarded a Marie-Curie fellowship at the School of Chemistry, University of Bristol, UK, during which he investigated the reaction mechanisms of biotransformation enzymes on the basis of combined quantum mechanical/molecular mechanical simulations.</p>\n\n<p>In 2002, he joined Organon R&amp;D, department of Molecular Design and Informatics. At Organon, which became part of Schering-Plough in 2009 and subsequently of Merck, he was responsible for in silico prediction of drug absorption, metabolism and toxicity and was part of multidisciplinary lead optimization teams.</p>\n\n<p>From 2012 to 2015, Lars led an academic project on computational interpretation of LC-MS/MS and LC-MSn data of complex biological samples. The project resulted in a user-friendly webapplication allowing metabolomics experts to annotate unknown metabolites and supporting them in the discovery of novel biochemical pathways.</p>\n\n<p>In May 2015 he joined the Netherlands eScience Center as senior eScience research engineer and project coordinator.</p>\n", "principalInvestigatorOf": ["/project/emetabolomics"], "jobTitle": "eScience Coordinator", "photo": "/images/person/l.ridder.jpg", "name": "Lars Ridder", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/person", "id": "/person/l.veen", "slug": "l.veen", "@id": "http://software.esciencecenter.nl/person/l.veen/", "email": "l.veen@esciencecenter.nl", "contactPersonOf": ["/project/enhancing-protein-drug-binding-prediction", "/project/e-musc"], "affiliation": ["/organization/nlesc"], "githubUrl": "https://github.com/LourensVeen", "title": "L.veen", "description": "<p>Lourens studied Computer Science at the University of Twente in\nThe Netherlands, where he received an MSc (Hons.) in Databases and Information\nSystems in 2007.</p>\n\n<p>He then joined the Computational Geo-Ecology group of the University of\nAmsterdam as a scientific programmer on the NDFF-EocGRID project (Part of the\nVirtual Laboratory for e-Science programme). Lourens led the design of the\ndata model and system architecture of the Dutch National Database of Flora and\nFauna (NDFF). The NDFF is a repository for species observations that is now\nused by volunteer and professional observers to record their observations, by\ngovernments to ensure compliance with EU nature protection directives, by\nscientists for species distribution modelling, and by companies operating in\nthe Dutch landscape to assess potential risks to nature at a time when they\ncan still be easily and inexpensively mitigated.</p>\n\n<p>Following this, Lourens continued at UvA as a PhD candidate in Computational\nGeo-Ecology, working on the incorporation of dispersal limitations into\nspecies distribution models, and fitting such models to observation data\nusing Bayesian techniques. He also worked with colleagues on processing\nhigh-resolution global forest cover data into statistics on forest loss and\nfragmentation, with the goal of investigating at which scales ecosystem\nservices are most affected by these changes.</p>\n\n<p>While working on these projects, Lourens discovered a love for the\nmethodological and technical aspects of doing research, and in February 2016\nhe joined the eScience Center.</p>\n", "name": "Lourens Veen", "nlescWebsite": "https://www.esciencecenter.nl/profile/ir.-lourens-veen", "engineerOf": ["/project/e-musc", "/project/enhancing-protein-drug-binding-prediction"], "jobTitle": "eScience Research Engineer", "photo": "/images/person/l.veen.jpg", "contributorOf": ["/software/xtas", "/software/spiraljs", "/software/metrochartjs", "/software/punchcardjs"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/person", "jobTitle": "eScience Research Engineer", "slug": "m.kuzak", "@id": "http://software.esciencecenter.nl/person/m.kuzak/", "email": "m.kuzak@esciencecenter.nl", "affiliation": ["/organization/nlesc"], "contributorOf": ["/software/pattyvis", "/software/spiraljs", "/software/metrochartjs", "/software/punchcardjs"], "githubUrl": "https://github.com/mkuzak", "title": "M.kuzak", "description": "<p>Mateusz obtained his master degree in Biotechnology with specialization Biophysics, at the Jagiellonian University, Krakow, Poland. He used live cell imaging techniques and fluorescence confocal microscopy to study the dynamics and structure of cell nucleus. During this period, he spent 6 months in the Centre de Biophysique Moleculaire, CNRS in Orleans, France. Mateusz worked there on a model of gene transfer in endothelial cell monolayer exposed to steady laminar flow. After obtaining his master degree, he continued research in live cell imaging in Krakow, but focusing more on automated microscopy image analysis.</p>\n\n<p>Mateusz engaged in collaboration with Eric Manders at van Leeuwenhoek Centre for Advanced Microscopy at University of Amsterdam and worked on MATLAB software for control of a prototype wide field CLEM microscope.</p>\n\n<p>In 2010, he moved to Amsterdam and worked at the RNA Biology &amp; Applied Bioinformatics unit, University of Amsterdam in the Virtual Laboratory for Plant Breeding project. Mateusz worked on the development of an interactive visualization for allelic variation in crop plants and on next generation sequencing data analysis. Mateusz has been active in the Dutch bioinformatics community mostly via NBIC bio-assist. \nSince 2013, he continues working in the Virtual Laboratory for Plant Breeding project as an eScience engineer on behalf of the Netherlands eScience Center. Mateusz works on the implementation of NGS data analysis pipelines and on development of new data analysis methods for Ion Proton platform.</p>\n\n<p>Mateusz enjoys programming in Python, R and JavaScript. He likes experimenting with new ways to visualize data in order to facilitate biological discovery.</p>\n", "nlescWebsite": "https://www.esciencecenter.nl/profile/mateusz-kuzak-msc", "id": "/person/m.kuzak", "photo": "/images/person/m.kuzak.jpg", "name": "Mateusz Kuzak", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/person", "title": "M.sanders", "description": "\n", "@id": "http://software.esciencecenter.nl/person/m.sanders/", "slug": "m.sanders", "userOf": ["/software/magma"], "endorsedBy": ["/organization/nlesc"], "name": "Marijn Sanders", "affiliation": ["/organization/nlesc"], "contributorOf": ["/software/magma"], "id": "/person/m.sanders" }, { "schema": "http://software.esciencecenter.nl/schema/person", "title": "M.vanmeersbergen", "slug": "m.vanmeersbergen", "@id": "http://software.esciencecenter.nl/person/m.vanmeersbergen/", "email": "m.vanmeersbergen@esciencecenter.nl", "contactPersonOf": ["/software/ahn2webviewer", "/software/potree", "/software/storyteller", "/software/pattyvis", "/project/visualizing-uncertainty-and-perspectives", "/software/cesium-ncwms"], "affiliation": ["/organization/nlesc"], "contributorOf": ["/software/storyteller", "/software/massivepotreeconverter", "/software/potree", "/software/ahn2webviewer", "/software/pattyvis", "/software/cesium-ncwms"], "userOf": ["/software/cesium"], "jobTitle": "eScience Research Engineer", "description": "<p>Maarten studied Computer Science at the VU University in Amsterdam, where he specialized in Multimedia Applications. His Master\u2019s thesis focused on visualization of the inner workings of the Ibis Complex HPC framework. During his studies, Maarten worked in IT support at the Faculty of Science at the VU University for 6 years, helping researchers to use the faculty\u2019s computing services to their full extent. During this time, he also engaged in some early eScience by parallelizing his code to verify a Math algorithm on a large scale.</p>\n\n<p>After graduation, Maarten was employed by the VU University as a Scientific Programmer to continue his work in visualization. His work was used to promote the Ibis eScience framework and a sample application in Astrophysics at the Supercomputing conference in Seattle in 2011. He also played a major role in the overhaul of the Computer Graphics course at the VU University, by introducing a framework for OpenGL 3+ and GLSL shader programming.</p>\n\n<p>Since 2012, Maarten is employed by the Netherlands eScience Center as a core team eScience Engineer, where he also focuses on visualization.</p>\n", "nlescWebsite": "https://www.esciencecenter.nl/profile/maarten-van-meersbergen-msc", "engineerOf": ["/project/visualizing-uncertainty-and-perspectives", "/project/massive-point-clouds-for-esciences", "/project/viaappia-patty"], "id": "/person/m.vanmeersbergen", "photo": "/images/person/m.vanmeersbergen.jpg", "name": "Maarten van Meersbergen", "endorsedBy": ["/organization/nlesc"] }, { "linkedInUrl": "https://www.linkedin.com/in/niels-drost-664698a", "schema": "http://software.esciencecenter.nl/schema/person", "title": "N.drost", "slug": "n.drost", "id": "/person/n.drost", "email": "n.drost@esciencecenter.nl", "contactPersonOf": ["/project/ewatercycle", "/project/large-scale-data-assimilation", "/software/amuse", "/project/amuse", "/software/sfm", "/software/ewaterleaf", "/software/openda"], "affiliation": ["/organization/nlesc"], "userOf": ["/software/xenon", "/software/cesium-ncwms", "/software/openda"], "githubUrl": "https://github.com/nielsdrost", "@id": "http://software.esciencecenter.nl/person/n.drost/", "description": "<p>Niels studied Computer Science at the VU University Amsterdam, specializing on Computer Systems, and resulting in a Master degree in 2004. During his PhD research, he developed techniques and software aimed at making it trivial to use any available computer resource (including desktop machines, clusters, clouds, supercomputers, etc.) to run parallel applications on. His research resulted in the Zorilla P2P middleware system.</p>\n\n<p>Niels defended his PhD \u201cReal-World Distributed Supercomputing\u201d in 2010. He is also one of the core developers of the Ibis project.</p>\n\n<p>In 2010, he became a Postdoc at the VU University, continuing his work on high-performance distributed computing. Niels was a part-time guest researcher at the Leiden Observatory, in the Computational Astrophysics group of Prof. Simon Portegies Zwart. There, he applied distributed computing techniques to the AMUSE computational astronomy simulation framework.</p>\n\n<p>Niels joined the Netherlands eScience Center in 2012, where he is working as an eScience Research Engineer. He has worked on the AMUSE as well as eWaterCycle, OpenDA, and EDS project.</p>\n", "name": "Niels Drost", "researchgateUrl": "https://www.researchgate.net/profile/Niels_Drost", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-niels-drost", "engineerOf": ["/project/large-scale-data-assimilation", "/project/ewatercycle", "/project/amuse", "/project/viaappia-patty"], "jobTitle": "eScience Research Engineer", "photo": "/images/person/n.drost.jpg", "contributorOf": ["/software/openda", "/software/cesium-ncwms", "/software/xenon", "/software/sfm", "/software/amuse", "/software/ewaterleaf"], "endorsedBy": ["/organization/nlesc"] }, { "linkedInUrl": "https://nl.linkedin.com/in/oscarmartinezrubi/en", "schema": "http://software.esciencecenter.nl/schema/person", "title": "O.rubi", "slug": "o.rubi", "id": "/person/o.rubi", "email": "o.rubi@esciencecenter.nl", "contactPersonOf": ["/project/massive-point-clouds-for-esciences", "/project/viaappia-patty", "/project/improving-photogrammetry", "/software/pdal", "/software/potreeconverter", "/software/massivepotreeconverter", "/software/pattydata", "/software/micmac", "/software/liblas", "/software/pymicmac", "/software/pycoeman"], "affiliation": ["/organization/nlesc"], "userOf": ["/software/monetdb", "/software/pattydata", "/software/pattyanalytics", "/software/pattyvis", "/software/sfm", "/software/potree", "/software/potreeconverter", "/software/massivepotreeconverter", "/software/pdal", "/software/ahn2webviewer", "/software/micmac", "/software/noodles", "/software/python-pcl", "/software/liblas", "/software/pycoeman", "/software/pymicmac"], "githubUrl": "https://github.com/oscarmartinezrubi", "@id": "http://software.esciencecenter.nl/person/o.rubi/", "description": "<p>Oscar did Telecommunications Engineering in the Polytechnic University of Catalonia (UPC) in Barcelona. Later on, he obtained a Master\u2019s degree in Astrophysics, focusing in software engineering challenges in astronomical projects.</p>\n\n<p>Oscar\u2019s background is development of software systems for the management, processing and analysis of Big Data. In the first years of his career, he was involved in astronomical projects. Initially in the development of a distributed analysis tool for the simulators of the ESA\u2019s Gaia space mission. More recently, he was in charge of the data management of the LOFAR Epoch of Reionization project, which meant the development of a database system for the indexing of the petabyte-scale data handled by the project (among other things). The system, together with some additional tools, was used to ease the processing of the data.</p>\n\n<p>Oscar has realized that the skills acquired in astronomy projects can also be applied in many other areas that also fascinates him. That is the reason why he joined NLeSC in 2013. He has been the principal eScience researcher for several projects related to point cloud data, concretely \u201cMassive point clouds for eScience\u201d, \u201cMapping the Via Appia in 3D\u201d and \u201cImproving Open-Source Photogrammetric Workflows for Processing Big Datasets\u201d. He also contributes to the eStep platform with libraries and knowledge for Geospatial analytics.</p>\n", "name": "Oscar Martinez Rubi", "researchgateUrl": "https://www.researchgate.net/profile/Oscar_Martinez_Rubi", "nlescWebsite": "https://www.esciencecenter.nl/profile/oscar-martinez-rubi-msc", "engineerOf": ["/project/aa-alert", "/project/massive-point-clouds-for-esciences", "/project/viaappia-patty", "/project/improving-photogrammetry"], "jobTitle": "eScience Research Engineer", "photo": "/images/person/o.rubi.jpg", "contributorOf": ["/software/rig", "/software/pattydata", "/software/potree", "/software/potreeconverter", "/software/massivepotreeconverter", "/software/pdal", "/software/ahn2webviewer", "/software/micmac", "/software/pattyvis", "/software/liblas", "/software/pymicmac", "/software/pycoeman"], "endorsedBy": ["/organization/nlesc"] }, { "linkedInUrl": "https://www.linkedin.com/in/egpbos", "schema": "http://software.esciencecenter.nl/schema/person", "title": "P.bos", "slug": "p.bos", "id": "/person/p.bos", "email": "p.bos@esciencecenter.nl", "contactPersonOf": ["/project/hadrianus", "/project/pidimehs", "/project/automated-parallel-calculation-of-collaborative-statistical-models", "/software/pidilib", "/software/roofit"], "affiliation": ["/organization/nlesc"], "userOf": ["/software/xtas"], "githubUrl": "https://github.com/egpbos", "@id": "http://software.esciencecenter.nl/person/p.bos/", "description": "<p>Patrick has studied astronomy and philosophy and has a PhD in cosmology from the Kapteyn Astronomical Institute of the University of Groningen. Patrick has worked on theoretical and observational problems in cosmology and extragalactic astronomy and has always taken a strongly computational approach.</p>\n\n<p>As an undergrad he used automated galaxy detection codes and the Astro-WISE database and later on focused on N-body simulations and structural analysis/visualization thereof. During his PhD, Patrick developed a Bayesian framework for inverting gravity to reconstruct the (ensemble of possible) initial conditions of the universe.</p>\n\n<p>Patrick joined the Netherlands eScience Center as an eScience Engineer in August 2014, where he has worked on Digital Humanities projects PIDIMEHS and HADRIANVS. From May 2016 he started work on using parallelization techniques to accelerate RooFit, a collaborative statistical model used for particle physics experiments, like the ATLAS and CMS detectors that were used to determine the mass of the Higgs boson.</p>\n", "name": "Patrick Bos", "researchgateUrl": "https://www.researchgate.net/profile/E_G_Patrick_Bos", "nlescWebsite": "https://www.esciencecenter.nl/profile/patrick-bos-msc", "engineerOf": ["/project/pidimehs", "/project/hadrianus", "/project/automated-parallel-calculation-of-collaborative-statistical-models"], "jobTitle": "eScience Research Engineer", "photo": "/images/person/p.bos.jpg", "website": "http://egpbos.nl", "contributorOf": ["/software/pattyvis", "/software/cptm", "/software/pidilib", "/software/roofit"], "endorsedBy": ["/organization/nlesc"] }, { "linkedInUrl": "https://www.linkedin.com/in/renab", "schema": "http://software.esciencecenter.nl/schema/person", "title": "R.bakhshi", "slug": "r.bakhshi", "coordinatorOf": ["http://software.esciencecenter.nl/project/towards-large-scale-cloud-resolving-climate-simulations", "http://software.esciencecenter.nl/project/idark", "http://software.esciencecenter.nl/project/e-musc", "http://software.esciencecenter.nl/project/enhancing-protein-drug-binding-prediction"], "contactPersonOf": ["http://software.esciencecenter.nl/project/primavera"], "affiliation": ["http://software.esciencecenter.nl/organization/nlesc", "http://software.esciencecenter.nl/organization/knmi"], "githubUrl": "https://github.com/bakhshir", "@id": "http://software.esciencecenter.nl/person/r.bakhshi/", "description": "<p>Rena holds double MSc in Applied Mathematics from Baku State University and in Computer Science from KTH, Sweden. In 2011 she received her PhD degree in Theoretical Computer Science from VU Amsterdam. Her research focused on (formal) modelling and analysis of large-scale stochastic systems. She worked as a postdoctoral fellow and an Assistant Professor at VU, and research visitor at NICTA Sydney and University of Melbourne on variety of interdisciplinary projects related to large-scale complex sytems. Rena joined the Netherlands eScience Center in January 2016.</p>\n\n", "name": "Rena Bakhshi", "researchgateUrl": null, "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-rena-bakhshi", "engineerOf": ["http://software.esciencecenter.nl/project/primavera"], "jobTitle": "eScience Coordinator", "photo": "https://www.esciencecenter.nl/img/team/Rena_Bakhshi-web.jpg", "website": null, "contributorOf": null, "id": "/person/r.bakhshi" }, { "linkedInUrl": "https://nl.linkedin.com/in/romulo-goncalves-6999b341", "schema": "http://software.esciencecenter.nl/schema/person", "title": "R.goncalves", "slug": "r.goncalves", "id": "/person/r.goncalves", "email": "r.goncalves@esciencecenter.nl", "contactPersonOf": ["/software/monetdb", "/software/datavaults", "/project/3d-geospatial-data-exploration-for-modern-risk-management-systems", "/project/big-data-analytics-in-the-geo-spatial-domain"], "affiliation": ["/organization/nlesc"], "userOf": ["/software/monetdb", "/software/datavaults", "/software/liblas"], "githubUrl": "https://github.com/romulogoncalves", "@id": "http://software.esciencecenter.nl/person/r.goncalves/", "description": "<p>In March 2014 Romulo joined Netherlands eScience Center after his post-doctoral research at IBM Almaden research center.</p>\n\n<p>On March 2013 he received a PhD degree from the University of Amsterdam entitled \u201cThe DataCyclotron: Juggling data and queries for a data warehouse audience\u201d. The research was conducted at CWI Database group place where he also worked in several other projects such as SkyServer, DataCell and Recycler. In the latter the team was awarded with a SIGMOD best paper runner-up award in 2009. During his PhD Romulo was a student assistant for the course Advanced Database Techniques from September 2006 until February 2009 at the University of Amsterdam and in 2011 he did a summer internship at Extreme Computing Group, Microsoft Research Redmond with Roger Barga. With interest in distributed systems and networks, between January 2009 and July 2010 he worked on a collaboration with Jens Teubner and Philip Frey from ETH Zurich on the development of the RDMA-part of Data Cyclotron.</p>\n\n<p>In January 2013 he joined IBM Almaden for his post-doctoral research. At IBM he worked on Big SQL 3.0, an SQL on Hadoop offering that leverages IBM\u2019s state-of-the-art relational database technology, without imposing any database structures or restrictions, hence keeping the exibility of Hadoop. Big SQL 3.0 injects IBM database technology for query optimization and execution to provide high performance SQL over Hadoop data.</p>\n\n<p>Romulo joined the Netherlands eScience Center as core eScience engineer responsible for data management systems and architectures. He works on research, design and implementation of data handling solutions for Big Data problems such as spatio-temporal data analysis on Earth Observation.</p>\n", "name": "Romulo Goncalves", "researchgateUrl": "https://www.researchgate.net/profile/Romulo_Goncalves", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-romulo-pereira-goncalves", "engineerOf": ["/project/big-data-analytics-in-the-geo-spatial-domain", "/project/3d-geospatial-data-exploration-for-modern-risk-management-systems", "/project/massive-point-clouds-for-esciences"], "jobTitle": "eScience Research Engineer", "photo": "/images/person/r.goncalves.jpg", "contributorOf": ["/software/monetdb", "/software/datavaults", "/software/pattydata", "/software/liblas"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/person", "title": "R.vanharen", "ownerOf": ["/software/netcdf2littler", "/software/wrfpy"], "slug": "r.vanharen", "id": "/person/r.vanharen", "email": "r.vanharen@esciencecenter.nl", "contactPersonOf": ["/software/netcdf2littler", "/software/wrfpy", "/project/era-urban"], "affiliation": ["/organization/nlesc"], "userOf": ["/software/netcdf2littler", "/software/wrfpy", "/software/pyxenon"], "githubUrl": "https://github.com/rvanharen", "@id": "http://software.esciencecenter.nl/person/r.vanharen/", "description": "<p>Ronald joined the Netherlands eScience Center in 2015 to work as an eScience research engineer on the ERA-URBAN project. The project is aimed at developing an environmental re-analysis specifically on the scale of the urban environment, a long-term archive of urban energy and water balances at very high resolution (~100m).</p>\n\n<p>Ronald studied aerospace engineering at the Delft University of Technology. During his masters program he specialized in data analysis, remote sensing and Earth systems. He worked on the detection of anthropogenic changes in terrestrial water storage using a combination of hydrological models and remote sensing data.</p>\n\n<p>After his masters he joined the Royal Netherlands Meteorological Institute (KNMI) to do a PhD. During his PhD research, he assessed the ability of climate models to correctly simulate precipitation using statistical techniques. Ronald defended his PhD \u201cAssessment of uncertainties in simulated European precipitation\u201d in March 2015.</p>\n\n<p>Ronald is also a core developer for the Arch Linux project, a lightweight and flexible Linux distribution that tries to Keep It Simple.</p>\n", "name": "Ronald van Haren", "researchgateUrl": "https://www.researchgate.net/profile/Ronald_Van_Haren", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-ronald-van-haren", "engineerOf": ["/project/era-urban"], "jobTitle": "eScience Research Engineer", "photo": "/images/person/r.vanharen.jpg", "contributorOf": ["/software/netcdf2littler", "/software/wrfpy", "/software/pattydata"], "endorsedBy": ["/organization/nlesc"] }, { "coordinatorOf": ["/project/emetabolomics", "/project/biomarker", "/project/generic-escience-technologies", "/project/beyond-the-data-explosion"], "jobTitle": "Director eScience Technology & Project Leader", "slug": "r.vannieuwpoort", "@id": "http://software.esciencecenter.nl/person/r.vannieuwpoort/", "email": "r.vannieuwpoort@esciencecenter.nl", "contactPersonOf": ["/software/eastroviz", "/project/generic-escience-technologies", "/project/biomarker", "/project/beyond-the-data-explosion"], "affiliation": ["/organization/nlesc", "/organization/vua"], "userOf": ["/software/xenon", "/software/eastroviz"], "title": "R.vannieuwpoort", "schema": "http://software.esciencecenter.nl/schema/person", "description": "<p>Rob received his PhD at VU University Amsterdam for work on \u201cEfficient Java-Centric Grid Computing\u201d. Rob has designed and implemented the Manta, Ibis, Satin, and JavaGAT systems (now standardized in OGF as SAGA) and worked on the EU GridLab project, and the Dutch Virtual Labs for eScience project.</p>\n\n<p>From 2009, Rob was a researcher at ASTRON, the Netherlands Institute for Radio Astronomy, where he designs and develops software for the real-time data processing of the LOFAR software telescope, the largest radio telescope in the world. This software runs on an IBM Blue Gene/P supercomputer. Rob performed research on radio astronomy algorithms and pipelines for LOFAR and the exascale SKA telescope. Rob\u2019s latest research focused on the use of many-core architectures such as GPUs for radio astronomy.</p>\n\n<p>Since 2011, he is assistant professor at VU University Amsterdam, where he teaches many-core technology, and initiated the first and only CUDA Teaching Center in the Netherlands. If you are looking for an interesting masters project, please go here. Rob\u2019s research interests include high performance computing, parallel and distributed algorithms, green computing, networks, programming languages, and compiler construction.</p>\n\n<p>In May 2012, Rob joined the Netherlands eScience Center. Rob\u2019s current position is Director eScience Technology. He is responsible for eScience Technology development in all projects, project leader of our eScience technology platform, and manager of the eScience Engineers.</p>\n", "name": "Rob van Nieuwpoort", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-rob-van-nieuwpoort", "engineerOf": ["/project/generic-escience-technologies", "/project/viaappia-patty", "/project/beyond-the-data-explosion"], "endorsedBy": ["/organization/nlesc"], "photo": "/images/person/r.vannieuwpoort.jpg", "contributorOf": ["/software/xenon", "/software/eastroviz"], "id": "/person/r.vannieuwpoort" }, { "coordinatorOf": ["/project/esibayes"], "title": "S.branchett", "id": "/person/s.branchett", "slug": "s.branchett", "schema": "http://software.esciencecenter.nl/schema/person", "email": "s.branchett@esciencecenter.nl", "contactPersonOf": ["/project/esibayes"], "affiliation": ["/organization/nlesc"], "githubUrl": "https://github.com/sbranchett", "@id": "http://software.esciencecenter.nl/person/s.branchett/", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-susan-branchett", "description": "<p>Susan studied physics at Bristol University and got her PhD for quantum mechanical calculations on \u2018Bound and Continuum states of Diatomic Molecules using the R-matrix method\u2019 from University College London.</p>\n\n<p>After a short postdoctoral period in Paris and then in London, she moved to the Netherlands in 1995. Susan\u2019s first job in the Netherlands was working for a small software company, specialized in creating detailed scheduling software for the semi-process industry. After a year at the Aegon insurance company, she took up a position in a department of TNO which later became an independent company \u2013 TNO Diana BV. This company is specialized in software products and services in the field of finite element solutions dedicated to civil, geotechnical, earthquake, and petroleum engineering.</p>\n\n<p>In 2007 she took up a management position within the IT department of the National Library of the Netherlands. There her responsibilities varied from application development to operations management of electronic publication storage and retrieval to enterprise architecture.</p>\n\n<p>On 1st May 2012, Susan joined the Netherlands eScience Center with responsibilities for project management within the \u2018Virtual laboratories for inspiration and discovery in Ecology\u2019 and the \u2018Sustainable infrastructure for translational medical research\u2019 projects.</p>\n\n<p>From 1st October 2013, Susan has been appointed as Director Business Development &amp; Operations.</p>\n", "researchgateUrl": "https://www.researchgate.net/profile/Susan_Branchett", "jobTitle": "Director Business Development & Operations", "photo": "/images/person/s.branchett.jpg", "name": "Susan Branchett", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/person", "title": "S.georgievska", "slug": "s.georgievska", "@id": "http://software.esciencecenter.nl/person/s.georgievska/", "email": "s.georgievska@esciencecenter.nl", "contactPersonOf": ["/project/arena", "/software/cclustera", "/project/massive-biological-data-clustering-reporting-and-visualization-tools"], "affiliation": ["/organization/nlesc"], "contributorOf": ["/software/cclustera"], "jobTitle": "eScience Research Engineer", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-sonja-georgievska", "description": "\n", "engineerOf": ["/software/cclustera", "/project/arena"], "id": "/person/s.georgievska", "photo": "/images/person/s.georgievska.jpg", "name": "Sonja Georgievska", "endorsedBy": ["/organization/nlesc"] }, { "linkedInUrl": "https://www.linkedin.com/in/stefan-verhoeven-15381122", "schema": "http://software.esciencecenter.nl/schema/person", "title": "S.verhoeven", "id": "/person/s.verhoeven", "slug": "s.verhoeven", "@id": "http://software.esciencecenter.nl/person/s.verhoeven/", "email": "s.verhoeven@esciencecenter.nl", "contactPersonOf": ["/software/eecology-annotation", "/software/eecology-tracker-calendar", "/software/osmium", "/software/extjs-datetime", "/project/emetabolomics", "/project/3d-e-chem", "/software/knime-archetype", "/software/3d-e-chem-vm", "/software/chemical-analytics-platform", "/software/knime-gpcrdb", "/software/knime-klifs", "/software/knime-molviewer"], "affiliation": ["/organization/nlesc"], "userOf": ["/software/xenon", "/software/osmium"], "githubUrl": "https://github.com/sverhoeven", "jobTitle": "eScience Research Engineer", "description": "<p>Stefan worked a decade within the Bioinformatics/Cheminformatics department in the pharma industry, where he administrated the Unix infrastructure and maintained/developed applications. Stefan helped scientists run their computations on clusters and maintained bioinformatics tools.\nMost of the applications he made use a rich web interface or are web service based.</p>\n\n<p>Stefan joined the Netherlands eScience Center as eScience Engineer, specialized in software development for life science projects.</p>\n", "name": "Stefan Verhoeven", "researchgateUrl": "https://www.researchgate.net/profile/Stefan_Verhoeven", "nlescWebsite": "https://www.esciencecenter.nl/profile/ing.-stefan-verhoeven", "engineerOf": ["/project/emetabolomics", "/project/eecology", "/project/massive-point-clouds-for-esciences", "/project/viaappia-patty", "/project/3d-e-chem"], "ownerOf": ["/software/eecology-annotation", "/software/eecology-tracker-calendar", "/software/osmium"], "photo": "/images/person/s.verhoeven.jpg", "contributorOf": ["/software/xenon", "/software/pyxenon", "/software/root-conda-recipes", "/software/osmium", "/software/magma", "/software/eecology-annotation", "/software/eecology-tracker-calendar", "/software/extjs-datetime", "/software/massivepotreeconverter", "/software/ahn2webviewer", "/software/potree", "/software/pattyvis", "/software/3d-e-chem-vm", "/software/knime-archetype", "/software/knime-gpcrdb", "/software/knime-klifs", "/software/knime-molviewer", "/software/chemical-analytics-platform"], "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/person", "title": "V.hees", "slug": "v.hees", "@id": "http://software.esciencecenter.nl/person/v.hees/", "email": "v.hees@esciencecenter.nl", "contactPersonOf": ["/project/compressing-the-sky-into-a-large-collection-of-statistical-models"], "affiliation": ["/organization/nlesc"], "contributorOf": ["/software/monetdb", "/software/mcfly"], "userOf": ["/software/monetdb", "/software/mcfly"], "jobTitle": "eScience Research Engineer", "description": "<p>Vincent graduated in Human kinetic technology (BEng) at The Hague University of Applied Sciences and in Human movement sciences (MSc with cum laude) at the VU University in Amsterdam. In 2008 Vincent moved to England to complete a PhD in Epidemiology at the MRC Epidemiology Unit within the University of Cambridge. Vincent did a post-doc at the Institute of Cellular Medicine within Newcastle University.</p>\n\n<p>Central theme of Vincent\u2019s work has been the development of scientific software and algorithms to process data from wearable movement sensors. Vincent pioneered the analysis of data collected with human wrist-mounted high-resolution accelerometers that have been implemented since 2007 in population research on daily physical activity and sleep. Over the years Vincent published on various methodological issues relating to this topic. Further, Vincent has co-authored publications on the first large scale implementation of the technology by scientists in Brazil and the United Kingdom. He released his code as open access software in R package GGIR.</p>\n\n<p>Vincent joined the Netherlands eScience Center in 2015.</p>\n", "nlescWebsite": "https://www.esciencecenter.nl/profile/dr.-vincent-van-hees", "engineerOf": ["/project/compressing-the-sky-into-a-large-collection-of-statistical-models"], "id": "/person/v.hees", "photo": "/images/person/v.hees.jpg", "name": "Vincent van Hees", "endorsedBy": ["/organization/nlesc"] }, { "linkedInUrl": "https://www.linkedin.com/in/wrvhage", "schema": "http://software.esciencecenter.nl/schema/person", "title": "W.vanhage", "twitterUrl": "http://twitter.com/wrvhage", "id": "/person/w.vanhage", "slug": "w.vanhage", "coordinatorOf": ["/project/simcity", "/project/microscopy"], "email": "w.vanhage@esciencecenter.nl", "affiliation": ["/organization/nlesc", "/organization/vua"], "githubUrl": "https://github.com/wrvhage", "@id": "http://software.esciencecenter.nl/person/w.vanhage/", "description": "<p>Willem received his PhD at VU University Amsterdam and TNO for work on Ontology Alignment for Information Integration. His main research topics in the past 10 years are semantics, augmented sense making, visual analytics, information integration, and text mining.</p>\n\n<p>He is a co-organizer of the LISC and DeRiVE workshop series; the Ontology Alignment Evaluation Initiative (OAEI); and the Linked Science Tutorial series about improving the speed, efficiency and transparency of Web research.</p>\n\n<p>He has developed the Simple Event Model (SEM), an OWL ontology for the description of event data; spatiotemporal indexing for SWI-Prolog (awarded with a best paper award at the EKAW 2010 conference), and the SPARQL package for the R statistical programming language.</p>\n\n<p>Willem was Chief Data Scientist at SynerScope B.V. where, as member of the management team, he helped to bring in a Series A investment. He developed various interactive visual analytics techniques for free text and brought them to the market in the fields of logistics, financial services.</p>\n\n<p>Since 2013 he is guest researcher at the Web &amp; Media group of the VU University Amsterdam, where until that time he was Assistant Professor, and gives lectures at various higher education institutions, such as TIAS, the Amsterdam Business School, Hogeschool InHolland, TU Delft and the University of Amsterdam.</p>\n", "name": "Willem van Hage", "researchgateUrl": "http://www.researchgate.net/profile/Willem_Van_Hage", "nlescWebsite": "https://www.esciencecenter.nl/profile/willem-van-hage", "jobTitle": "Tech Lead Data Management and Analytics", "photo": "/images/person/w.vanhage.jpg", "website": "http://wrvhage.nl/", "contributorOf": ["/software/rig"], "endorsedBy": ["/organization/nlesc"] }], "publication": [{ "schema": "http://software.esciencecenter.nl/schema/publication", "publishedIn": "Rapid Communications in Mass Spectrometry", "slug": "10.1002_rcm.6364", "doi": "http://dx.doi.org/10.1002/rcm.6364", "type": "journal-article", "@id": "http://software.esciencecenter.nl/publication/10.1002_rcm.6364/", "author": ["/project/emetabolomics"], "description": "<p>Ridder, L., van der Hooft, J. J. J., Verhoeven, S., de Vos, R. C. H., van Schaik, R., &amp; Vervoort, J. (2012).  Substructure-based annotation of high-resolution multistage MS  n  spectral trees . Rapid Commun. Mass Spectrom., 26(20), 2461\u00e2\u0080\u00932471. doi:10.1002/rcm.6364</p>\n", "date": "2012-09-10T00:00:00+00:00", "title": "10.1002_rcm.6364", "id": "/publication/10.1002_rcm.6364", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/publication", "publishedIn": "Analytical Chemistry", "slug": "10.1021_ac400861a", "doi": "http://dx.doi.org/10.1021/ac400861a", "type": "journal-article", "@id": "http://software.esciencecenter.nl/publication/10.1021_ac400861a/", "author": ["/project/emetabolomics"], "description": "<p>Ridder, L., van der Hooft, J. J. J., Verhoeven, S., de Vos, R. C. H., Bino, R. J., &amp; Vervoort, J. (2013).  Automatic Chemical Structure Annotation of an LC\u00e2\u0080\u0093MS  n  Based Metabolic Profile from Green Tea . Anal. Chem., 85(12), 6033\u00e2\u0080\u00936040. doi:10.1021/ac400861a</p>\n\n", "date": "2013-06-18T00:00:00+00:00", "title": "10.1021_ac400861a", "id": "/publication/10.1021_ac400861a", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/publication", "publishedIn": "Future Generation Computer Systems", "slug": "10.1016_j.future.2013.09.003", "doi": "http://dx.doi.org/10.1016/j.future.2013.09.003", "type": "journal-article", "@id": "http://software.esciencecenter.nl/publication/10.1016_j.future.2013.09.003/", "author": [], "description": "<p>Van Werkhoven, B., Maassen, J., Bal, H. E., &amp; Seinstra, F. J. (2014). Optimizing convolution operations on GPUs using adaptive tiling. Future Generation Computer Systems, 30, 14\u00e2\u0080\u009326. doi:10.1016/j.future.2013.09.003</p>\n\n", "date": "2014-01-01T00:00:00+00:00", "title": "10.1016_j.future.2013.09.003", "id": "/publication/10.1016_j.future.2013.09.003", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/publication", "publishedIn": "Procedia Computer Science", "slug": "10.1016_j.procs.2015.05.399", "doi": "http://dx.doi.org/10.1016/j.procs.2015.05.399", "type": "journal-article", "@id": "http://software.esciencecenter.nl/publication/10.1016_j.procs.2015.05.399/", "author": ["/project/simcity"], "description": "<p>Borgdorff, J., Krishna, H., &amp; Lees, M. H. (2015). SIM-CITY: An e-Science framework for Urban Assisted Decision Support. Procedia Computer Science, 51, 2327\u00e2\u0080\u00932336. doi:10.1016/j.procs.2015.05.399</p>\n\n", "date": "2015-01-01T00:00:00+00:00", "title": "10.1016_j.procs.2015.05.399", "id": "/publication/10.1016_j.procs.2015.05.399", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/publication", "publishedIn": "Concurrency and Computation: Practice and Experience", "@id": "http://software.esciencecenter.nl/publication/10.1002_cpe.3416/", "author": [], "slug": "10.1002_cpe.3416", "date": "2015-01-27T00:00:00+00:00", "title": "10.1002_cpe.3416", "id": "/publication/10.1002_cpe.3416", "type": "journal-article", "description": "<p>Hijma, P., van Nieuwpoort, R. V., Jacobs, C. J. H., &amp; Bal, H. E. (2015). Stepwise-refinement for performance: a methodology for many-core programming. Concurrency Computat.: Pract. Exper., 27(17), 4515\u00e2\u0080\u00934554. doi:10.1002/cpe.3416</p>\n\n", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/publication", "publishedIn": "Computers & Graphics", "slug": "10.1016_j.cag.2015.01.007", "doi": "http://dx.doi.org/10.1016/j.cag.2015.01.007", "type": "journal-article", "@id": "http://software.esciencecenter.nl/publication/10.1016_j.cag.2015.01.007/", "author": ["/project/massive-point-clouds-for-esciences"], "description": "<p>Van Oosterom, P., Martinez-Rubi, O., Ivanova, M., Horhammer, M., Geringer, D., Ravada, S., \u00e2\u0080\u00a6 Gon\u00c3\u00a7alves, R. (2015). Massive point cloud data management: Design, implementation and execution of a point cloud benchmark. Computers &amp; Graphics, 49, 92\u00e2\u0080\u0093125. doi:10.1016/j.cag.2015.01.007</p>\n\n", "date": "2015-06-01T00:00:00+00:00", "title": "10.1016_j.cag.2015.01.007", "id": "/publication/10.1016_j.cag.2015.01.007", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/publication", "publishedIn": "2015 IEEE 11th International Conference on e-Science", "slug": "10.1109_eScience.2015.12", "doi": "http://dx.doi.org/10.1109/eScience.2015.12", "type": "proceedings-article", "@id": "http://software.esciencecenter.nl/publication/10.1109_eScience.2015.12/", "author": ["/project/beyond-the-book"], "description": "<p>Martinez-Ortiz, C., Koolen, M., Buschenhenke, F., &amp; Dalen-Oskam, K. van. (2015). Beyond the Book: Linking Books to Wikipedia. 2015 IEEE 11th International Conference on e-Science. doi:10.1109/escience.2015.12</p>\n\n", "date": "2015-08-01T00:00:00+00:00", "title": "10.1109_escience.2015.12", "id": "/publication/10.1109_eScience.2015.12", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/publication", "publishedIn": "2015 IEEE 11th International Conference on e-Science", "slug": "10.1109_eScience.2015.18", "doi": "http://dx.doi.org/10.1109/eScience.2015.18", "type": "proceedings-article", "@id": "http://software.esciencecenter.nl/publication/10.1109_eScience.2015.18/", "author": ["/project/from-sentiment-mining-to-mining-embodied-emotions"], "description": "<p>Zwaan, J. M. van der, Leemans, I., Kuijpers, E., &amp; Maks, I. (2015). HEEM, a Complex Model for Mining Emotions in Historical Text. 2015 IEEE 11th International Conference on e-Science. doi:10.1109/escience.2015.18</p>\n\n", "date": "2015-08-01T00:00:00+00:00", "title": "10.1109_escience.2015.18", "id": "/publication/10.1109_eScience.2015.18", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/publication", "publishedIn": "2015 IEEE 11th International Conference on e-Science", "slug": "10.1109_eScience.2015.21", "doi": "http://dx.doi.org/10.1109/eScience.2015.21", "type": "proceedings-article", "@id": "http://software.esciencecenter.nl/publication/10.1109_eScience.2015.21/", "author": ["/project/summer-in-the-city"], "description": "<p>Attema, J. J., Heusinkveld, B. G., Ronda, R. J., Steeneveld, G. J., &amp; Holtslag, A. A. M. (2015). Summer in the City: Forecasting and Mapping Human Thermal Comfort in Urban Areas. 2015 IEEE 11th International Conference on e-Science. doi:10.1109/escience.2015.21</p>\n\n", "date": "2015-08-01T00:00:00+00:00", "title": "10.1109_escience.2015.21", "id": "/publication/10.1109_eScience.2015.21", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/publication", "publishedIn": "Proc. VLDB Endow.", "slug": "10.14778_2824032.2824110", "doi": "http://dx.doi.org/10.14778/2824032.2824110", "type": "journal-article", "@id": "http://software.esciencecenter.nl/publication/10.14778_2824032.2824110/", "author": ["/project/massive-point-clouds-for-esciences"], "description": "<p>Alvanaki, F., Goncalves, R., Ivanova, M., Kersten, M., &amp; Kyzirakos, K. (2015). GIS navigation boosted by column stores. Proceedings of the VLDB Endowment, 8(12), 1956\u00e2\u0080\u00931959. doi:10.14778/2824032.2824110</p>\n\n", "date": "2015-08-01T00:00:00+00:00", "title": "10.14778_2824032.2824110", "id": "/publication/10.14778_2824032.2824110", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/publication", "publishedIn": "Clim Dyn", "@id": "http://software.esciencecenter.nl/publication/10.1007_s00382-015-2899-0/", "author": [], "slug": "10.1007_s00382-015-2899-0", "date": "2015-11-19T00:00:00+00:00", "title": "10.1007_s00382 015 2899 0", "id": "/publication/10.1007_s00382-015-2899-0", "type": "journal-article", "description": "<p>Van der Linden, E. C., Bintanja, R., Hazeleger, W., &amp; Graversen, R. G. (2015). Low-frequency variability of surface air temperature over the Barents Sea: causes and mechanisms. Climate Dynamics, 47(3-4), 1247\u00e2\u0080\u00931262. doi:10.1007/s00382-015-2899-0</p>\n\n", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/publication", "publishedIn": "Astronomy and Computing", "@id": "http://software.esciencecenter.nl/publication/10.1016_j.ascom.2016.01.001/", "author": [], "slug": "10.1016_j.ascom.2016.01.001", "date": "2016-01-01T00:00:00+00:00", "title": "10.1016_j.ascom.2016.01.001", "id": "/publication/10.1016_j.ascom.2016.01.001", "type": "journal-article", "description": "<p>Sclocco, A., van Leeuwen, J., Bal, H. E., &amp; van Nieuwpoort, R. V. (2016). Real-time dedispersion for fast radio transient surveys, using auto tuning on many-core accelerators. Astronomy and Computing, 14, 1\u00e2\u0080\u00937. doi:10.1016/j.ascom.2016.01.001</p>\n\n", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/publication", "publishedIn": "Digital Applications in Archaeology and Cultural Heritage", "slug": "10.1016_j.daach.2016.03.001", "doi": "http://dx.doi.org/10.1016/j.daach.2016.03.001", "type": "journal-article", "@id": "http://software.esciencecenter.nl/publication/10.1016_j.daach.2016.03.001/", "author": ["/project/viaappia-patty"], "description": "<p>De Kleijn, M., de Hond, R., &amp; Martinez-Rubi, O. (2016). A 3D spatial data infrastructure for Mapping the Via Appia. Digital Applications in Archaeology and Cultural Heritage, 3(2), 23\u00e2\u0080\u009332. doi:10.1016/j.daach.2016.03.001</p>\n\n", "date": "2016-01-01T00:00:00+00:00", "title": "10.1016_j.daach.2016.03.001", "id": "/publication/10.1016_j.daach.2016.03.001", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/publication", "publishedIn": "Clim Dyn", "@id": "http://software.esciencecenter.nl/publication/10.1007_s00382-016-2992-z/", "author": [], "slug": "10.1007_s00382-016-2992-z", "date": "2016-02-10T00:00:00+00:00", "title": "10.1007_s00382 016 2992 Z", "id": "/publication/10.1007_s00382-016-2992-z", "type": "journal-article", "description": "<p>Deppenmeier, A.-L., Haarsma, R. J., &amp; Hazeleger, W. (2016). The Bjerknes feedback in the tropical Atlantic in CMIP5 models. Climate Dynamics. doi:10.1007/s00382-016-2992-z</p>\n\n", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/publication", "publishedIn": "Geophys. Res. Lett.", "@id": "http://software.esciencecenter.nl/publication/10.1002_2016GL068462/", "author": [], "slug": "10.1002_2016GL068462", "date": "2016-05-21T00:00:00+00:00", "title": "10.1002_2016gl068462", "id": "/publication/10.1002_2016GL068462", "type": "journal-article", "description": "<p>Krikken, F., Schmeits, M., Vlot, W., Guemas, V., &amp; Hazeleger, W. (2016). Skill improvement of dynamical seasonal Arctic sea ice forecasts. Geophysical Research Letters, 43(10), 5124\u00e2\u0080\u00935132. doi:10.1002/2016gl068462</p>\n\n", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/publication", "publishedIn": "Journal of Geophysical Research: Atmospheres", "@id": "http://software.esciencecenter.nl/publication/10.1002_2015JD024492/", "author": [], "slug": "10.1002_2015JD024492", "date": "2016-05-27T00:00:00+00:00", "title": "10.1002_2015jd024492", "id": "/publication/10.1002_2015JD024492", "type": "journal-article", "description": "<p>Rasmijn, L. M., van der Schrier, G., Barkmeijer, J., Sterl, A., &amp; Hazeleger, W. (2016). Simulating the extreme 2013/2014 winter in a future climate. J. Geophys. Res. Atmos., 121(10), 5680\u00e2\u0080\u00935698. doi:10.1002/2015jd024492</p>\n\n", "endorsedBy": ["/organization/nlesc"] }, { "schema": "http://software.esciencecenter.nl/schema/publication", "publishedIn": "International Journal of Digital Earth", "slug": "10.1080_17538947.2016.1205673", "doi": "http://dx.doi.org/10.1080/17538947.2016.1205673", "type": "journal-article", "@id": "http://software.esciencecenter.nl/publication/10.1080_17538947.2016.1205673/", "author": ["/project/viaappia-patty"], "description": "<p>Martinez-Rubi, O., de Kleijn, M., Verhoeven, S., Drost, N., Attema, J., van Meersbergen, M., \u00e2\u0080\u00a6 Svetachov, P. (2016). Using modular 3D digital earth applications based on point clouds for the study of complex sites. International Journal of Digital Earth, 1\u00e2\u0080\u009318. doi:10.1080/17538947.2016.1205673</p>\n\n", "date": "2016-07-26T00:00:00+00:00", "title": "10.1080_17538947.2016.1205673", "id": "/publication/10.1080_17538947.2016.1205673", "endorsedBy": ["/organization/nlesc"] }] }
